Chapter 13. Goals, Power, and Sample Size
================
A Solomon Kurz
2018-10-05

Goals, Power, and Sample Size
=============================

> Researchers collect data in order to achieve a goal. Sometimes the goal is to show that a suspected underlying state of the world is credible; other times the goal is to achieve a minimal degree of precision on whatever trends are observed. Whatever the goal, it can only be probabilistically achieved, as opposed to definitely achieved, because data are replete with random noise that can obscure the underlying state of the world. Statistical power is the probability of achieving the goal of a planned empirical study, if a suspected underlying state of the world is true. (p. 359)

13.1. The will to power
-----------------------

"In this section, \[Kruschke laid out a\] framework for research and data analysis \[that led\] to a more precise definition of power and how to compute it" (p. 360).

### 13.1.1 Goals and obstacles.

The three research goals Kruschke dealt with in this chapter were:

-   to reject a null value for a parameter
-   to confirm the legitimacy of a particular parameter value
-   to estimate a parameter with reasonable precision

All these could, of course, be extended to contexts involving multiple parameters. And all of these were dealt with with respect to 95% HDIs.

### 13.1.2 Power

> Because of random noise, the goal of a study can be achieved only probabilistically. The probability of achieving the goal, given the hypothetical state of the world and the sampling plan, is called the *power* of the planned research. In traditional null hypothesis significance testing (NHST), power has only one goal (rejecting the null hypothesis), and there is one conventional sampling plan (stop at predetermined sample size) and the hypothesis is only a single specific value of the parameter. In traditional statistics, that is *the* definition of power. That definition is generalized in this book to include other goals, other sampling plans, and hypotheses that involve an entire distribution on parameters. (p. 360, *emphasis* in the original)

Three primary methods to increase power are:

-   reducing measurement error
-   increasing the effect size
-   increasing the sample size

Kruschke then laid out a five-step procedure to compute power within a Bayesian workflow.

1.  Use theory/prior information to specify hypothetical distributions for all parameter values in the model.
2.  Use those distributions to generate synthetic data according to the planned sampling method.
3.  Fit the proposed model—including the relevant priors--with the synthetic data.
4.  Use the posterior to determine whether we attained the research goal.
5.  Repeat the procedure many times (i.e., using different `set.seed()` values) to get a distribution of results.

### 13.1.3 Sample size.

> *The best that a large sample can do is exactly reflect the data- generating distribution.* If the data-generating distribution has considerable mass straddling the null value, then the best we can do is get estimates that include and straddle the null value. As a simple example, suppose that we think that a coin may be biased, and the data-generating hypothesis entertains four possible values of *θ* , with p(*θ* = 0.5)=25%, p(*θ* = 0.6)=25%, p(*θ* = 0.7)=25%, and p(*θ* = 0.8)=25%. Because 25% of the simulated data come from a fair coin, the maximum probability of excluding *θ* = 0.5, even with a huge sample, is 75%.

> Therefore, when planning the sample size for an experiment, it is crucial to decide what a realistic goal is. If there are good reasons to posit a highly certain data-generating hypothesis, perhaps because of extensive previous results, then a viable goal may be to exclude a null value. On the other hand, if the data-generating hypothesis is somewhat vague, then a more reasonable goal is to attain a desired degree of precision in the posterior. (p. 364, *emphasis* in the original)

### 13.1.4 Other expressions of goals.

I'm going to skip over these.

> In the remainder of the chapter, it will be assumed that the goal of the research is estimation of the parameter values, starting with a viable prior. The resulting posterior distribution is then used to assess whether the goal was achieved. (p. 366)

13.2. Computing power and sample size
-------------------------------------

> As our first worked-out example, consider the simplest case: Data from a single coin. Perhaps we are polling a population and we want to precisely estimate the preferences for candidates A or B. Perhaps we want to know if a drug has more than a 50% cure rate. (p. 366)

### 13.2.1 When the goal is to exclude a null value.

> Usually it is more intuitively accessible to get prior data, or to think of idealized prior data, than to directly specify a distribution over parameter values. For example, based on knowledge about the application domain, we might have 2000 actual or idealized flips of the coin for which the result showed 65% heads. Therefore we’ll describe the data-generating hypothesis as a beta distribution with a mode of 0.65 and concentration based on 2000 flips after a uniform "proto-prior":

$$\\text{beta} (\\theta | 0.65 \\dot (2000 - 2) + 1, (1 - 0.65) \\dot (2000 - 2) + 1)$$

### 13.2.2 Formal solution and implementation in R.

### 13.2.3 When the goal is precision.

### 13.2.4 Monte Carlo approximation of power.

### 13.2.5 Power from idealized or actual data.

13.3. Sequential testing and the goal of precision
--------------------------------------------------

### 13.3.1 Examples of sequential tests.

### 13.3.2 Average behavior of sequential tests.

13.4. Discussion
----------------

### 13.4.1 Power and multiple comparisons.

### 13.4.2 Power: prospective, retrospective, and replication.

### 13.4.3 Power analysis requires verisimilitude of simulated data.

### 13.4.4 The importance of planning.

13.5. Exercises
---------------

References
----------

Kruschke, J. K. (2015). *Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan.* Burlington, MA: Academic Press/Elsevier.

Session info
------------

``` r
sessionInfo()
```

    ## R version 3.5.1 (2018-07-02)
    ## Platform: x86_64-apple-darwin15.6.0 (64-bit)
    ## Running under: macOS High Sierra 10.13.6
    ## 
    ## Matrix products: default
    ## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
    ## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
    ## 
    ## locale:
    ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
    ## 
    ## attached base packages:
    ## [1] stats     graphics  grDevices utils     datasets  methods   base     
    ## 
    ## loaded via a namespace (and not attached):
    ##  [1] compiler_3.5.1  backports_1.1.2 magrittr_1.5    rprojroot_1.3-2
    ##  [5] tools_3.5.1     htmltools_0.3.6 yaml_2.1.19     Rcpp_0.12.18   
    ##  [9] stringi_1.2.3   rmarkdown_1.10  knitr_1.20      stringr_1.3.1  
    ## [13] digest_0.6.15   evaluate_0.10.1
