<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>19 Metric Predicted Variable with One Nominal Predictor | Doing Bayesian Data Analysis in brms and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="19 Metric Predicted Variable with One Nominal Predictor | Doing Bayesian Data Analysis in brms and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="19 Metric Predicted Variable with One Nominal Predictor | Doing Bayesian Data Analysis in brms and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz" />


<meta name="date" content="2020-01-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="metric-predicted-variable-with-multiple-metric-predictors.html"/>
<link rel="next" href="metric-predicted-variable-with-multiple-nominal-predictors.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>What and why</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#caution-work-in-progress"><i class="fa fa-check"></i>Caution: Work in progress</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#thank-yous-are-in-order"><i class="fa fa-check"></i>Thank-you’s are in order</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html"><i class="fa fa-check"></i><b>1</b> What’s in This Book (Read This First!)</a><ul>
<li class="chapter" data-level="1.1" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#real-people-can-read-this-book"><i class="fa fa-check"></i><b>1.1</b> Real people can read this book</a></li>
<li class="chapter" data-level="1.2" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#whats-in-this-book"><i class="fa fa-check"></i><b>1.2</b> What’s in this book</a></li>
<li class="chapter" data-level="1.3" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#whats-new-in-the-second-edition"><i class="fa fa-check"></i><b>1.3</b> What’s new in the second edition</a></li>
<li class="chapter" data-level="1.4" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#gimme-feedback-be-polite"><i class="fa fa-check"></i><b>1.4</b> Gimme feedback (be polite)</a></li>
<li class="chapter" data-level="1.5" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#thank-you"><i class="fa fa-check"></i><b>1.5</b> Thank you!</a></li>
<li class="chapter" data-level="" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#reference"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="part"><span><b>I THE BASICS: MODELS, PROBABILITY, BAYES’ RULE, AND R</b></span></li>
<li class="chapter" data-level="2" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html"><i class="fa fa-check"></i><b>2</b> Introduction: Credibility, Models, and Parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#bayesian-inference-is-reallocation-of-credibility-across-possibilities"><i class="fa fa-check"></i><b>2.1</b> Bayesian inference is reallocation of credibility across possibilities</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#data-are-noisy-and-inferences-are-probabilistic."><i class="fa fa-check"></i><b>2.1.1</b> Data are noisy and inferences are probabilistic.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#possibilities-are-parameter-values-in-descriptive-models"><i class="fa fa-check"></i><b>2.2</b> Possibilities are parameter values in descriptive models</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis"><i class="fa fa-check"></i><b>2.3</b> The steps of Bayesian data analysis</a></li>
<li class="chapter" data-level="" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#reference-1"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html"><i class="fa fa-check"></i><b>3</b> The R Programming Language</a><ul>
<li class="chapter" data-level="3.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#get-the-software"><i class="fa fa-check"></i><b>3.1</b> Get the software</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#a-look-at-rstudio."><i class="fa fa-check"></i><b>3.1.1</b> A look at RStudio.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#a-simple-example-of-r-in-action"><i class="fa fa-check"></i><b>3.2</b> A simple example of R in action</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#get-the-programs-used-with-this-book."><i class="fa fa-check"></i><b>3.2.1</b> Get the programs used with this book.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#basic-commands-and-operators-in-r"><i class="fa fa-check"></i><b>3.3</b> Basic commands and operators in R</a><ul>
<li class="chapter" data-level="3.3.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#getting-help-in-r."><i class="fa fa-check"></i><b>3.3.1</b> Getting help in R.</a></li>
<li class="chapter" data-level="3.3.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#arithmetic-and-logical-operators."><i class="fa fa-check"></i><b>3.3.2</b> Arithmetic and logical operators.</a></li>
<li class="chapter" data-level="3.3.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#assignment-relational-operators-and-tests-of-equality."><i class="fa fa-check"></i><b>3.3.3</b> Assignment, relational operators, and tests of equality.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#variable-types"><i class="fa fa-check"></i><b>3.4</b> Variable types</a><ul>
<li class="chapter" data-level="3.4.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#vector."><i class="fa fa-check"></i><b>3.4.1</b> Vector.</a></li>
<li class="chapter" data-level="3.4.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#factor."><i class="fa fa-check"></i><b>3.4.2</b> Factor.</a></li>
<li class="chapter" data-level="3.4.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#matrix-and-array."><i class="fa fa-check"></i><b>3.4.3</b> Matrix and array.</a></li>
<li class="chapter" data-level="3.4.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#list-and-data-frame."><i class="fa fa-check"></i><b>3.4.4</b> List and data frame.</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#loading-and-saving-data"><i class="fa fa-check"></i><b>3.5</b> Loading and saving data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#the-read.csv-read_csv-and-read.table-read_table-functions."><i class="fa fa-check"></i><b>3.5.1</b> The <del>read.csv</del> <code>read_csv()</code> and <del>read.table</del> <code>read_table()</code> functions.</a></li>
<li class="chapter" data-level="3.5.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#saving-data-from-r."><i class="fa fa-check"></i><b>3.5.2</b> Saving data from R.</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#some-utility-functions"><i class="fa fa-check"></i><b>3.6</b> Some utility functions</a></li>
<li class="chapter" data-level="3.7" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#programming-in-r"><i class="fa fa-check"></i><b>3.7</b> Programming in R</a><ul>
<li class="chapter" data-level="3.7.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#variable-names-in-r."><i class="fa fa-check"></i><b>3.7.1</b> Variable names in R.</a></li>
<li class="chapter" data-level="3.7.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#running-a-program."><i class="fa fa-check"></i><b>3.7.2</b> Running a program.</a></li>
<li class="chapter" data-level="3.7.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#programming-a-function."><i class="fa fa-check"></i><b>3.7.3</b> Programming a function.</a></li>
<li class="chapter" data-level="3.7.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#conditions-and-loops."><i class="fa fa-check"></i><b>3.7.4</b> Conditions and loops.</a></li>
<li class="chapter" data-level="3.7.5" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#measuring-processing-time."><i class="fa fa-check"></i><b>3.7.5</b> Measuring processing time.</a></li>
<li class="chapter" data-level="3.7.6" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#debugging."><i class="fa fa-check"></i><b>3.7.6</b> Debugging.</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#graphical-plots-opening-and-saving"><i class="fa fa-check"></i><b>3.8</b> Graphical plots: Opening and saving</a></li>
<li class="chapter" data-level="" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#reference-2"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html"><i class="fa fa-check"></i><b>4</b> What is This Stuff Called Probability?</a><ul>
<li class="chapter" data-level="4.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#the-set-of-all-possible-events"><i class="fa fa-check"></i><b>4.1</b> The set of all possible events</a></li>
<li class="chapter" data-level="4.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probability-outside-or-inside-the-head"><i class="fa fa-check"></i><b>4.2</b> Probability: Outside or inside the head</a><ul>
<li class="chapter" data-level="4.2.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#outside-the-head-long-run-relative-frequency."><i class="fa fa-check"></i><b>4.2.1</b> Outside the head: Long-run relative frequency.</a></li>
<li class="chapter" data-level="4.2.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#inside-the-head-subjective-belief."><i class="fa fa-check"></i><b>4.2.2</b> Inside the head: Subjective belief.</a></li>
<li class="chapter" data-level="4.2.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probabilities-assign-numbers-to-possibilities."><i class="fa fa-check"></i><b>4.2.3</b> Probabilities assign numbers to possibilities.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probability-distributions"><i class="fa fa-check"></i><b>4.3</b> Probability distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#discrete-distributions-probability-mass."><i class="fa fa-check"></i><b>4.3.1</b> Discrete distributions: Probability mass.</a></li>
<li class="chapter" data-level="4.3.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#continuous-distributions-rendezvous-with-density."><i class="fa fa-check"></i><b>4.3.2</b> Continuous distributions: Rendezvous with density.</a></li>
<li class="chapter" data-level="4.3.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#mean-and-variance-of-a-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Mean and variance of a distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#highest-density-interval-hdi."><i class="fa fa-check"></i><b>4.3.4</b> Highest density interval (HDI).</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#two-way-distributions"><i class="fa fa-check"></i><b>4.4</b> Two-way distributions</a></li>
<li class="chapter" data-level="" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#reference-3"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>5</b> Bayes’ Rule</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-rule.html"><a href="bayes-rule.html#bayes-rule-1"><i class="fa fa-check"></i><b>5.1</b> Bayes’ rule</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayes-rule.html"><a href="bayes-rule.html#derived-from-definitions-of-conditional-probability."><i class="fa fa-check"></i><b>5.1.1</b> Derived from definitions of conditional probability.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayes-rule.html"><a href="bayes-rule.html#applied-to-parameters-and-data"><i class="fa fa-check"></i><b>5.2</b> Applied to parameters and data</a></li>
<li class="chapter" data-level="5.3" data-path="bayes-rule.html"><a href="bayes-rule.html#complete-examples-estimating-bias-in-a-coin"><i class="fa fa-check"></i><b>5.3</b> Complete examples: Estimating bias in a coin</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayes-rule.html"><a href="bayes-rule.html#influence-of-sample-size-on-the-posterior."><i class="fa fa-check"></i><b>5.3.1</b> Influence of sample size on the posterior.</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayes-rule.html"><a href="bayes-rule.html#influence-of-prior-on-the-posterior."><i class="fa fa-check"></i><b>5.3.2</b> Influence of prior on the posterior.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="bayes-rule.html"><a href="bayes-rule.html#why-bayesian-inference-can-be-difficult"><i class="fa fa-check"></i><b>5.4</b> Why Bayesian inference can be difficult</a></li>
<li class="chapter" data-level="" data-path="bayes-rule.html"><a href="bayes-rule.html#reference-4"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="bayes-rule.html"><a href="bayes-rule.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="part"><span><b>II ALL THE FUNDAMENTALS APPLIED TO INFERRING A BINOMIAL PROBABILITY</b></span></li>
<li class="chapter" data-level="6" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><i class="fa fa-check"></i><b>6</b> Inferring a Binomial Probability via Exact Mathematical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-likelihood-function-the-bernoulli-distribution"><i class="fa fa-check"></i><b>6.1</b> The likelihood function: The Bernoulli distribution</a></li>
<li class="chapter" data-level="6.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#a-description-of-credibilities-the-beta-distribution"><i class="fa fa-check"></i><b>6.2</b> A description of credibilities: The beta distribution</a><ul>
<li class="chapter" data-level="6.2.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#specifying-a-beta-prior."><i class="fa fa-check"></i><b>6.2.1</b> Specifying a beta prior.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-posterior-beta"><i class="fa fa-check"></i><b>6.3</b> The posterior beta</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#posterior-is-compromise-of-prior-and-likelihood."><i class="fa fa-check"></i><b>6.3.1</b> Posterior is compromise of prior and likelihood.</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#examples"><i class="fa fa-check"></i><b>6.4</b> Examples</a><ul>
<li class="chapter" data-level="6.4.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#prior-knowledge-expressed-as-a-beta-distribution."><i class="fa fa-check"></i><b>6.4.1</b> Prior knowledge expressed as a beta distribution.</a></li>
<li class="chapter" data-level="6.4.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#prior-knowledge-that-cannot-be-expressed-as-a-beta-distribution."><i class="fa fa-check"></i><b>6.4.2</b> Prior knowledge that cannot be expressed as a beta distribution.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#summary"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#reference-5"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>7</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="7.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#approximating-a-distribution-with-a-large-sample"><i class="fa fa-check"></i><b>7.1</b> Approximating a distribution with a large sample</a></li>
<li class="chapter" data-level="7.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-simple-case-of-the-metropolis-algorithm"><i class="fa fa-check"></i><b>7.2</b> A simple case of the Metropolis algorithm</a><ul>
<li class="chapter" data-level="7.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-politician-stumbles-upon-the-metropolis-algorithm."><i class="fa fa-check"></i><b>7.2.1</b> A politician stumbles upon the Metropolis algorithm.</a></li>
<li class="chapter" data-level="7.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-random-walk."><i class="fa fa-check"></i><b>7.2.2</b> A random walk.</a></li>
<li class="chapter" data-level="7.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#general-properties-of-a-random-walk."><i class="fa fa-check"></i><b>7.2.3</b> General properties of a random walk.</a></li>
<li class="chapter" data-level="7.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#why-we-care."><i class="fa fa-check"></i><b>7.2.4</b> Why we care.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-metropolis-algorithm-more-generally"><i class="fa fa-check"></i><b>7.3</b> The Metropolis algorithm more generally</a><ul>
<li class="chapter" data-level="7.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#metropolis-algorithm-applied-to-bernoulli-likelihood-and-beta-prior."><i class="fa fa-check"></i><b>7.3.1</b> Metropolis algorithm applied to Bernoulli likelihood and beta prior.</a></li>
<li class="chapter" data-level="7.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#summary-of-metropolis-algorithm."><i class="fa fa-check"></i><b>7.3.2</b> Summary of Metropolis algorithm.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#toward-gibbs-sampling-estimating-two-coin-biases"><i class="fa fa-check"></i><b>7.4</b> Toward Gibbs sampling: Estimating two coin biases</a><ul>
<li class="chapter" data-level="7.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#prior-likelihood-and-posterior-for-two-biases."><i class="fa fa-check"></i><b>7.4.1</b> Prior, likelihood and posterior for two biases.</a></li>
<li class="chapter" data-level="7.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-posterior-via-exact-formal-analysis."><i class="fa fa-check"></i><b>7.4.2</b> The posterior via exact formal analysis.</a></li>
<li class="chapter" data-level="7.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-posterior-via-the-metropolis-algorithm."><i class="fa fa-check"></i><b>7.4.3</b> The posterior via the Metropolis algorithm.</a></li>
<li class="chapter" data-level="7.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#gibbs-hamiltonian-monte-carlo-sampling."><i class="fa fa-check"></i><b>7.4.4</b> <del>Gibbs</del> Hamiltonian Monte Carlo sampling.</a></li>
<li class="chapter" data-level="7.4.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#is-there-a-difference-between-biases"><i class="fa fa-check"></i><b>7.4.5</b> Is there a difference between biases?</a></li>
<li class="chapter" data-level="7.4.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#terminology-mcmc."><i class="fa fa-check"></i><b>7.4.6</b> Terminology: MCMC.</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-representativeness-accuracy-and-efficiency"><i class="fa fa-check"></i><b>7.5</b> MCMC representativeness, accuracy, and efficiency</a><ul>
<li class="chapter" data-level="7.5.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-representativeness."><i class="fa fa-check"></i><b>7.5.1</b> MCMC representativeness.</a></li>
<li class="chapter" data-level="7.5.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-accuracy."><i class="fa fa-check"></i><b>7.5.2</b> MCMC accuracy.</a></li>
<li class="chapter" data-level="7.5.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-efficiency."><i class="fa fa-check"></i><b>7.5.3</b> MCMC efficiency.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#reference-6"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="jags-brms.html"><a href="jags-brms.html"><i class="fa fa-check"></i><b>8</b> <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="8.1" data-path="jags-brms.html"><a href="jags-brms.html#jags-brms-and-its-relation-to-r"><i class="fa fa-check"></i><b>8.1</b> <del>JAGS</del> brms and its relation to R</a></li>
<li class="chapter" data-level="8.2" data-path="jags-brms.html"><a href="jags-brms.html#a-complete-example"><i class="fa fa-check"></i><b>8.2</b> A complete example</a><ul>
<li class="chapter" data-level="8.2.1" data-path="jags-brms.html"><a href="jags-brms.html#load-data."><i class="fa fa-check"></i><b>8.2.1</b> Load data.</a></li>
<li class="chapter" data-level="8.2.2" data-path="jags-brms.html"><a href="jags-brms.html#specify-model."><i class="fa fa-check"></i><b>8.2.2</b> Specify model.</a></li>
<li class="chapter" data-level="8.2.3" data-path="jags-brms.html"><a href="jags-brms.html#initialize-chains."><i class="fa fa-check"></i><b>8.2.3</b> Initialize chains.</a></li>
<li class="chapter" data-level="8.2.4" data-path="jags-brms.html"><a href="jags-brms.html#generate-chains."><i class="fa fa-check"></i><b>8.2.4</b> Generate chains.</a></li>
<li class="chapter" data-level="8.2.5" data-path="jags-brms.html"><a href="jags-brms.html#examine-chains."><i class="fa fa-check"></i><b>8.2.5</b> Examine chains.</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="jags-brms.html"><a href="jags-brms.html#simplified-scripts-for-frequently-used-analyses"><i class="fa fa-check"></i><b>8.3</b> Simplified scripts for frequently used analyses</a></li>
<li class="chapter" data-level="8.4" data-path="jags-brms.html"><a href="jags-brms.html#example-difference-of-biases"><i class="fa fa-check"></i><b>8.4</b> Example: Difference of biases</a></li>
<li class="chapter" data-level="8.5" data-path="jags-brms.html"><a href="jags-brms.html#sampling-from-the-prior-distribution-in-jags-brms"><i class="fa fa-check"></i><b>8.5</b> Sampling from the prior distribution in <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="8.6" data-path="jags-brms.html"><a href="jags-brms.html#probability-distributions-available-in-jags-brms"><i class="fa fa-check"></i><b>8.6</b> Probability distributions available in <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="8.6.1" data-path="jags-brms.html"><a href="jags-brms.html#defining-new-likelihood-functions."><i class="fa fa-check"></i><b>8.6.1</b> Defining new likelihood functions.</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="jags-brms.html"><a href="jags-brms.html#faster-sampling-with-parallel-processing-in-runjags-brmsbrm"><i class="fa fa-check"></i><b>8.7</b> Faster sampling with parallel processing in <del>runjags</del> <code>brms::brm()</code></a></li>
<li class="chapter" data-level="8.8" data-path="jags-brms.html"><a href="jags-brms.html#tips-for-expanding-jags-brms-models"><i class="fa fa-check"></i><b>8.8</b> Tips for expanding <del>JAGS</del> brms models</a></li>
<li class="chapter" data-level="" data-path="jags-brms.html"><a href="jags-brms.html#reference-7"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="jags-brms.html"><a href="jags-brms.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>9</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="9.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-single-coin-from-a-single-mint"><i class="fa fa-check"></i><b>9.1</b> A single coin from a single mint</a><ul>
<li class="chapter" data-level="9.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#posterior-via-grid-approximation."><i class="fa fa-check"></i><b>9.1.1</b> Posterior via grid approximation.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#multiple-coins-from-a-single-mint"><i class="fa fa-check"></i><b>9.2</b> Multiple coins from a single mint</a><ul>
<li class="chapter" data-level="9.2.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#posterior-via-grid-approximation.-1"><i class="fa fa-check"></i><b>9.2.1</b> Posterior via grid approximation.</a></li>
<li class="chapter" data-level="9.2.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-realistic-model-with-mcmc."><i class="fa fa-check"></i><b>9.2.2</b> A realistic model with MCMC.</a></li>
<li class="chapter" data-level="9.2.3" data-path="hierarchical-models.html"><a href="hierarchical-models.html#doing-it-with-jags-brms."><i class="fa fa-check"></i><b>9.2.3</b> Doing it with <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="9.2.4" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-therapeutic-touch."><i class="fa fa-check"></i><b>9.2.4</b> Example: Therapeutic touch.</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="hierarchical-models.html"><a href="hierarchical-models.html#shrinkage-in-hierarchical-models"><i class="fa fa-check"></i><b>9.3</b> Shrinkage in hierarchical models</a></li>
<li class="chapter" data-level="9.4" data-path="hierarchical-models.html"><a href="hierarchical-models.html#speeding-up-jags-brms"><i class="fa fa-check"></i><b>9.4</b> Speeding up <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="9.5" data-path="hierarchical-models.html"><a href="hierarchical-models.html#extending-the-hierarchy-subjects-within-categories"><i class="fa fa-check"></i><b>9.5</b> Extending the hierarchy: Subjects within categories</a><ul>
<li class="chapter" data-level="9.5.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-batting-abilities-by-position."><i class="fa fa-check"></i><b>9.5.1</b> Example: Baseball batting abilities by position.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hierarchical-models.html"><a href="hierarchical-models.html#reference-8"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="hierarchical-models.html"><a href="hierarchical-models.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html"><i class="fa fa-check"></i><b>10</b> Model Comparison and Hierarchical Modeling</a><ul>
<li class="chapter" data-level="10.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#general-formula-and-the-bayes-factor"><i class="fa fa-check"></i><b>10.1</b> General formula and the Bayes factor</a></li>
<li class="chapter" data-level="10.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#example-two-factories-of-coins"><i class="fa fa-check"></i><b>10.2</b> Example: Two factories of coins</a><ul>
<li class="chapter" data-level="10.2.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-formal-analysis."><i class="fa fa-check"></i><b>10.2.1</b> Solution by formal analysis.</a></li>
<li class="chapter" data-level="10.2.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-grid-approximation."><i class="fa fa-check"></i><b>10.2.2</b> Solution by grid approximation.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-mcmc"><i class="fa fa-check"></i><b>10.3</b> Solution by MCMC</a><ul>
<li class="chapter" data-level="10.3.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#nonhierarchical-mcmc-computation-of-each-models-marginal-likelihood."><i class="fa fa-check"></i><b>10.3.1</b> Nonhierarchical MCMC computation of each model’s marginal likelihood.</a></li>
<li class="chapter" data-level="10.3.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#hierarchical-mcmc-computation-of-relative-model-probability-is-not-available-in-brms-well-cover-information-criteria-instead."><i class="fa fa-check"></i><b>10.3.2</b> Hierarchical MCMC computation <del>of relative model probability</del> is not available in brms: We’ll cover information criteria instead.</a></li>
<li class="chapter" data-level="10.3.3" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#models-with-different-noise-distributions-in-jags-brms."><i class="fa fa-check"></i><b>10.3.3</b> Models with different “noise” distributions in <del>JAGS</del> brms.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#prediction-model-averaging"><i class="fa fa-check"></i><b>10.4</b> Prediction: Model averaging</a></li>
<li class="chapter" data-level="10.5" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#model-complexity-naturally-accounted-for"><i class="fa fa-check"></i><b>10.5</b> Model complexity naturally accounted for</a><ul>
<li class="chapter" data-level="10.5.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#caveats-regarding-nested-model-comparison."><i class="fa fa-check"></i><b>10.5.1</b> Caveats regarding nested model comparison.</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#extreme-sensitivity-to-the-prior-distribution"><i class="fa fa-check"></i><b>10.6</b> Extreme sensitivity to the prior distribution</a><ul>
<li class="chapter" data-level="10.6.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#priors-of-different-models-should-be-equally-informed."><i class="fa fa-check"></i><b>10.6.1</b> Priors of different models should be equally informed.</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#bonus-theres-danger-ahead"><i class="fa fa-check"></i><b>10.7</b> Bonus: There’s danger ahead</a></li>
<li class="chapter" data-level="" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#reference-9"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html"><i class="fa fa-check"></i><b>11</b> Null Hypothesis Significance Testing</a><ul>
<li class="chapter" data-level="11.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#paved-with-good-intentions"><i class="fa fa-check"></i><b>11.1</b> Paved with good intentions</a><ul>
<li class="chapter" data-level="11.1.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#definition-of-p-value."><i class="fa fa-check"></i><b>11.1.1</b> Definition of <span class="math inline">\(p\)</span> value.</a></li>
<li class="chapter" data-level="11.1.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-n."><i class="fa fa-check"></i><b>11.1.2</b> With intention to fix <span class="math inline">\(N\)</span>.</a></li>
<li class="chapter" data-level="11.1.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-z."><i class="fa fa-check"></i><b>11.1.3</b> With intention to fix <span class="math inline">\(z\)</span>.</a></li>
<li class="chapter" data-level="11.1.4" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-duration."><i class="fa fa-check"></i><b>11.1.4</b> With intention to fix duration.</a></li>
<li class="chapter" data-level="11.1.5" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-make-multiple-tests."><i class="fa fa-check"></i><b>11.1.5</b> With intention to make multiple tests.</a></li>
<li class="chapter" data-level="11.1.6" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#soul-searching."><i class="fa fa-check"></i><b>11.1.6</b> Soul searching.</a></li>
<li class="chapter" data-level="11.1.7" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-analysis."><i class="fa fa-check"></i><b>11.1.7</b> Bayesian analysis.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#prior-knowledge"><i class="fa fa-check"></i><b>11.2</b> Prior knowledge</a><ul>
<li class="chapter" data-level="11.2.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#nhst-analysis."><i class="fa fa-check"></i><b>11.2.1</b> NHST analysis.</a></li>
<li class="chapter" data-level="11.2.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-analysis.-1"><i class="fa fa-check"></i><b>11.2.2</b> Bayesian analysis.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#confidence-interval-and-highest-density-interval"><i class="fa fa-check"></i><b>11.3</b> Confidence interval and highest density interval</a><ul>
<li class="chapter" data-level="11.3.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#ci-depends-on-intention."><i class="fa fa-check"></i><b>11.3.1</b> CI depends on intention.</a></li>
<li class="chapter" data-level="11.3.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-hdi."><i class="fa fa-check"></i><b>11.3.2</b> Bayesian HDI.</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#multiple-comparisons"><i class="fa fa-check"></i><b>11.4</b> Multiple comparisons</a><ul>
<li class="chapter" data-level="11.4.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#nhst-correction-for-experiment-wise-error."><i class="fa fa-check"></i><b>11.4.1</b> NHST correction for experiment wise error.</a></li>
<li class="chapter" data-level="11.4.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#just-one-bayesian-posterior-no-matter-how-you-look-at-it."><i class="fa fa-check"></i><b>11.4.2</b> Just one Bayesian posterior no matter how you look at it.</a></li>
<li class="chapter" data-level="11.4.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#how-bayesian-analysis-mitigates-false-alarms."><i class="fa fa-check"></i><b>11.4.3</b> How Bayesian analysis mitigates false alarms.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#what-a-sampling-distribution-is-good-for"><i class="fa fa-check"></i><b>11.5</b> What a sampling distribution is good for</a><ul>
<li class="chapter" data-level="11.5.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#planning-an-experiment."><i class="fa fa-check"></i><b>11.5.1</b> Planning an experiment.</a></li>
<li class="chapter" data-level="11.5.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#exploring-model-predictions-posterior-predictive-check."><i class="fa fa-check"></i><b>11.5.2</b> Exploring model predictions (posterior predictive check).</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#reference-10"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><i class="fa fa-check"></i><b>12</b> Bayesian Approaches to Testing a Point (“Null”) Hypothesis</a><ul>
<li class="chapter" data-level="12.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#the-estimation-approach"><i class="fa fa-check"></i><b>12.1</b> The estimation approach</a><ul>
<li class="chapter" data-level="12.1.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#region-of-practical-equivalence."><i class="fa fa-check"></i><b>12.1.1</b> Region of practical equivalence.</a></li>
<li class="chapter" data-level="12.1.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#some-examples."><i class="fa fa-check"></i><b>12.1.2</b> Some examples.</a></li>
<li class="chapter" data-level="12.1.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#differences-of-correlated-parameters."><i class="fa fa-check"></i><b>12.1.3</b> Differences of correlated parameters.</a></li>
<li class="chapter" data-level="12.1.4" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#why-hdi-and-not-equal-tailed-interval"><i class="fa fa-check"></i><b>12.1.4</b> Why HDI and not equal-tailed interval?</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#the-model-comparison-approach"><i class="fa fa-check"></i><b>12.2</b> The model-comparison approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#is-a-coin-fair-or-not"><i class="fa fa-check"></i><b>12.2.1</b> Is a coin fair or not?</a></li>
<li class="chapter" data-level="12.2.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#bayes-factor-can-accept-null-with-poor-precision."><i class="fa fa-check"></i><b>12.2.2</b> Bayes’ factor can accept null with poor precision.</a></li>
<li class="chapter" data-level="12.2.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#are-different-groups-equal-or-not"><i class="fa fa-check"></i><b>12.2.3</b> Are different groups equal or not?</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#relations-of-parameter-estimation-and-model-comparison"><i class="fa fa-check"></i><b>12.3</b> Relations of parameter estimation and model comparison</a></li>
<li class="chapter" data-level="12.4" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#estimation-and-model-comparison"><i class="fa fa-check"></i><b>12.4</b> Estimation and model comparison?</a></li>
<li class="chapter" data-level="" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#reference-11"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html"><i class="fa fa-check"></i><b>13</b> Goals, Power, and Sample Size</a><ul>
<li class="chapter" data-level="13.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#the-will-to-power"><i class="fa fa-check"></i><b>13.1</b> The will to power</a><ul>
<li class="chapter" data-level="13.1.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#goals-and-obstacles."><i class="fa fa-check"></i><b>13.1.1</b> Goals and obstacles.</a></li>
<li class="chapter" data-level="13.1.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power."><i class="fa fa-check"></i><b>13.1.2</b> Power.</a></li>
<li class="chapter" data-level="13.1.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#sample-size."><i class="fa fa-check"></i><b>13.1.3</b> Sample size.</a></li>
<li class="chapter" data-level="13.1.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#other-expressions-of-goals."><i class="fa fa-check"></i><b>13.1.4</b> Other expressions of goals.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#computing-power-and-sample-size"><i class="fa fa-check"></i><b>13.2</b> Computing power and sample size</a><ul>
<li class="chapter" data-level="13.2.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#when-the-goal-is-to-exclude-a-null-value."><i class="fa fa-check"></i><b>13.2.1</b> When the goal is to exclude a null value.</a></li>
<li class="chapter" data-level="13.2.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#formal-solution-and-implementation-in-r."><i class="fa fa-check"></i><b>13.2.2</b> Formal solution and implementation in R.</a></li>
<li class="chapter" data-level="13.2.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#when-the-goal-is-precision."><i class="fa fa-check"></i><b>13.2.3</b> When the goal is precision.</a></li>
<li class="chapter" data-level="13.2.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#monte-carlo-approximation-of-power."><i class="fa fa-check"></i><b>13.2.4</b> Monte Carlo approximation of power.</a></li>
<li class="chapter" data-level="13.2.5" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-from-idealized-or-actual-data."><i class="fa fa-check"></i><b>13.2.5</b> Power from idealized or actual data.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#sequential-testing-and-the-goal-of-precision"><i class="fa fa-check"></i><b>13.3</b> Sequential testing and the goal of precision</a><ul>
<li class="chapter" data-level="13.3.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#examples-ofsequential-tests."><i class="fa fa-check"></i><b>13.3.1</b> Examples ofsequential tests.</a></li>
<li class="chapter" data-level="13.3.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#average-behavior-of-sequential-tests."><i class="fa fa-check"></i><b>13.3.2</b> Average behavior of sequential tests.</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#discussion"><i class="fa fa-check"></i><b>13.4</b> Discussion</a><ul>
<li class="chapter" data-level="13.4.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-and-multiple-comparisons."><i class="fa fa-check"></i><b>13.4.1</b> Power and multiple comparisons.</a></li>
<li class="chapter" data-level="13.4.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-prospective-retrospective-and-replication."><i class="fa fa-check"></i><b>13.4.2</b> Power: prospective, retrospective, and replication.</a></li>
<li class="chapter" data-level="13.4.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-analysis-requires-verisimilitude-of-simulated-data."><i class="fa fa-check"></i><b>13.4.3</b> Power analysis requires verisimilitude of simulated data.</a></li>
<li class="chapter" data-level="13.4.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#the-importance-of-planning."><i class="fa fa-check"></i><b>13.4.4</b> The importance of planning.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#reference-12"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>14</b> Stan</a><ul>
<li class="chapter" data-level="14.1" data-path="stan.html"><a href="stan.html#hmc-sampling"><i class="fa fa-check"></i><b>14.1</b> HMC sampling</a></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#references"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="part"><span><b>III THE GENERALIZED LINEAR MODEL</b></span></li>
<li class="chapter" data-level="15" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>15</b> Overview of the Generalized Linear Model</a><ul>
<li class="chapter" data-level="15.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#types-of-variables"><i class="fa fa-check"></i><b>15.1</b> Types of variables</a><ul>
<li class="chapter" data-level="15.1.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#predictor-and-predicted-variables."><i class="fa fa-check"></i><b>15.1.1</b> Predictor and predicted variables.</a></li>
<li class="chapter" data-level="15.1.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#scale-types-metric-ordinal-nominal-and-count."><i class="fa fa-check"></i><b>15.1.2</b> Scale types: metric, ordinal, nominal, and count.</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linear-combination-of-predictors"><i class="fa fa-check"></i><b>15.2</b> Linear combination of predictors</a><ul>
<li class="chapter" data-level="15.2.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linear-function-of-a-single-metric-predictor."><i class="fa fa-check"></i><b>15.2.1</b> Linear function of a single metric predictor.</a></li>
<li class="chapter" data-level="15.2.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#additive-combination-of-metric-predictors."><i class="fa fa-check"></i><b>15.2.2</b> Additive combination of metric predictors.</a></li>
<li class="chapter" data-level="15.2.3" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#nonadditive-interaction-of-metric-predictors."><i class="fa fa-check"></i><b>15.2.3</b> Nonadditive interaction of metric predictors.</a></li>
<li class="chapter" data-level="15.2.4" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#nominal-predictors."><i class="fa fa-check"></i><b>15.2.4</b> Nominal predictors.</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linking-from-combined-predictors-to-noisy-predicted-data"><i class="fa fa-check"></i><b>15.3</b> Linking from combined predictors to noisy predicted data</a><ul>
<li class="chapter" data-level="15.3.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#from-predictors-to-predicted-central-tendency."><i class="fa fa-check"></i><b>15.3.1</b> From predictors to predicted central tendency.</a></li>
<li class="chapter" data-level="15.3.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#from-predicted-central-tendency-to-noisy-data."><i class="fa fa-check"></i><b>15.3.2</b> From predicted central tendency to noisy data.</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#formal-expression-of-the-glm"><i class="fa fa-check"></i><b>15.4</b> Formal expression of the GLM</a><ul>
<li class="chapter" data-level="15.4.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#cases-of-the-glm."><i class="fa fa-check"></i><b>15.4.1</b> Cases of the GLM.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#reference-13"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html"><i class="fa fa-check"></i><b>16</b> Metric-Predicted Variable on One or Two Groups</a><ul>
<li class="chapter" data-level="16.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#estimating-the-mean-and-standard-deviation-of-a-normal-distribution"><i class="fa fa-check"></i><b>16.1</b> Estimating the mean and standard deviation of a normal distribution</a><ul>
<li class="chapter" data-level="16.1.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#solution-by-mathematical-analysis-heads-up-on-precision."><i class="fa fa-check"></i><b>16.1.1</b> <del>Solution by mathematical analysis</del> Heads up on precision.</a></li>
<li class="chapter" data-level="16.1.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#approximation-by-mcmc-in-jags-hmc-in-brms."><i class="fa fa-check"></i><b>16.1.2</b> Approximation by <del>MCMC in JAGS</del> HMC in brms.</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#outliers-and-robust-estimation-the-t-distribution"><i class="fa fa-check"></i><b>16.2</b> Outliers and robust estimation: The <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="16.2.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#using-the-t-distribution-in-jags-brms."><i class="fa fa-check"></i><b>16.2.1</b> Using the <span class="math inline">\(t\)</span> distribution in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="16.2.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#using-the-t-distribution-in-stan."><i class="fa fa-check"></i><b>16.2.2</b> Using the <span class="math inline">\(t\)</span> distribution in Stan.</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#two-groups"><i class="fa fa-check"></i><b>16.3</b> Two groups</a><ul>
<li class="chapter" data-level="16.3.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#analysis-by-nhst."><i class="fa fa-check"></i><b>16.3.1</b> Analysis by NHST.</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#other-noise-distributions-and-transforming-data"><i class="fa fa-check"></i><b>16.4</b> Other noise distributions and transforming data</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#reference-14"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#session-info-15"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html"><i class="fa fa-check"></i><b>17</b> Metric Predicted Variable with One Metric Predictor</a><ul>
<li class="chapter" data-level="17.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#simple-linear-regression"><i class="fa fa-check"></i><b>17.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="17.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression"><i class="fa fa-check"></i><b>17.2</b> Robust linear regression</a><ul>
<li class="chapter" data-level="17.2.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression-in-jags-brms."><i class="fa fa-check"></i><b>17.2.1</b> Robust linear regression in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="17.2.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression-in-stan."><i class="fa fa-check"></i><b>17.2.2</b> Robust linear regression in Stan.</a></li>
<li class="chapter" data-level="17.2.3" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#stan-or-jags"><i class="fa fa-check"></i><b>17.2.3</b> Stan or JAGS?</a></li>
<li class="chapter" data-level="17.2.4" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#interpreting-the-posterior-distribution."><i class="fa fa-check"></i><b>17.2.4</b> Interpreting the posterior distribution.</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#hierarchical-regression-on-individuals-within-groups"><i class="fa fa-check"></i><b>17.3</b> Hierarchical regression on individuals within groups</a><ul>
<li class="chapter" data-level="17.3.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#the-model-and-implementation-in-jags-brms."><i class="fa fa-check"></i><b>17.3.1</b> The model and implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="17.3.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#the-posterior-distribution-shrinkage-and-prediction."><i class="fa fa-check"></i><b>17.3.2</b> The posterior distribution: Shrinkage and prediction.</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#quadratic-trend-and-weighted-data"><i class="fa fa-check"></i><b>17.4</b> Quadratic trend and weighted data</a><ul>
<li class="chapter" data-level="17.4.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#results-and-interpretation."><i class="fa fa-check"></i><b>17.4.1</b> Results and interpretation.</a></li>
<li class="chapter" data-level="17.4.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#further-extensions."><i class="fa fa-check"></i><b>17.4.2</b> Further extensions.</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#procedure-and-perils-for-expanding-a-model"><i class="fa fa-check"></i><b>17.5</b> Procedure and perils for expanding a model</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#reference-15"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#session-info-16"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html"><i class="fa fa-check"></i><b>18</b> Metric Predicted Variable with Multiple Metric Predictors</a><ul>
<li class="chapter" data-level="18.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#multiple-linear-regression"><i class="fa fa-check"></i><b>18.1</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="18.1.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-perils-of-correlated-predictors."><i class="fa fa-check"></i><b>18.1.1</b> The perils of correlated predictors.</a></li>
<li class="chapter" data-level="18.1.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-model-and-implementation."><i class="fa fa-check"></i><b>18.1.2</b> The model and implementation.</a></li>
<li class="chapter" data-level="18.1.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-posterior-distribution."><i class="fa fa-check"></i><b>18.1.3</b> The posterior distribution.</a></li>
<li class="chapter" data-level="18.1.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#redundant-predictors."><i class="fa fa-check"></i><b>18.1.4</b> Redundant predictors.</a></li>
<li class="chapter" data-level="18.1.5" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#informative-priors-sparse-data-and-correlated-predictors."><i class="fa fa-check"></i><b>18.1.5</b> Informative priors, sparse data, and correlated predictors.</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#multiplicative-interaction-of-metric-predictors"><i class="fa fa-check"></i><b>18.2</b> Multiplicative interaction of metric predictors</a><ul>
<li class="chapter" data-level="18.2.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#an-example."><i class="fa fa-check"></i><b>18.2.1</b> An example.</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#shrinkage-of-regression-coefficients"><i class="fa fa-check"></i><b>18.3</b> Shrinkage of regression coefficients</a></li>
<li class="chapter" data-level="18.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#variable-selection"><i class="fa fa-check"></i><b>18.4</b> Variable selection</a><ul>
<li class="chapter" data-level="18.4.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#inclusion-probability-is-strongly-affected-by-vagueness-of-prior."><i class="fa fa-check"></i><b>18.4.1</b> Inclusion probability is strongly affected by vagueness of prior.</a></li>
<li class="chapter" data-level="18.4.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#variable-selection-with-hierarchical-shrinkage."><i class="fa fa-check"></i><b>18.4.2</b> Variable selection with hierarchical shrinkage.</a></li>
<li class="chapter" data-level="18.4.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#what-to-report-and-what-to-conclude."><i class="fa fa-check"></i><b>18.4.3</b> What to report and what to conclude.</a></li>
<li class="chapter" data-level="18.4.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#caution-computational-methods."><i class="fa fa-check"></i><b>18.4.4</b> Caution: Computational methods.</a></li>
<li class="chapter" data-level="18.4.5" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#caution-interaction-variables."><i class="fa fa-check"></i><b>18.4.5</b> Caution: Interaction variables.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#reference-16"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#session-info-17"><i class="fa fa-check"></i>Session info</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#footnote"><i class="fa fa-check"></i>Footnote</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html"><i class="fa fa-check"></i><b>19</b> Metric Predicted Variable with One Nominal Predictor</a><ul>
<li class="chapter" data-level="19.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#describing-multiple-groups-of-metric-data"><i class="fa fa-check"></i><b>19.1</b> Describing multiple groups of metric data</a></li>
<li class="chapter" data-level="19.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#traditional-analysis-of-variance"><i class="fa fa-check"></i><b>19.2</b> Traditional analysis of variance</a></li>
<li class="chapter" data-level="19.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#hierarchical-bayesian-approach"><i class="fa fa-check"></i><b>19.3</b> Hierarchical Bayesian approach</a><ul>
<li class="chapter" data-level="19.3.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#implementation-in-jags-brms."><i class="fa fa-check"></i><b>19.3.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="19.3.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-sex-and-death."><i class="fa fa-check"></i><b>19.3.2</b> Example: Sex and death.</a></li>
<li class="chapter" data-level="19.3.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#contrasts."><i class="fa fa-check"></i><b>19.3.3</b> Contrasts.</a></li>
<li class="chapter" data-level="19.3.4" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#multiple-comparisons-and-shrinkage."><i class="fa fa-check"></i><b>19.3.4</b> Multiple comparisons and shrinkage.</a></li>
<li class="chapter" data-level="19.3.5" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#the-two-group-case."><i class="fa fa-check"></i><b>19.3.5</b> The two-group case.</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#including-a-metric-predictor"><i class="fa fa-check"></i><b>19.4</b> Including a metric predictor</a><ul>
<li class="chapter" data-level="19.4.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-sex-death-and-size."><i class="fa fa-check"></i><b>19.4.1</b> Example: Sex, death, and size.</a></li>
<li class="chapter" data-level="19.4.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#analogous-to-traditional-ancova."><i class="fa fa-check"></i><b>19.4.2</b> Analogous to traditional ANCOVA.</a></li>
<li class="chapter" data-level="19.4.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#relation-to-hierarchical-linear-regression."><i class="fa fa-check"></i><b>19.4.3</b> Relation to hierarchical linear regression.</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#heterogeneous-variances-and-robustness-against-outliers"><i class="fa fa-check"></i><b>19.5</b> Heterogeneous variances and robustness against outliers</a><ul>
<li class="chapter" data-level="19.5.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-contrast-of-means-with-different-variances."><i class="fa fa-check"></i><b>19.5.1</b> Example: Contrast of means with different variances.</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#exercises-walk-out-an-effect-size"><i class="fa fa-check"></i><b>19.6</b> <del>Exercises</del> Walk out an effect size</a><ul>
<li class="chapter" data-level="19.6.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#populations-and-samples."><i class="fa fa-check"></i><b>19.6.1</b> Populations and samples.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#reference-17"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#session-info-18"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html"><i class="fa fa-check"></i><b>20</b> Metric Predicted Variable with Multiple Nominal Predictors</a><ul>
<li class="chapter" data-level="20.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#describing-groups-of-metric-data-with-multiple-nominal-predictors"><i class="fa fa-check"></i><b>20.1</b> Describing groups of metric data with multiple nominal predictors</a><ul>
<li class="chapter" data-level="20.1.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#interaction."><i class="fa fa-check"></i><b>20.1.1</b> Interaction.</a></li>
<li class="chapter" data-level="20.1.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#traditional-anova."><i class="fa fa-check"></i><b>20.1.2</b> Traditional ANOVA.</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#hierarchical-bayesian-approach-1"><i class="fa fa-check"></i><b>20.2</b> Hierarchical Bayesian approach</a><ul>
<li class="chapter" data-level="20.2.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#implementation-in-jags-brms.-1"><i class="fa fa-check"></i><b>20.2.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="20.2.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#example-its-only-money."><i class="fa fa-check"></i><b>20.2.2</b> Example: It’s only money.</a></li>
<li class="chapter" data-level="20.2.3" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#main-effect-contrasts."><i class="fa fa-check"></i><b>20.2.3</b> Main effect contrasts.</a></li>
<li class="chapter" data-level="20.2.4" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#interaction-contrasts-and-simple-effects."><i class="fa fa-check"></i><b>20.2.4</b> Interaction contrasts and simple effects.</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#rescaling-can-change-interactions-homogeneity-and-normality"><i class="fa fa-check"></i><b>20.3</b> Rescaling can change interactions, homogeneity, and normality</a></li>
<li class="chapter" data-level="20.4" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#heterogeneous-variances-and-robustness-against-outliers-1"><i class="fa fa-check"></i><b>20.4</b> Heterogeneous variances and robustness against outliers</a></li>
<li class="chapter" data-level="20.5" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#within-subject-designs"><i class="fa fa-check"></i><b>20.5</b> Within-subject designs</a><ul>
<li class="chapter" data-level="20.5.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#why-use-a-within-subject-design-and-why-not"><i class="fa fa-check"></i><b>20.5.1</b> Why use a within-subject design? And why not?</a></li>
<li class="chapter" data-level="20.5.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#split-plot-design."><i class="fa fa-check"></i><b>20.5.2</b> Split-plot design.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#reference-18"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#session-info-19"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html"><i class="fa fa-check"></i><b>21</b> Dichotomous Predicted Variable</a><ul>
<li class="chapter" data-level="21.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#multiple-metric-predictors"><i class="fa fa-check"></i><b>21.1</b> Multiple metric predictors</a><ul>
<li class="chapter" data-level="21.1.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#the-model-and-implementation-in-jags-brms.-1"><i class="fa fa-check"></i><b>21.1.1</b> The model and implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="21.1.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#example-height-weight-and-gender."><i class="fa fa-check"></i><b>21.1.2</b> Example: Height, weight, and gender.</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#interpreting-the-regression-coefficients"><i class="fa fa-check"></i><b>21.2</b> Interpreting the regression coefficients</a><ul>
<li class="chapter" data-level="21.2.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#log-odds."><i class="fa fa-check"></i><b>21.2.1</b> Log odds.</a></li>
<li class="chapter" data-level="21.2.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#when-there-are-few-1s-or-0s-in-the-data."><i class="fa fa-check"></i><b>21.2.2</b> When there are few 1’s or 0’s in the data.</a></li>
<li class="chapter" data-level="21.2.3" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#correlated-predictors."><i class="fa fa-check"></i><b>21.2.3</b> Correlated predictors.</a></li>
<li class="chapter" data-level="21.2.4" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#interaction-of-metric-predictors."><i class="fa fa-check"></i><b>21.2.4</b> Interaction of metric predictors.</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#robust-logistic-regression"><i class="fa fa-check"></i><b>21.3</b> Robust logistic regression</a></li>
<li class="chapter" data-level="21.4" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#nominal-predictors"><i class="fa fa-check"></i><b>21.4</b> Nominal predictors</a><ul>
<li class="chapter" data-level="21.4.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#single-group."><i class="fa fa-check"></i><b>21.4.1</b> Single group.</a></li>
<li class="chapter" data-level="21.4.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#multiple-groups."><i class="fa fa-check"></i><b>21.4.2</b> Multiple groups.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#reference-19"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#session-info-20"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html"><i class="fa fa-check"></i><b>22</b> Nominal Predicted Variable</a><ul>
<li class="chapter" data-level="22.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-regression"><i class="fa fa-check"></i><b>22.1</b> Softmax regression</a><ul>
<li class="chapter" data-level="22.1.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-reduces-to-logistic-for-two-outcomes."><i class="fa fa-check"></i><b>22.1.1</b> Softmax reduces to logistic for two outcomes.</a></li>
<li class="chapter" data-level="22.1.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#independence-from-irrelevant-attributes."><i class="fa fa-check"></i><b>22.1.2</b> Independence from irrelevant attributes.</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#conditional-logistic-regression"><i class="fa fa-check"></i><b>22.2</b> Conditional logistic regression</a></li>
<li class="chapter" data-level="22.3" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#implementation-in-jags-brms"><i class="fa fa-check"></i><b>22.3</b> Implementation in <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="22.3.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-model."><i class="fa fa-check"></i><b>22.3.1</b> Softmax model.</a></li>
<li class="chapter" data-level="22.3.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#conditional-logistic-model."><i class="fa fa-check"></i><b>22.3.2</b> Conditional logistic model.</a></li>
<li class="chapter" data-level="22.3.3" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#results-interpreting-the-regression-coefficients."><i class="fa fa-check"></i><b>22.3.3</b> Results: Interpreting the regression coefficients.</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#generalizations-and-variations-of-the-models"><i class="fa fa-check"></i><b>22.4</b> Generalizations and variations of the models</a></li>
<li class="chapter" data-level="" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#reference-20"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#session-info-21"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html"><i class="fa fa-check"></i><b>23</b> Ordinal Predicted Variable</a><ul>
<li class="chapter" data-level="23.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#modeling-ordinal-data-with-an-underlying-metric-variable"><i class="fa fa-check"></i><b>23.1</b> Modeling ordinal data with an underlying metric variable</a></li>
<li class="chapter" data-level="23.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-a-single-group"><i class="fa fa-check"></i><b>23.2</b> The case of a single group</a><ul>
<li class="chapter" data-level="23.2.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-3"><i class="fa fa-check"></i><b>23.2.1</b> Implementation in <del>JAGS</del> <strong>brms</strong>.</a></li>
<li class="chapter" data-level="23.2.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#examples-bayesian-estimation-recovers-true-parameter-values."><i class="fa fa-check"></i><b>23.2.2</b> Examples: Bayesian estimation recovers true parameter values.</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-two-groups"><i class="fa fa-check"></i><b>23.3</b> The case of two groups</a><ul>
<li class="chapter" data-level="23.3.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-4"><i class="fa fa-check"></i><b>23.3.1</b> Implementation in <del>JAGS</del> <strong>brms</strong>.</a></li>
<li class="chapter" data-level="23.3.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#examples-not-funny."><i class="fa fa-check"></i><b>23.3.2</b> Examples: Not funny.</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-metric-predictors"><i class="fa fa-check"></i><b>23.4</b> The Case of metric predictors</a><ul>
<li class="chapter" data-level="23.4.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags."><i class="fa fa-check"></i><b>23.4.1</b> Implementation in JAGS.</a></li>
<li class="chapter" data-level="23.4.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#example-happiness-and-money."><i class="fa fa-check"></i><b>23.4.2</b> Example: Happiness and money.</a></li>
<li class="chapter" data-level="23.4.3" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#example-moviesthey-dont-make-em-like-they-used-to."><i class="fa fa-check"></i><b>23.4.3</b> Example: Movies–They don’t make ’em like they used to.</a></li>
<li class="chapter" data-level="23.4.4" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#why-are-some-thresholds-outside-the-data"><i class="fa fa-check"></i><b>23.4.4</b> Why are some thresholds outside the data?</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#posterior-prediction"><i class="fa fa-check"></i><b>23.5</b> Posterior prediction</a></li>
<li class="chapter" data-level="23.6" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#generalizations-and-extensions"><i class="fa fa-check"></i><b>23.6</b> Generalizations and extensions</a></li>
<li class="chapter" data-level="" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#reference-21"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#session-info-22"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html"><i class="fa fa-check"></i><b>24</b> Count Predicted Variable</a><ul>
<li class="chapter" data-level="24.1" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#poisson-exponential-model"><i class="fa fa-check"></i><b>24.1</b> Poisson exponential model</a><ul>
<li class="chapter" data-level="24.1.1" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#data-structure."><i class="fa fa-check"></i><b>24.1.1</b> Data structure.</a></li>
<li class="chapter" data-level="24.1.2" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#exponential-link-function."><i class="fa fa-check"></i><b>24.1.2</b> Exponential link function.</a></li>
<li class="chapter" data-level="24.1.3" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#poisson-noise-distribution."><i class="fa fa-check"></i><b>24.1.3</b> Poisson noise distribution.</a></li>
<li class="chapter" data-level="24.1.4" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#the-complete-model-and-implementation-in-jags-brms."><i class="fa fa-check"></i><b>24.1.4</b> The complete model and implementation in <del>JAGS</del> brms.</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#example-hair-eye-go-again"><i class="fa fa-check"></i><b>24.2</b> Example: Hair eye go again</a></li>
<li class="chapter" data-level="24.3" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#example-interaction-contrasts-shrinkage-and-omnibus-test"><i class="fa fa-check"></i><b>24.3</b> Example: Interaction contrasts, shrinkage, and omnibus test</a></li>
<li class="chapter" data-level="24.4" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#log-linear-models-for-contingency-tables-bonus-alternative-parameterization"><i class="fa fa-check"></i><b>24.4</b> <del>Log-linear models for contingency tables</del> Bonus: Alternative parameterization</a></li>
<li class="chapter" data-level="" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#reference-22"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#session-info-23"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Doing Bayesian Data Analysis</em> in brms and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="metric-predicted-variable-with-one-nominal-predictor" class="section level1">
<h1><span class="header-section-number">19</span> Metric Predicted Variable with One Nominal Predictor</h1>
<blockquote>
<p>This chapter considers data structures that consist of a metric predicted variable and a nominal predictor…. This type of data structure can arise from experiments or from observational studies. In experiments, the researcher assigns the categories (at random) to the experimental subjects. In observational studies, both the nominal predictor value and the metric predicted value are generated by processes outside the direct control of the researcher. In either case, the same mathematical description can be applied to the data (although causality is best inferred from experimental intervention).</p>
<p>The traditional treatment of this sort of data structure is called single-factor analysis of variance (ANOVA), or sometimes one-way ANOVA. Our Bayesian approach will be a hierarchical generalization of the traditional ANOVA model. The chapter will also consider the situation in which there is also a metric predictor that accompanies the primary nominal predictor. The metric predictor is sometimes called a covariate, and the traditional treatment of this data structure is called analysis of covariance (ANCOVA). The chapter also considers generalizations of the traditional models, because it is straight forward in Bayesian software to implement heavy-tailed distributions to accommodate outliers, along with hierarchical structure to accommodate heterogeneous variances in the different groups, etc. (pp. 553–554)</p>
</blockquote>
<div id="describing-multiple-groups-of-metric-data" class="section level2">
<h2><span class="header-section-number">19.1</span> Describing multiple groups of metric data</h2>
<blockquote>
<p>Figure 19.1 illustrates the conventional description of grouped metric data. Each group is represented as a position on the horizontal axis. The vertical axis represents the variable to be predicted by group membership. The data are assumed to be normally distributed within groups, with equal standard deviation in all groups. The group means are deflections from overall baseline, such that the deflections sum to zero. Figure 19.1 provides a specific numerical example, with data that were randomly generated from the model. (p. 554)</p>
</blockquote>
<p>We’ll want a custom data-generating function for our primary group data.</p>
<div class="sourceCode" id="cb1557"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1557-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb1557-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1557-3" data-line-number="3">generate_data &lt;-<span class="st"> </span><span class="cf">function</span>(seed, mean) {</a>
<a class="sourceLine" id="cb1557-4" data-line-number="4">  <span class="kw">set.seed</span>(seed)</a>
<a class="sourceLine" id="cb1557-5" data-line-number="5">  <span class="kw">rnorm</span>(n, <span class="dt">mean =</span> grand_mean <span class="op">+</span><span class="st"> </span>mean, <span class="dt">sd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1557-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb1557-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1557-8" data-line-number="8">n          &lt;-<span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb1557-9" data-line-number="9">grand_mean &lt;-<span class="st"> </span><span class="dv">101</span></a>
<a class="sourceLine" id="cb1557-10" data-line-number="10"></a>
<a class="sourceLine" id="cb1557-11" data-line-number="11">d &lt;-</a>
<a class="sourceLine" id="cb1557-12" data-line-number="12"><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">group     =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb1557-13" data-line-number="13">         <span class="dt">deviation =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">-5</span>, <span class="dv">-2</span>, <span class="dv">6</span>, <span class="dv">-3</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1557-14" data-line-number="14"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d =</span> purrr<span class="op">::</span><span class="kw">map2</span>(group, deviation, generate_data)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1557-15" data-line-number="15"><span class="st">  </span><span class="kw">unnest</span>(d) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1557-16" data-line-number="16"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iteration =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="dt">times =</span> <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb1557-17" data-line-number="17"></a>
<a class="sourceLine" id="cb1557-18" data-line-number="18"><span class="kw">glimpse</span>(d)</a></code></pre></div>
<pre><code>## Observations: 100
## Variables: 4
## $ group     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2…
## $ deviation &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, -5, -5, -5, -5, -5,…
## $ d         &lt;dbl&gt; 103.74709, 105.36729, 103.32874, 108.19056, 105.65902, 103.35906, 105.97486, 10…
## $ iteration &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 2, 3,…</code></pre>
<p>Here we’ll make a tibble containing the necessary data for the rotated Gaussians. As far as I can tell, Kruschke’s Gaussians only span to the bounds of percentile-based 98% intervals. We partition off those bounds for each <code>group</code> by the <code>ll</code> and <code>ul</code> columns in the first <code>mutate()</code> function. In the second <code>mutate()</code>, we expand the dataset to include a sequence of 100 values between those lower- and upper-limit points. In the third <code>mutate()</code>, we feed those points into the <code>dnorm()</code> function, with group-specific means and a common <code>sd</code>.</p>
<div class="sourceCode" id="cb1559"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1559-1" data-line-number="1">densities &lt;-</a>
<a class="sourceLine" id="cb1559-2" data-line-number="2"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1559-3" data-line-number="3"><span class="st">  </span><span class="kw">distinct</span>(group, deviation) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1559-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ll      =</span> <span class="kw">qnorm</span>(.<span class="dv">01</span>, <span class="dt">mean =</span> grand_mean <span class="op">+</span><span class="st"> </span>deviation, <span class="dt">sd =</span> <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb1559-5" data-line-number="5">         <span class="dt">ul      =</span> <span class="kw">qnorm</span>(.<span class="dv">99</span>, <span class="dt">mean =</span> grand_mean <span class="op">+</span><span class="st"> </span>deviation, <span class="dt">sd =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1559-6" data-line-number="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d       =</span> <span class="kw">map2</span>(ll, ul, seq, <span class="dt">length.out =</span> <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1559-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">map2</span>(d, grand_mean <span class="op">+</span><span class="st"> </span>deviation, dnorm, <span class="dt">sd =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1559-8" data-line-number="8"><span class="st">  </span><span class="kw">unnest</span>(<span class="kw">c</span>(d, density))</a>
<a class="sourceLine" id="cb1559-9" data-line-number="9"></a>
<a class="sourceLine" id="cb1559-10" data-line-number="10"><span class="kw">head</span>(densities)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   group deviation    ll    ul     d density
##   &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
## 1     1         4  100.  110.  100.  0.0133
## 2     1         4  100.  110.  100.  0.0148
## 3     1         4  100.  110.  101.  0.0165
## 4     1         4  100.  110.  101.  0.0183
## 5     1         4  100.  110.  101.  0.0203
## 6     1         4  100.  110.  101.  0.0224</code></pre>
<p>We’ll need two more supplementary tibbles to add the flourishes to the plot. The <code>arrow</code> tibble will specify our light-gray arrows. The <code>text</code> tibble will contain our annotation information.</p>
<div class="sourceCode" id="cb1561"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1561-1" data-line-number="1">arrow &lt;-</a>
<a class="sourceLine" id="cb1561-2" data-line-number="2"><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">group     =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb1561-3" data-line-number="3">         <span class="dt">d         =</span> grand_mean,</a>
<a class="sourceLine" id="cb1561-4" data-line-number="4">         <span class="dt">deviation =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">-5</span>, <span class="dv">-2</span>, <span class="dv">6</span>, <span class="dv">-3</span>),</a>
<a class="sourceLine" id="cb1561-5" data-line-number="5">         <span class="dt">offset    =</span> <span class="fl">.1</span>)</a>
<a class="sourceLine" id="cb1561-6" data-line-number="6"></a>
<a class="sourceLine" id="cb1561-7" data-line-number="7"><span class="kw">head</span>(arrow)</a></code></pre></div>
<pre><code>## # A tibble: 5 x 4
##   group     d deviation offset
##   &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;
## 1     1   101         4    0.1
## 2     2   101        -5    0.1
## 3     3   101        -2    0.1
## 4     4   101         6    0.1
## 5     5   101        -3    0.1</code></pre>
<div class="sourceCode" id="cb1563"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1563-1" data-line-number="1">text &lt;-</a>
<a class="sourceLine" id="cb1563-2" data-line-number="2"><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">group     =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">5</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb1563-3" data-line-number="3">         <span class="dt">d         =</span> grand_mean,</a>
<a class="sourceLine" id="cb1563-4" data-line-number="4">         <span class="dt">deviation =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">-5</span>, <span class="dv">-2</span>, <span class="dv">6</span>, <span class="dv">-3</span>, <span class="dv">10</span>),</a>
<a class="sourceLine" id="cb1563-5" data-line-number="5">         <span class="dt">offset    =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dv">0</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">1</span>)),</a>
<a class="sourceLine" id="cb1563-6" data-line-number="6">         <span class="dt">angle     =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">90</span>, <span class="dv">0</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">1</span>)),</a>
<a class="sourceLine" id="cb1563-7" data-line-number="7">         <span class="dt">label     =</span> <span class="kw">c</span>(<span class="st">&quot;beta[0] == 101&quot;</span>, <span class="st">&quot;beta[&#39;[1]&#39;] == 4&quot;</span>, <span class="st">&quot;beta[&#39;[2]&#39;] == -5&quot;</span>, <span class="st">&quot;beta[&#39;[3]&#39;] == -2&quot;</span>, <span class="st">&quot;beta[&#39;[4]&#39;] == 6&quot;</span>, <span class="st">&quot;beta[&#39;[5]&#39;] == 3&quot;</span>, <span class="st">&quot;sigma[&#39;all&#39;] == 2&quot;</span>))</a>
<a class="sourceLine" id="cb1563-8" data-line-number="8"></a>
<a class="sourceLine" id="cb1563-9" data-line-number="9"><span class="kw">head</span>(text)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   group     d deviation offset angle label            
##   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;            
## 1     0   101         0   0.25    90 beta[0] == 101   
## 2     1   101         4   0.25    90 beta[&#39;[1]&#39;] == 4 
## 3     2   101        -5   0.25    90 beta[&#39;[2]&#39;] == -5
## 4     3   101        -2   0.25    90 beta[&#39;[3]&#39;] == -2
## 5     4   101         6   0.25    90 beta[&#39;[4]&#39;] == 6 
## 6     5   101        -3   0.25    90 beta[&#39;[5]&#39;] == 3</code></pre>
<p>Now we’re ready to plot.</p>
<div class="sourceCode" id="cb1565"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1565-1" data-line-number="1"><span class="kw">library</span>(ggridges)</a>
<a class="sourceLine" id="cb1565-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1565-3" data-line-number="3">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1565-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> d, <span class="dt">y =</span> group, <span class="dt">group =</span> group)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> grand_mean, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="fl">.05</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-7" data-line-number="7"><span class="st">  </span><span class="co"># the Gausians</span></a>
<a class="sourceLine" id="cb1565-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_ridgeline</span>(<span class="dt">data =</span> densities,</a>
<a class="sourceLine" id="cb1565-9" data-line-number="9">                 <span class="kw">aes</span>(<span class="dt">height =</span> <span class="op">-</span>density),</a>
<a class="sourceLine" id="cb1565-10" data-line-number="10">                 <span class="dt">min_height =</span> <span class="ot">NA</span>, <span class="dt">scale =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1565-11" data-line-number="11">                 <span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-12" data-line-number="12"><span class="st">  </span><span class="co"># the small arrows</span></a>
<a class="sourceLine" id="cb1565-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">data =</span> arrow,</a>
<a class="sourceLine" id="cb1565-14" data-line-number="14">               <span class="kw">aes</span>(<span class="dt">xend =</span> d <span class="op">+</span><span class="st"> </span>deviation,</a>
<a class="sourceLine" id="cb1565-15" data-line-number="15">                   <span class="dt">y =</span> group <span class="op">+</span><span class="st"> </span>offset, <span class="dt">yend =</span> group <span class="op">+</span><span class="st"> </span>offset),</a>
<a class="sourceLine" id="cb1565-16" data-line-number="16">               <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb1565-17" data-line-number="17">               <span class="dt">arrow =</span> <span class="kw">arrow</span>(<span class="dt">length =</span> <span class="kw">unit</span>(.<span class="dv">2</span>, <span class="st">&quot;cm&quot;</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-18" data-line-number="18"><span class="st">  </span><span class="co"># the large arrow on the left</span></a>
<a class="sourceLine" id="cb1565-19" data-line-number="19"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">80</span>, <span class="dt">xend =</span> grand_mean,</a>
<a class="sourceLine" id="cb1565-20" data-line-number="20">                   <span class="dt">y =</span> <span class="dv">0</span>, <span class="dt">yend =</span> <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb1565-21" data-line-number="21">               <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>, <span class="dt">size =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1565-22" data-line-number="22">               <span class="dt">arrow =</span> <span class="kw">arrow</span>(<span class="dt">length =</span> <span class="kw">unit</span>(.<span class="dv">2</span>, <span class="st">&quot;cm&quot;</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-23" data-line-number="23"><span class="st">  </span><span class="co"># the text</span></a>
<a class="sourceLine" id="cb1565-24" data-line-number="24"><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> text,</a>
<a class="sourceLine" id="cb1565-25" data-line-number="25">            <span class="kw">aes</span>(<span class="dt">x =</span> grand_mean <span class="op">+</span><span class="st"> </span>deviation, <span class="dt">y =</span> group <span class="op">+</span><span class="st"> </span>offset,</a>
<a class="sourceLine" id="cb1565-26" data-line-number="26">                <span class="dt">label =</span> label, <span class="dt">angle =</span> angle), </a>
<a class="sourceLine" id="cb1565-27" data-line-number="27">            <span class="dt">size =</span> <span class="dv">4</span>, <span class="dt">parse =</span> T) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-28" data-line-number="28"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb1565-29" data-line-number="29">                     <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;&lt;1,0,0,0,0&gt;&quot;</span>, <span class="st">&quot;&lt;0,1,0,0,0&gt;&quot;</span>, <span class="st">&quot;&lt;0,0,1,0,0&gt;&quot;</span>, <span class="st">&quot;&lt;0,0,0,1,0&gt;&quot;</span>, <span class="st">&quot;&lt;0,0,0,0,1&gt;&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-30" data-line-number="30"><span class="st">  </span><span class="kw">coord_flip</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">5.5</span>), <span class="dt">xlim =</span> <span class="dv">90</span><span class="op">:</span><span class="dv">112</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-31" data-line-number="31"><span class="st">  </span><span class="kw">xlab</span>(<span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1565-32" data-line-number="32"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-5-1.png" /><!-- --></p>
<blockquote>
<p>The descriptive model presented in Figure 19.1 is the traditional one used by classical ANOVA (which is described a bit more in the next section). More general models are straight forward to implement in Bayesian software. For example, outliers could be accommodated by using heavy-tailed noise distributions (such as a <span class="math inline">\(t\)</span> distribution) instead of a normal distribution, and different groups could be given different standard deviations. (p. 556)</p>
</blockquote>
</div>
<div id="traditional-analysis-of-variance" class="section level2">
<h2><span class="header-section-number">19.2</span> Traditional analysis of variance</h2>
<blockquote>
<p>The terminology, “analysis of variance,” comes from a decomposition of overall data variance into within-group variance and between-group variance (<a href="http://psycnet.apa.org/record/1925-15003-000">Fisher, 1925</a>). Algebraically, the sum of squared deviations of the scores from their overall mean equals the sum of squared deviations of the scores from their respective group means plus the sum of squared deviations of the group means from the overall mean. In other words, the total variance can be partitioned into within-group variance plus between-group variance. Because one definition of the word “analysis” is separation into constituent parts, the term ANOVA accurately describes the underlying algebra in the traditional methods. That algebraic relation is not used in the hierarchical Bayesian approach presented here. The Bayesian method can estimate component variances, however. Therefore, the Bayesian approach is not ANOVA, but is analogous to ANOVA. (p. 556)</p>
</blockquote>
</div>
<div id="hierarchical-bayesian-approach" class="section level2">
<h2><span class="header-section-number">19.3</span> Hierarchical Bayesian approach</h2>
<p>“Our goal is to estimate its parameters in a Bayesian framework. Therefore, all the parameters need to be given a meaningfully structured prior distribution” (p. 557). However, our approach will depart a little from the one in the text. All our parameters will <strong>not</strong> “have generic noncommittal prior distributions” (p. 557). Most importantly, we will not follow the example in <a href="http://www.stat.columbia.edu/~gelman/research/published/taumain.pdf">Gelman (2006)</a> of putting a broad uniform prior on <span class="math inline">\(\sigma_y\)</span>. Rather, we will continue using the half-Gaussian prior, as <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">recommended by the Stan team</a>. However, we will follow Kruschke’s lead for the overall intercept and use a Gaussian prior “made broad on the scale of the data” (p. 557). And like Kruschke, we will estimate <span class="math inline">\(\sigma_\beta\)</span> from the data.</p>
<p>Later on, Kruschke opined</p>
<blockquote>
<p>A crucial pre-requisite for estimating <span class="math inline">\(\sigma_\beta\)</span> from all the groups is an assumption that all the groups are representative and informative for the estimate. It only makes sense to influence the estimate of one group with data from the other groups if the groups can be meaningfully described as representative of a shared higher-level distribution. (p. 559)</p>
</blockquote>
<p>Although I agree with him in spirit, this doesn’t appear to strictly be the case. As odd and paradoxical as this sounds, partial pooling can be of use even when the some of the cases are of a different kind. For more on the topic, see <a href="http://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf">Efron and Morris’s classic paper</a> and <a href="https://solomonkurz.netlify.com/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/">my blog post</a> walking out one of their examples in <strong>brms</strong>.</p>
<div id="implementation-in-jags-brms." class="section level3">
<h3><span class="header-section-number">19.3.1</span> Implementation in <del>JAGS</del> brms.</h3>
<p>The <strong>brms</strong> setup, of course, differs a bit from JAGS.</p>
<div class="sourceCode" id="cb1566"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1566-1" data-line-number="1">fit &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1566-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data, </a>
<a class="sourceLine" id="cb1566-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1566-4" data-line-number="4">      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>categirical_variable),</a>
<a class="sourceLine" id="cb1566-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, x), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1566-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, x), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1566-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, x), <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1566-8" data-line-number="8">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, x), <span class="dt">class =</span> sigma)))</a></code></pre></div>
<p>The noise standard deviation <span class="math inline">\(\sigma_y\)</span> is depicted in the prior statement including the argument <code>class = sigma</code>. The grand mean is depicted by the first <code>1</code> in the model formula and its prior is indicated by the <code>class = Intercept</code> argument. We indicate we’d like group-based deviations from the grand mean with the <code>(1 | categirical_variable)</code> syntax, where the <code>1</code> on the left side of the bar indicates we’d like our intercepts to vary by group and the <code>categirical_variable</code> part simply represents the name of a given categorical variable we’d like those intercepts to vary by. The <strong>brms</strong> default is to do this with deviance scores, the mean for which will be zero. Although it’s not obvious in the formula syntax, the model presumes the group-based deviations are normally distributed with a mean of zero and a standard deviation, which Kruschke termed <span class="math inline">\(\sigma_\beta\)</span>. There is no prior for the mean. It’s set at zero. But there is a prior for <span class="math inline">\(\sigma_\beta\)</span>, which is denoted by the argument <code>class = sd</code>. We, of course, are not using a uniform prior on any of our variance parameters. But in order to be weakly informative, we will use the half-Cauchy. Recall that since the <strong>brms</strong> default is to set the lower bound for any variance parameter to 0, there’s no need to worry about doing so ourselves. So even though the syntax only indicates <code>cauchy</code>, it’s understood to mean Cauchy with a lower bound at zero; since the mean is usually 0, that makes is a half-Cauchy.</p>
<p>Kruschke set the upper bound for his <span class="math inline">\(\sigma_y\)</span> to 10 times the standard deviation of the criterion variable. The tails of the half-Cauchy are sufficiently fat that, in practice, I’ve found it doesn’t matter much what you set the <span class="math inline">\(SD\)</span> of its prior to. One is often a sensible default for reasonably-scaled data. But if we want to take a more principled approach, we can set it to the size of the criterion’s <span class="math inline">\(SD\)</span> or perhaps even 10 times that.</p>
<p>Kruschke suggested using a gamma on <span class="math inline">\(\sigma_\beta\)</span>, which is a sensible alternative to half-Cauchy often used within the Stan universe. Especially in situations in which you would like to (a) keep the variance parameter above zero, but (b) still allow it to be arbitrarily close to zero, and also (c) let the likelihood dominate the posterior, the Stan team recommends the gamma(2, 0) prior, based on the <a href="http://www.stat.columbia.edu/~gelman/research/published/chung_etal_Pmetrika2013.pdf">paper by Chung and colleagues</a>. But you should note that I don’t mean a literal 0 for the second parameter in the gamma distribution, but rather some small value like 0.1 or so. This is all clarified in <a href="http://www.stat.columbia.edu/~gelman/research/published/chung_etal_Pmetrika2013.pdf">Chung et al</a>. Here’s what gamma(2, 0.1) looks like.</p>
<div class="sourceCode" id="cb1567"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1567-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">110</span>, <span class="dt">by =</span> <span class="fl">.1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1567-2" data-line-number="2"><span class="st">  </span></a>
<a class="sourceLine" id="cb1567-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> <span class="kw">dgamma</span>(x, <span class="dv">2</span>, <span class="fl">.1</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb1567-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1567-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1567-6" data-line-number="6"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">100</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1567-7" data-line-number="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-7-1.png" /><!-- --></p>
<p>And if you’d like that prior be even less informative, just reduce it to like gamma(2, 0.01) or so. Kruschke goes further to recommend “the shape and rate parameters of the gamma distribution are set so its mode is <code>sd(y)/2</code> and its standard deviation is <code>2*sd(y)</code>, using the function <code>gammaShRaFromModeSD</code> explained in Section 9.2.2.” (pp. 560–561). Let’s make that function.</p>
<div class="sourceCode" id="cb1568"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1568-1" data-line-number="1">gamma_a_b_from_omega_sigma &lt;-<span class="st"> </span><span class="cf">function</span>(mode, sd) {</a>
<a class="sourceLine" id="cb1568-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb1568-3" data-line-number="3">  <span class="cf">if</span> (mode <span class="op">&lt;=</span><span class="st"> </span><span class="dv">0</span>) <span class="kw">stop</span>(<span class="st">&quot;mode must be &gt; 0&quot;</span>)</a>
<a class="sourceLine" id="cb1568-4" data-line-number="4">  <span class="cf">if</span> (sd   <span class="op">&lt;=</span><span class="st"> </span><span class="dv">0</span>) <span class="kw">stop</span>(<span class="st">&quot;sd must be &gt; 0&quot;</span>)</a>
<a class="sourceLine" id="cb1568-5" data-line-number="5">  rate &lt;-<span class="st"> </span>(mode <span class="op">+</span><span class="st"> </span><span class="kw">sqrt</span>(mode<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>sd<span class="op">^</span><span class="dv">2</span>)) <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1568-6" data-line-number="6">  shape &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>mode <span class="op">*</span><span class="st"> </span>rate</a>
<a class="sourceLine" id="cb1568-7" data-line-number="7">  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">shape =</span> shape, <span class="dt">rate =</span> rate))</a>
<a class="sourceLine" id="cb1568-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb1568-9" data-line-number="9">}</a></code></pre></div>
<p>So in the case of standardized data where <code>sd(1)</code> = 1, we’d use our <code>gamma_a_b_from_omega_sigma()</code> function like so.</p>
<div class="sourceCode" id="cb1569"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1569-1" data-line-number="1">sd_y  &lt;-<span class="st"> </span><span class="dv">1</span> </a>
<a class="sourceLine" id="cb1569-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1569-3" data-line-number="3">omega &lt;-<span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb1569-4" data-line-number="4">sigma &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y</a>
<a class="sourceLine" id="cb1569-5" data-line-number="5"></a>
<a class="sourceLine" id="cb1569-6" data-line-number="6">(s_r &lt;-<span class="st"> </span><span class="kw">gamma_a_b_from_omega_sigma</span>(<span class="dt">mode =</span> omega, <span class="dt">sd =</span> sigma))</a></code></pre></div>
<pre><code>## $shape
## [1] 1.283196
## 
## $rate
## [1] 0.5663911</code></pre>
<p>And that produces the following gamma distribution.</p>
<div class="sourceCode" id="cb1571"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1571-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">50</span>, <span class="dt">by =</span> <span class="fl">.01</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1571-2" data-line-number="2"><span class="st">  </span></a>
<a class="sourceLine" id="cb1571-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> <span class="kw">dgamma</span>(x, s_r<span class="op">$</span>shape, s_r<span class="op">$</span>rate))) <span class="op">+</span></a>
<a class="sourceLine" id="cb1571-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1571-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1571-6" data-line-number="6"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1571-7" data-line-number="7"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">20</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1571-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-10-1.png" /><!-- --></p>
<p>In the parameter space that matters, from zero to one, that gamma is pretty noninformative. It peaks between the two, slopes very gently rightward, but has the nice steep slope on the left keeping the estimates off the zero boundary. And even though that right slope is very gentle given the scale of the data, it’s aggressive enough that it should keep the MCMC chains from spending a lot of time in ridiculous parts of the parameter space. I.e., when working with finite numbers of iterations, we want our MCMC chains wasting exactly zero iterations investigating what the density might be for <span class="math inline">\(\sigma_\beta \approx 1e10\)</span> for standardized data.</p>
</div>
<div id="example-sex-and-death." class="section level3">
<h3><span class="header-section-number">19.3.2</span> Example: Sex and death.</h3>
<p>Let’s load and <code>glimpse()</code> at <a href="http://jse.amstat.org/v2n1/datasets.hanley.html">Hanley and Shapiro’s (1994)</a> fruit fly data.</p>
<div class="sourceCode" id="cb1572"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1572-1" data-line-number="1">my_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data.R/FruitflyDataReduced.csv&quot;</span>)</a>
<a class="sourceLine" id="cb1572-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1572-3" data-line-number="3"><span class="kw">glimpse</span>(my_data)</a></code></pre></div>
<pre><code>## Observations: 125
## Variables: 3
## $ Longevity       &lt;dbl&gt; 35, 37, 49, 46, 63, 39, 46, 56, 63, 65, 56, 65, 70, 63, 65, 70, 77, 81, 8…
## $ CompanionNumber &lt;chr&gt; &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnan…
## $ Thorax          &lt;dbl&gt; 0.64, 0.68, 0.68, 0.72, 0.72, 0.76, 0.76, 0.76, 0.76, 0.76, 0.80, 0.80, 0…</code></pre>
<p>We can use <code>geom_density_ridges()</code> to help get a sense of how our criterion <code>Longevity</code> is distributed across groups of <code>CompanionNumber</code>.</p>
<div class="sourceCode" id="cb1574"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1574-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1574-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(CompanionNumber) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1574-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">group_mean =</span> <span class="kw">mean</span>(Longevity)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1574-4" data-line-number="4"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1574-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">CompanionNumber =</span> <span class="kw">fct_reorder</span>(CompanionNumber, group_mean)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1574-6" data-line-number="6"><span class="st">  </span></a>
<a class="sourceLine" id="cb1574-7" data-line-number="7"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Longevity, <span class="dt">y =</span> CompanionNumber, <span class="dt">fill =</span> group_mean)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1574-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_density_ridges</span>(<span class="dt">scale =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1574-9" data-line-number="9"><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">option =</span> <span class="st">&quot;A&quot;</span>, <span class="dt">end =</span> <span class="fl">.92</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1574-10" data-line-number="10"><span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1574-11" data-line-number="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid      =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1574-12" data-line-number="12">        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,</a>
<a class="sourceLine" id="cb1574-13" data-line-number="13">        <span class="dt">axis.ticks.y    =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1574-14" data-line-number="14">        <span class="dt">axis.text.y     =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-12-1.png" /><!-- --></p>
<p>Let’s fire up <strong>brms</strong>.</p>
<div class="sourceCode" id="cb1575"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1575-1" data-line-number="1"><span class="kw">library</span>(brms)</a></code></pre></div>
<p>We’ll want to do the preparatory work to define our <code>stanvars</code>.</p>
<div class="sourceCode" id="cb1576"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1576-1" data-line-number="1">(mean_y &lt;-<span class="st"> </span><span class="kw">mean</span>(my_data<span class="op">$</span>Longevity))</a></code></pre></div>
<pre><code>## [1] 57.44</code></pre>
<div class="sourceCode" id="cb1578"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1578-1" data-line-number="1">(sd_y &lt;-<span class="st"> </span><span class="kw">sd</span>(my_data<span class="op">$</span>Longevity))</a></code></pre></div>
<pre><code>## [1] 17.56389</code></pre>
<div class="sourceCode" id="cb1580"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1580-1" data-line-number="1">omega &lt;-<span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb1580-2" data-line-number="2">sigma &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y</a>
<a class="sourceLine" id="cb1580-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1580-4" data-line-number="4">(s_r &lt;-<span class="st"> </span><span class="kw">gamma_a_b_from_omega_sigma</span>(<span class="dt">mode =</span> omega, <span class="dt">sd =</span> sigma))</a></code></pre></div>
<pre><code>## $shape
## [1] 1.283196
## 
## $rate
## [1] 0.03224747</code></pre>
<p>With the prep work is done, here are our <code>stanvars</code>.</p>
<div class="sourceCode" id="cb1582"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1582-1" data-line-number="1">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1582-2" data-line-number="2"><span class="st">  </span><span class="kw">stanvar</span>(mean_y,    <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1582-3" data-line-number="3"><span class="st">  </span><span class="kw">stanvar</span>(sd_y,      <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1582-4" data-line-number="4"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>shape, <span class="dt">name =</span> <span class="st">&quot;alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1582-5" data-line-number="5"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>rate,  <span class="dt">name =</span> <span class="st">&quot;beta&quot;</span>)</a></code></pre></div>
<p>Now fit the model, our hierarchical Bayesian alternative to an ANOVA.</p>
<div class="sourceCode" id="cb1583"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1583-1" data-line-number="1">fit1 &lt;-</a>
<a class="sourceLine" id="cb1583-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1583-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1583-4" data-line-number="4">      Longevity <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>CompanionNumber),</a>
<a class="sourceLine" id="cb1583-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1583-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">gamma</span>(alpha, beta), <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1583-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, sd_y), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1583-8" data-line-number="8">      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1583-9" data-line-number="9">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1583-10" data-line-number="10">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>),</a>
<a class="sourceLine" id="cb1583-11" data-line-number="11">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>Much like Kruschke’s JAGS chains, our <strong>brms</strong> chains are well behaved.</p>
<div class="sourceCode" id="cb1584"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1584-1" data-line-number="1"><span class="kw">plot</span>(fit1)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-16-1.png" /><!-- --></p>
<p>Also like Kruschke, our chains appear moderately autocorrelated.</p>
<div class="sourceCode" id="cb1585"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1585-1" data-line-number="1">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit1, <span class="dt">add_chain =</span> T)</a>
<a class="sourceLine" id="cb1585-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1585-3" data-line-number="3"><span class="kw">library</span>(bayesplot)</a>
<a class="sourceLine" id="cb1585-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1585-5" data-line-number="5"><span class="kw">theme_set</span>(<span class="kw">theme_gray</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb1585-6" data-line-number="6"><span class="st">            </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()))</a>
<a class="sourceLine" id="cb1585-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1585-8" data-line-number="8"><span class="kw">mcmc_acf</span>(post, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b_Intercept&quot;</span>, <span class="st">&quot;sd_CompanionNumber__Intercept&quot;</span>, <span class="st">&quot;sigma&quot;</span>), <span class="dt">lags =</span> <span class="dv">10</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-17-1.png" /><!-- --></p>
<p>Here’s the model summary.</p>
<div class="sourceCode" id="cb1586"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1586-1" data-line-number="1"><span class="kw">print</span>(fit1)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Longevity ~ 1 + (1 | CompanionNumber) 
##    Data: my_data (Number of observations: 125) 
## Samples: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Group-Level Effects: 
## ~CompanionNumber (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    15.03      8.04     6.24    36.42 1.00     2311     3554
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    57.59      7.51    43.03    73.39 1.00     2505     3147
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    14.93      0.97    13.22    16.98 1.00     5824     5872
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>With the <code>ranef()</code> function, we can get the summaries of the group-specific deflections.</p>
<div class="sourceCode" id="cb1588"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1588-1" data-line-number="1"><span class="kw">ranef</span>(fit1)</a></code></pre></div>
<pre><code>## $CompanionNumber
## , , Intercept
## 
##              Estimate Est.Error       Q2.5     Q97.5
## None0       5.5794036  7.818598 -10.238748 20.800280
## Pregnant1   6.7890585  7.816206  -9.059062 22.125098
## Pregnant8   5.3766714  7.839145 -10.687290 20.717351
## Virgin1    -0.7754446  7.856840 -17.380637 14.139118
## Virgin8   -17.7177658  7.939150 -34.940259 -3.181382</code></pre>
<p>And with the <code>coef()</code> function, we can get those same group-level summaries in a non-deflection metric.</p>
<div class="sourceCode" id="cb1590"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1590-1" data-line-number="1"><span class="kw">coef</span>(fit1)</a></code></pre></div>
<pre><code>## $CompanionNumber
## , , Intercept
## 
##           Estimate Est.Error     Q2.5    Q97.5
## None0     63.17168  2.921267 57.43048 68.80815
## Pregnant1 64.38133  2.927249 58.70815 70.16666
## Pregnant8 62.96894  2.920661 57.21388 68.65320
## Virgin1   56.81683  2.934214 51.12637 62.52715
## Virgin8   39.87451  3.091971 33.85827 46.00826</code></pre>
<p>Those are all estimates of the group-specific means. Since it wasn’t modeled, all have the same parameter estimates for <span class="math inline">\(\sigma_y\)</span>.</p>
<div class="sourceCode" id="cb1592"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1592-1" data-line-number="1"><span class="kw">posterior_summary</span>(fit1)[<span class="st">&quot;sigma&quot;</span>, ]</a></code></pre></div>
<pre><code>##   Estimate  Est.Error       Q2.5      Q97.5 
## 14.9346100  0.9662639 13.2174322 16.9832791</code></pre>
<p>To prepare for our version of the top panel of Figure 19.3, we’ll use <code>sample_n()</code> to randomly sample from the posterior draws.</p>
<div class="sourceCode" id="cb1594"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1594-1" data-line-number="1"><span class="co"># how many random draws from the posterior would you like?</span></a>
<a class="sourceLine" id="cb1594-2" data-line-number="2">n_draws &lt;-<span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb1594-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1594-4" data-line-number="4"><span class="kw">set.seed</span>(<span class="dv">19</span>)</a>
<a class="sourceLine" id="cb1594-5" data-line-number="5">post_draws &lt;-</a>
<a class="sourceLine" id="cb1594-6" data-line-number="6"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1594-7" data-line-number="7"><span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> n_draws, <span class="dt">replace =</span> F)</a>
<a class="sourceLine" id="cb1594-8" data-line-number="8"></a>
<a class="sourceLine" id="cb1594-9" data-line-number="9"><span class="kw">glimpse</span>(post_draws)</a></code></pre></div>
<pre><code>## Observations: 20
## Variables: 12
## $ b_Intercept                              &lt;dbl&gt; 51.37055, 42.46025, 58.43885, 56.01002, 48.52338…
## $ sd_CompanionNumber__Intercept            &lt;dbl&gt; 16.262790, 17.931260, 10.294159, 14.104043, 27.4…
## $ sigma                                    &lt;dbl&gt; 13.71128, 13.91828, 16.24448, 14.03107, 16.30758…
## $ Intercept                                &lt;dbl&gt; 51.37055, 42.46025, 58.43885, 56.01002, 48.52338…
## $ `r_CompanionNumber[None0,Intercept]`     &lt;dbl&gt; 14.6642542, 18.4782479, 0.3908729, 6.5999786, 14…
## $ `r_CompanionNumber[Pregnant1,Intercept]` &lt;dbl&gt; 12.207309, 23.184843, 9.985389, 15.058426, 19.47…
## $ `r_CompanionNumber[Pregnant8,Intercept]` &lt;dbl&gt; 9.7663362, 15.5679928, 7.3901457, 7.7165676, 15.…
## $ `r_CompanionNumber[Virgin1,Intercept]`   &lt;dbl&gt; 6.04861233, 15.33460132, -3.33245392, 0.58641261…
## $ `r_CompanionNumber[Virgin8,Intercept]`   &lt;dbl&gt; -12.425826, -3.181759, -14.673815, -15.790020, -…
## $ lp__                                     &lt;dbl&gt; -526.6386, -528.8238, -531.0766, -528.5373, -526…
## $ chain                                    &lt;fct&gt; 3, 4, 2, 3, 1, 2, 2, 4, 1, 4, 4, 4, 2, 4, 2, 2, …
## $ iter                                     &lt;dbl&gt; 2677, 1910, 2483, 2557, 3745, 2803, 3677, 2255, …</code></pre>
<p>Before we make our version of the top panel, let’s make a corresponding plot of the fixed intercept, the grand mean. The most important lines in the code, below are the ones where we used <code>stat_function()</code> within <code>mapply()</code>.</p>
<div class="sourceCode" id="cb1596"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1596-1" data-line-number="1"><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">150</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1596-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1596-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1596-4" data-line-number="4"><span class="st">  </span><span class="kw">mapply</span>(<span class="cf">function</span>(mean, sd) {</a>
<a class="sourceLine" id="cb1596-5" data-line-number="5">    <span class="kw">stat_function</span>(<span class="dt">fun   =</span> dnorm, </a>
<a class="sourceLine" id="cb1596-6" data-line-number="6">                  <span class="dt">args  =</span> <span class="kw">list</span>(<span class="dt">mean =</span> mean, <span class="dt">sd =</span> sd), </a>
<a class="sourceLine" id="cb1596-7" data-line-number="7">                  <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, </a>
<a class="sourceLine" id="cb1596-8" data-line-number="8">                  <span class="dt">size  =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,</a>
<a class="sourceLine" id="cb1596-9" data-line-number="9">                  <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>)</a>
<a class="sourceLine" id="cb1596-10" data-line-number="10">    }, </a>
<a class="sourceLine" id="cb1596-11" data-line-number="11">    <span class="co"># enter means and standard deviations here</span></a>
<a class="sourceLine" id="cb1596-12" data-line-number="12">    <span class="dt">mean =</span> post_draws[, <span class="st">&quot;b_Intercept&quot;</span>],</a>
<a class="sourceLine" id="cb1596-13" data-line-number="13">    <span class="dt">sd   =</span> post_draws[, <span class="st">&quot;sigma&quot;</span>]</a>
<a class="sourceLine" id="cb1596-14" data-line-number="14">    ) <span class="op">+</span></a>
<a class="sourceLine" id="cb1596-15" data-line-number="15"><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">data =</span> my_data, <span class="kw">aes</span>(<span class="dt">x =</span> Longevity, <span class="dt">y =</span> <span class="fl">-0.001</span>),</a>
<a class="sourceLine" id="cb1596-16" data-line-number="16">              <span class="dt">height =</span> <span class="fl">.001</span>, </a>
<a class="sourceLine" id="cb1596-17" data-line-number="17">              <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1596-18" data-line-number="18"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;Longevity&quot;</span>, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">100</span>, <span class="dt">by =</span> <span class="dv">25</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1596-19" data-line-number="19"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1596-20" data-line-number="20"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">110</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1596-21" data-line-number="21"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title    =</span> <span class="st">&quot;Posterior Predictive Distribution&quot;</span>,</a>
<a class="sourceLine" id="cb1596-22" data-line-number="22">       <span class="dt">subtitle =</span> <span class="st">&quot;The jittered dots are the ungrouped Longevity data. The</span><span class="ch">\n</span><span class="st">Gaussians are posterior draws depicting the overall</span><span class="ch">\n</span><span class="st">distribution, the grand mean.&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-23-1.png" /><!-- --></p>
<p>Unfortunately, we can’t extend our <code>mapply(stat_function())</code> method to the group-level estimates. To my knowledge, there isn’t a way to show the group estimates at different spots along the y-axis. And our <code>mapply(stat_function())</code> approach has other limitations, too. Happily, we have some great alternatives. To use them, we’ll need a little help from <strong>tidybayes</strong>.</p>
<div class="sourceCode" id="cb1597"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1597-1" data-line-number="1"><span class="kw">library</span>(tidybayes)</a></code></pre></div>
<p>For the first part, we’ll take <code>tidybayes::add_fitted_draws()</code> for a whirl.</p>
<div class="sourceCode" id="cb1598"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1598-1" data-line-number="1">densities &lt;-</a>
<a class="sourceLine" id="cb1598-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1598-3" data-line-number="3"><span class="st">  </span><span class="kw">distinct</span>(CompanionNumber) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1598-4" data-line-number="4"><span class="st">  </span><span class="kw">add_fitted_draws</span>(fit1, <span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">seed =</span> <span class="dv">19</span>, <span class="dt">dpar =</span> <span class="kw">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma&quot;</span>))</a>
<a class="sourceLine" id="cb1598-5" data-line-number="5"></a>
<a class="sourceLine" id="cb1598-6" data-line-number="6"><span class="kw">glimpse</span>(densities)</a></code></pre></div>
<pre><code>## Observations: 100
## Variables: 8
## Groups: CompanionNumber, .row [5]
## $ CompanionNumber &lt;chr&gt; &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnan…
## $ .row            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2…
## $ .chain          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .iteration      &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .draw           &lt;int&gt; 1115, 2133, 2685, 2745, 4031, 4436, 4483, 4803, 5677, 5784, 7173, 7557, 7…
## $ .value          &lt;dbl&gt; 60.74737, 63.17496, 59.68698, 63.73562, 60.19609, 59.72371, 65.82900, 61.…
## $ mu              &lt;dbl&gt; 60.74737, 63.17496, 59.68698, 63.73562, 60.19609, 59.72371, 65.82900, 61.…
## $ sigma           &lt;dbl&gt; 15.11354, 14.27563, 16.01779, 16.30758, 14.23716, 15.40663, 16.24448, 14.…</code></pre>
<p>With the first two lines, we made a <span class="math inline">\(5 \times 1\)</span> tibble containing the five levels of the experimental grouping variable, <code>CompanionNumber</code>. The <a href="https://cran.r-project.org/web/packages/tidybayes/tidybayes.pdf"><code>add_fitted_draws()</code></a> function comes from <strong>tidybayes</strong>. The first argument of the <code>add_fitted_draws()</code> is <code>newdata</code>, which works much like it does in <code>brms::fitted()</code>; it took our <span class="math inline">\(5 \times 1\)</span> tibble. The next argument took our <strong>brms</strong> model fit, <code>fit1</code>. With the <code>n</code> argument, we indicated we just wanted 20 random draws from the posterior. The <code>seed</code> argument makes those random draws reproducible. With <code>dpar</code>, we requested distributional regression parameters in the output. In our case, those were the <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> values for each level of <code>CompanionNumber</code>. Since we took 20 draws across 5 groups, we ended up with a 100-row tibble.</p>
<p>The next steps are a direct extension of the method we used to make our Gaussians for our version of Figure 19.1.</p>
<div class="sourceCode" id="cb1600"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1600-1" data-line-number="1">densities &lt;-</a>
<a class="sourceLine" id="cb1600-2" data-line-number="2"><span class="st">  </span>densities <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1600-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ll        =</span> <span class="kw">qnorm</span>(.<span class="dv">025</span>, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma),</a>
<a class="sourceLine" id="cb1600-4" data-line-number="4">         <span class="dt">ul        =</span> <span class="kw">qnorm</span>(.<span class="dv">975</span>, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1600-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Longevity =</span> <span class="kw">map2</span>(ll, ul, seq, <span class="dt">length.out =</span> <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1600-6" data-line-number="6"><span class="st">  </span><span class="kw">unnest</span>(Longevity) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1600-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density   =</span> <span class="kw">dnorm</span>(Longevity, mu, sigma))</a>
<a class="sourceLine" id="cb1600-8" data-line-number="8"></a>
<a class="sourceLine" id="cb1600-9" data-line-number="9"><span class="kw">glimpse</span>(densities)</a></code></pre></div>
<pre><code>## Observations: 10,000
## Variables: 12
## Groups: CompanionNumber, .row [5]
## $ CompanionNumber &lt;chr&gt; &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnan…
## $ .row            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ .chain          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .iteration      &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .draw           &lt;int&gt; 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1…
## $ .value          &lt;dbl&gt; 60.74737, 60.74737, 60.74737, 60.74737, 60.74737, 60.74737, 60.74737, 60.…
## $ mu              &lt;dbl&gt; 60.74737, 60.74737, 60.74737, 60.74737, 60.74737, 60.74737, 60.74737, 60.…
## $ sigma           &lt;dbl&gt; 15.11354, 15.11354, 15.11354, 15.11354, 15.11354, 15.11354, 15.11354, 15.…
## $ ll              &lt;dbl&gt; 31.12538, 31.12538, 31.12538, 31.12538, 31.12538, 31.12538, 31.12538, 31.…
## $ ul              &lt;dbl&gt; 90.36936, 90.36936, 90.36936, 90.36936, 90.36936, 90.36936, 90.36936, 90.…
## $ Longevity       &lt;dbl&gt; 31.12538, 31.72381, 32.32223, 32.92066, 33.51908, 34.11750, 34.71593, 35.…
## $ density         &lt;dbl&gt; 0.003867068, 0.004175850, 0.004502224, 0.004846502, 0.005208934, 0.005589…</code></pre>
<p>If you look at the code we used to make <code>ll</code> and <code>ul</code>, you’ll see we used 95% intervals, this time. Our second <code>mutate()</code> function is basically the same. After unnesting the tibble, we just needed to plug in the <code>Longevity</code>, <code>mu</code>, and <code>sigma</code> values into the <code>dnorm()</code> function to compute the corresponding density values.</p>
<div class="sourceCode" id="cb1602"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1602-1" data-line-number="1">densities <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1602-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Longevity, <span class="dt">y =</span> CompanionNumber)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1602-3" data-line-number="3"><span class="st">  </span><span class="co"># here we make our density lines</span></a>
<a class="sourceLine" id="cb1602-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ridgeline</span>(<span class="kw">aes</span>(<span class="dt">height =</span> density, <span class="dt">group =</span> <span class="kw">interaction</span>(CompanionNumber, .draw)),</a>
<a class="sourceLine" id="cb1602-5" data-line-number="5">                 <span class="dt">fill =</span> <span class="ot">NA</span>, <span class="dt">color =</span> <span class="kw">adjustcolor</span>(<span class="st">&quot;grey50&quot;</span>, <span class="dt">alpha.f =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>),</a>
<a class="sourceLine" id="cb1602-6" data-line-number="6">                 <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">scale =</span> <span class="dv">25</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1602-7" data-line-number="7"><span class="st">  </span><span class="co"># the original data with little jitter thrown in</span></a>
<a class="sourceLine" id="cb1602-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1602-9" data-line-number="9">              <span class="dt">height =</span> <span class="fl">.04</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1602-10" data-line-number="10"><span class="st">  </span><span class="co"># pretty much everything below this line is aesthetic fluff</span></a>
<a class="sourceLine" id="cb1602-11" data-line-number="11"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">100</span>, <span class="dt">by =</span> <span class="dv">25</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1602-12" data-line-number="12"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">110</span>,</a>
<a class="sourceLine" id="cb1602-13" data-line-number="13">                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.25</span>, <span class="fl">5.25</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1602-14" data-line-number="14"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Data with Posterior Predictive Distrib.&quot;</span>, </a>
<a class="sourceLine" id="cb1602-15" data-line-number="15">       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1602-16" data-line-number="16"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1602-17" data-line-number="17">        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-27-1.png" /><!-- --></p>
<p>Do be aware that when you use this method, you may have to fiddle around with the <code>geom_ridgeline()</code> <code>scale</code> argument to get the Gaussian’s heights on reasonable-looking relative heights. Stick in different numbers to get a sense of what I mean. I also find that I’m often not a fan of the way the spacing on the y axis ends up with default <code>geom_ridgeline()</code>. It’s easy to overcome this with a little <code>ylim</code> fiddling.</p>
<p>To return to the more substantive interpretation, the top panel of</p>
<blockquote>
<p>Figure 19.3 suggests that the normal distributions with homogeneous variances appear to be reasonable descriptions of the data. There are no dramatic outliers relative to the posterior predicted curves, and the spread of the data within each group appears to be reasonably matched by the width of the posterior normal curves. (Be careful when making visual assessments of homogeneity of variance because the visual spread of the data depends on the sample size; for a reminder see the [see the right panel of Figure 17.1, p. 478].) The range of credible group means, indicated by the peaks of the normal curves, suggests that the group Virgin8 is clearly lower than the others, and the group Virgin1 might be lower than the controls. To find out for sure, we need to examine the differences of group means, which we do in the next section. (p. 564)</p>
</blockquote>
<p>For clarity, the “see the right panel of Figure 17.1, p. 478” part was changed following <a href="https://sites.google.com/site/doingbayesiandataanalysis/corrigenda">Kruschke’s Corrigenda</a>.</p>
</div>
<div id="contrasts." class="section level3">
<h3><span class="header-section-number">19.3.3</span> Contrasts.</h3>
<blockquote>
<p>It is straight forward to examine the posterior distribution of credible differences. Every step in the MCMC chain provides a combination of group means that are jointly credible, given the data. Therefore, every step in the MCMC chain provides a credible difference between groups…</p>
<p>To construct the credible differences of group 1 and group 2, at every step in the MCMC chain we compute</p>
<p><span class="math display">\[\begin{align*}
\mu_1 - \mu_2 &amp; =  (\beta_0 + \beta_1) - (\beta_0 + \beta_2) \\
              &amp; =  (+1) \cdot \beta_1 + (-1) \cdot \beta_2
\end{align*}\]</span></p>
<p>In other words, the baseline cancels out of the calculation, and the difference is a sum of weighted group deflections. Notice that the weights sum to zero. To construct the credible differences of the average of groups 1-3 and the average of groups 4-5, at every step in the MCMC chain we compute</p>
<p><span class="math display">\[\begin{align*}
(\mu_1 + \mu_2 + \mu_3) / 3 - (\mu_4 + \mu_5) / 2 &amp; = ((\beta_0 + \beta_1)  + (\beta_0 + \beta_2)  + (\beta_0 + \beta_3) ) / 3 - ((\beta_0 + \beta_4) + (\beta_0 + \beta_5) ) / 2 \\
&amp; = (\beta_1 + \beta_2 + \beta_3) / 3 - (\beta_4 + \beta_5) / 2 \\
&amp; = (+ 1/3) \cdot \beta_1 + (+ 1/3) \cdot \beta_2 + (+ 1/3) \cdot \beta_3 + (- 1/2) \cdot \beta_4 + (- 1/2) \cdot \beta_5
\end{align*}\]</span></p>
<p>Again, the difference is a sum of weighted group deflections. The coefficients on the group deflections have the properties that they sum to zero, with the positive coefficients summing to +1 and the negative coefficients summing to −1. Such a combination is called a contrast. The differences can also be expressed in terms of effect size, by dividing the difference by <span class="math inline">\(\sigma_y\)</span> at each step in the chain. (pp. 565–566)</p>
</blockquote>
<p>To warm up, here’s how to compute the first contrast shown in the lower portion of Kruschke’s Figure 19.3–the contrast between the two pregnant conditions and the none-control condition.</p>
<div class="sourceCode" id="cb1603"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1603-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1603-2" data-line-number="2"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">c =</span> (<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1603-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb1603-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> c)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1603-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1603-6" data-line-number="6">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1603-7" data-line-number="7"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1603-8" data-line-number="8">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1603-9" data-line-number="9"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1603-10" data-line-number="10"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Pregnant1.Pregnant8 vs None0&quot;</span>,</a>
<a class="sourceLine" id="cb1603-11" data-line-number="11">       <span class="dt">x =</span> <span class="st">&quot;Difference&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-28-1.png" /><!-- --></p>
<p>In case you were curious, here are the HMC-based posterior mode and 95% HDIs.</p>
<div class="sourceCode" id="cb1604"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1604-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1604-2" data-line-number="2"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">difference =</span> (<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1604-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb1604-4" data-line-number="4"><span class="st">  </span><span class="kw">mode_hdi</span>(difference)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 6
##   difference .lower .upper .width .point .interval
##        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1       1.67  -6.83   9.07   0.95 mode   hdi</code></pre>
<p>Little difference, there. Now let’s quantify the same contrast as an effect size.</p>
<div class="sourceCode" id="cb1606"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1606-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1606-2" data-line-number="2"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">es =</span> ((<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span>sigma) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1606-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb1606-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> es)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1606-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1606-6" data-line-number="6">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1606-7" data-line-number="7"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1606-8" data-line-number="8">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1606-9" data-line-number="9"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1606-10" data-line-number="10"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Pregnant1.Pregnant8 vs None0&quot;</span>,</a>
<a class="sourceLine" id="cb1606-11" data-line-number="11">       <span class="dt">x =</span> <span class="st">&quot;Effect Size&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-30-1.png" /><!-- --></p>
<p>Tiny.</p>
<p>Okay, now let’s do the rest in bulk. First we’ll do the difference scores.</p>
<div class="sourceCode" id="cb1607"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1607-1" data-line-number="1">differences &lt;-</a>
<a class="sourceLine" id="cb1607-2" data-line-number="2"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1607-3" data-line-number="3"><span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">Pregnant1.Pregnant8.None0 vs Virgin1</span><span class="st">`</span> =<span class="st"> </span>(<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">3</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin1,Intercept]</span><span class="st">`</span>,</a>
<a class="sourceLine" id="cb1607-4" data-line-number="4">            </a>
<a class="sourceLine" id="cb1607-5" data-line-number="5">            <span class="st">`</span><span class="dt">Virgin1 vs Virgin8</span><span class="st">`</span> =<span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin1,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin8,Intercept]</span><span class="st">`</span>,</a>
<a class="sourceLine" id="cb1607-6" data-line-number="6">            </a>
<a class="sourceLine" id="cb1607-7" data-line-number="7">            <span class="st">`</span><span class="dt">Pregnant1.Pregnant8.None0 vs Virgin1.Virgin8</span><span class="st">`</span> =<span class="st"> </span>(<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">3</span> <span class="op">-</span><span class="st"> </span>(<span class="st">`</span><span class="dt">r_CompanionNumber[Virgin1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin8,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1607-8" data-line-number="8"></a>
<a class="sourceLine" id="cb1607-9" data-line-number="9">differences <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1607-10" data-line-number="10"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1607-11" data-line-number="11"><span class="st">  </span></a>
<a class="sourceLine" id="cb1607-12" data-line-number="12"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1607-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1607-14" data-line-number="14">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1607-15" data-line-number="15"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1607-16" data-line-number="16">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1607-17" data-line-number="17"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1607-18" data-line-number="18"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Difference&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1607-19" data-line-number="19"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-31-1.png" /><!-- --></p>
<p>Because we save our data wrangling labor from above as <code>differences</code>, it won’t take much more effort to compute and plot the corresponding effect sizes as displayed in the bottom row of Figure 19.3.</p>
<div class="sourceCode" id="cb1608"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1608-1" data-line-number="1">differences <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1608-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate_all</span>(<span class="dt">.funs =</span> <span class="op">~</span><span class="st"> </span>. <span class="op">/</span><span class="st"> </span>post<span class="op">$</span>sigma) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1608-3" data-line-number="3"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1608-4" data-line-number="4"><span class="st">  </span></a>
<a class="sourceLine" id="cb1608-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1608-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1608-7" data-line-number="7">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1608-8" data-line-number="8"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1608-9" data-line-number="9">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1608-10" data-line-number="10"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1608-11" data-line-number="11"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Effect Size&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1608-12" data-line-number="12"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-32-1.png" /><!-- --></p>
<blockquote>
<p>In traditional ANOVA, analysts often perform a so-called omnibus test that asks whether it is plausible that all the groups are simultaneously exactly equal. I find that the omnibus test is rarely meaningful, however…. In the hierarchical Bayesian estimation used here, there is no direct equivalent to an omnibus test in ANOVA, and the emphasis is on examining all the meaningful contrasts. (p. 567)</p>
</blockquote>
<p>Speaking of all meaningful contrasts, if you’d like to make all pairwise comparisons in a hierarchical model of this form, <a href="https://mjskay.github.io/tidybayes/articles/tidy-brms.html"><strong>tidybayes</strong> offers a convenient way to do so</a>. Here we’ll demonstrate with <code>geom_halfeyeh()</code>.</p>
<div class="sourceCode" id="cb1609"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1609-1" data-line-number="1">fit1 <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1609-2" data-line-number="2"><span class="st">  </span><span class="co"># these two lines are where the magic is at</span></a>
<a class="sourceLine" id="cb1609-3" data-line-number="3"><span class="st">  </span><span class="kw">spread_draws</span>(r_CompanionNumber[CompanionNumber,]) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1609-4" data-line-number="4"><span class="st">  </span><span class="kw">compare_levels</span>(r_CompanionNumber, <span class="dt">by =</span> CompanionNumber) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1609-5" data-line-number="5"><span class="st">  </span></a>
<a class="sourceLine" id="cb1609-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> r_CompanionNumber, <span class="dt">y =</span> CompanionNumber)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1609-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1609-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1609-9" data-line-number="9"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Contrast&quot;</span>,</a>
<a class="sourceLine" id="cb1609-10" data-line-number="10">       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1609-11" data-line-number="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1609-12" data-line-number="12">        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-33-1.png" /><!-- --></p>
<p>But back to that omnibus test notion. If you really wanted to, I suppose one rough analogue would be to use information criteria to compare the hierarchical model to one that includes a single intercept with no group-level deflections. Here’s what the simpler model would look like.</p>
<div class="sourceCode" id="cb1610"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1610-1" data-line-number="1">fit1_without_deflections &lt;-</a>
<a class="sourceLine" id="cb1610-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1610-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1610-4" data-line-number="4">      Longevity <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb1610-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1610-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, sd_y), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1610-7" data-line-number="7">      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1610-8" data-line-number="8">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1610-9" data-line-number="9">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>Here’s the model summary.</p>
<div class="sourceCode" id="cb1611"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1611-1" data-line-number="1"><span class="kw">print</span>(fit1_without_deflections)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Longevity ~ 1 
##    Data: my_data (Number of observations: 125) 
## Samples: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    57.42      1.59    54.32    60.56 1.00     9746     7638
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    17.69      1.16    15.56    20.12 1.00     7742     7149
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Here are their LOO values and their difference score.</p>
<div class="sourceCode" id="cb1613"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1613-1" data-line-number="1">fit1 &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit1, <span class="dt">criterion =</span> <span class="st">&quot;loo&quot;</span>)</a>
<a class="sourceLine" id="cb1613-2" data-line-number="2">fit1_without_deflections &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(fit1_without_deflections, <span class="dt">criterion =</span> <span class="st">&quot;loo&quot;</span>)</a>
<a class="sourceLine" id="cb1613-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1613-4" data-line-number="4"><span class="kw">loo_compare</span>(fit1, fit1_without_deflections) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1613-5" data-line-number="5"><span class="st">  </span><span class="kw">print</span>(<span class="dt">simplify =</span> F)</a></code></pre></div>
<pre><code>##                          elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic  se_looic
## fit1                        0.0       0.0  -517.7      6.9         5.5    0.6   1035.4   13.8  
## fit1_without_deflections  -19.4       5.3  -537.1      7.1         1.8    0.3   1074.1   14.1</code></pre>
<p>The hierarchical model has a better LOO. Here are the stacking-based model weights.</p>
<div class="sourceCode" id="cb1615"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1615-1" data-line-number="1">(mw &lt;-<span class="st"> </span><span class="kw">model_weights</span>(fit1, fit1_without_deflections))</a></code></pre></div>
<pre><code>##                     fit1 fit1_without_deflections 
##             9.999994e-01             6.438484e-07</code></pre>
<p>If you don’t like scientific notation, just <code>round()</code>.</p>
<div class="sourceCode" id="cb1617"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1617-1" data-line-number="1">mw <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1617-2" data-line-number="2"><span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">3</span>)</a></code></pre></div>
<pre><code>##                     fit1 fit1_without_deflections 
##                        1                        0</code></pre>
<p>Yep, in complimenting the LOO difference, virtually all the stacking weight went to the hierarchical model. You might think of this another way. The conceptual question we’re asking is <em>Does it make sense to say that the</em> <span class="math inline">\(\sigma_\beta\)</span> <em>parameter is zero? Is zero a credible value?</em> We’ll, I suppose we could just look at the posterior to assess for that.</p>
<div class="sourceCode" id="cb1619"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1619-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1619-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sd_CompanionNumber__Intercept)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1619-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1619-4" data-line-number="4">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">binwidth =</span> <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1619-5" data-line-number="5"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1619-6" data-line-number="6">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1619-7" data-line-number="7"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1619-8" data-line-number="8"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">50</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1619-9" data-line-number="9"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Behold the fit1 posterior for the &quot;</span>, sigma[beta], <span class="st">&quot; parameter.&quot;</span>)),</a>
<a class="sourceLine" id="cb1619-10" data-line-number="10">       <span class="dt">subtitle =</span> <span class="st">&quot;This parameter&#39;s many things, but zero isn&#39;t one of them.&quot;</span>,</a>
<a class="sourceLine" id="cb1619-11" data-line-number="11">       <span class="dt">x =</span> <span class="ot">NULL</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-38-1.png" /><!-- --></p>
<p>Yeah, zero and other values close to zero don’t look credible for that parameter. 95% of the mass is between 5 and 30, with the bulk hovering around 10. We don’t need an <span class="math inline">\(F\)</span>-test or even a LOO model comparison to see the writing on wall.</p>
</div>
<div id="multiple-comparisons-and-shrinkage." class="section level3">
<h3><span class="header-section-number">19.3.4</span> Multiple comparisons and shrinkage.</h3>
<blockquote>
<p>The previous section suggested that an analyst should investigate all contrasts of interest. This recommendation can be thought to conflict with traditional advice in the context on null hypothesis significance testing, which instead recommends that a minimal number of comparisons should be conducted in order to maximize the power of each test while keeping the overall false alarm rate capped at 5% (or whatever maximum is desired)…. Instead, a Bayesian analysis can mitigate false alarms by incorporating prior knowledge into the model. In particular, hierarchical structure (which is an expression of prior knowledge) produces shrinkage of estimates, and shrinkage can help rein in estimates of spurious outlying data. For example, in the posterior distribution from the fruit fly data, the modal values of the posterior group means have a range of 23.2. The sample means of the groups have a range of 26.1. Thus, there is some shrinkage in the estimated means. The amount of shrinkage is dictated only by the data and by the prior structure, not by the intended tests. (p. 568)</p>
</blockquote>
<p>We may as well compute those ranges by hand. Here’s the range of the observed data.</p>
<div class="sourceCode" id="cb1620"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1620-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1620-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(CompanionNumber) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1620-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean  =</span> <span class="kw">mean</span>(Longevity)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1620-4" data-line-number="4"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">range =</span> <span class="kw">max</span>(mean) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(mean))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   range
##   &lt;dbl&gt;
## 1  26.1</code></pre>
<p>For our hierarchical model <code>fit1</code>, the posterior means are rank ordered in the same way as the empirical data.</p>
<div class="sourceCode" id="cb1622"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1622-1" data-line-number="1"><span class="kw">coef</span>(fit1)<span class="op">$</span>CompanionNumber[, , <span class="st">&quot;Intercept&quot;</span>] <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1622-2" data-line-number="2"><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1622-3" data-line-number="3"><span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="dt">var =</span> <span class="st">&quot;companion_number&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1622-4" data-line-number="4"><span class="st">  </span><span class="kw">arrange</span>(Estimate) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1622-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate_if</span>(is.double, round, <span class="dt">digits =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>##   companion_number Estimate Est.Error Q2.5 Q97.5
## 1          Virgin8     39.9       3.1 33.9  46.0
## 2          Virgin1     56.8       2.9 51.1  62.5
## 3        Pregnant8     63.0       2.9 57.2  68.7
## 4            None0     63.2       2.9 57.4  68.8
## 5        Pregnant1     64.4       2.9 58.7  70.2</code></pre>
<p>If we compute the range by a difference of the point estimates of the highest and lowest posterior means, we can get a quick number.</p>
<div class="sourceCode" id="cb1624"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1624-1" data-line-number="1"><span class="kw">coef</span>(fit1)<span class="op">$</span>CompanionNumber[, , <span class="st">&quot;Intercept&quot;</span>] <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1624-2" data-line-number="2"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1624-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">range =</span> <span class="kw">max</span>(Estimate) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(Estimate))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   range
##   &lt;dbl&gt;
## 1  24.5</code></pre>
<p>Note that wasn’t fully Bayesian of us. Those means and their difference carry uncertainty with them and that uncertainty can be fully expressed if we use all the posterior draws (i.e., use <code>summary = F</code> and wrangle).</p>
<div class="sourceCode" id="cb1626"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1626-1" data-line-number="1"><span class="kw">coef</span>(fit1, <span class="dt">summary =</span> F)<span class="op">$</span>CompanionNumber[, , <span class="st">&quot;Intercept&quot;</span>] <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1626-2" data-line-number="2"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1626-3" data-line-number="3"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">range =</span> Pregnant1 <span class="op">-</span><span class="st"> </span>Virgin8) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1626-4" data-line-number="4"><span class="st">  </span><span class="kw">mode_hdi</span>(range)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 6
##   range .lower .upper .width .point .interval
##   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1  24.7   15.7   32.9   0.95 mode   hdi</code></pre>
<p>Happily, the central tendency of the range is near equivalent with both methods, but now we have 95% intervals, too. Do note how wide they are. This is why we work with the full set of posterior draws.</p>
</div>
<div id="the-two-group-case." class="section level3">
<h3><span class="header-section-number">19.3.5</span> The two-group case.</h3>
<blockquote>
<p>A special case of our current scenario is when there are only two groups. The model of the present section could, in principle, be applied to the two-group case, but the hierarchical structure would do little good because there is virtually no shrinkage when there are so few groups (and the top-level prior on <span class="math inline">\(\sigma_\beta\)</span> is broad as assumed here). (p. 568)</p>
</blockquote>
<p>For kicks and giggles, let’s practice. Since <code>Pregnant1</code> and <code>Virgin8</code> had the highest and lowest empirical means—making them the groups best suited to define our range, we’ll use them to fit the 2-group hierarchical model. To fit it with haste, just use <code>update()</code>.</p>
<div class="sourceCode" id="cb1628"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1628-1" data-line-number="1">fit2 &lt;-</a>
<a class="sourceLine" id="cb1628-2" data-line-number="2"><span class="st">  </span><span class="kw">update</span>(fit1,</a>
<a class="sourceLine" id="cb1628-3" data-line-number="3">         <span class="dt">newdata =</span> my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1628-4" data-line-number="4"><span class="st">           </span><span class="kw">filter</span>(CompanionNumber <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Pregnant1&quot;</span>, <span class="st">&quot;Virgin8&quot;</span>)),</a>
<a class="sourceLine" id="cb1628-5" data-line-number="5">         <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.999</span>,</a>
<a class="sourceLine" id="cb1628-6" data-line-number="6">                        <span class="dt">max_treedepth =</span> <span class="dv">12</span>),</a>
<a class="sourceLine" id="cb1628-7" data-line-number="7">         <span class="dt">seed =</span> <span class="dv">19</span>)</a></code></pre></div>
<p>Even with just two groups, there were no gross issues with fitting the model.</p>
<div class="sourceCode" id="cb1629"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1629-1" data-line-number="1"><span class="kw">print</span>(fit2)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Longevity ~ 1 + (1 | CompanionNumber) 
##    Data: my_data %&gt;% filter(CompanionNumber %in% c(&quot;Pregnan (Number of observations: 50) 
## Samples: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Group-Level Effects: 
## ~CompanionNumber (Number of levels: 2) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    33.07     22.62     8.86    93.59 1.00     3269     4606
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    52.23     24.82     1.13   105.83 1.00     3447     3274
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    14.24      1.49    11.66    17.51 1.00     5500     4602
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>If you compare the posteriors for <span class="math inline">\(\sigma_\beta\)</span> across the two models, you’ll see how the one for <code>fit2</code> is substantially larger.</p>
<div class="sourceCode" id="cb1631"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1631-1" data-line-number="1"><span class="kw">posterior_summary</span>(fit1)[<span class="st">&quot;sd_CompanionNumber__Intercept&quot;</span>, ]</a></code></pre></div>
<pre><code>##  Estimate Est.Error      Q2.5     Q97.5 
## 15.031865  8.041133  6.238274 36.416484</code></pre>
<div class="sourceCode" id="cb1633"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1633-1" data-line-number="1"><span class="kw">posterior_summary</span>(fit2)[<span class="st">&quot;sd_CompanionNumber__Intercept&quot;</span>, ]</a></code></pre></div>
<pre><code>##  Estimate Est.Error      Q2.5     Q97.5 
## 33.065688 22.615175  8.861131 93.587013</code></pre>
<p>This implies less shrinkage and a larger range.</p>
<div class="sourceCode" id="cb1635"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1635-1" data-line-number="1"><span class="kw">coef</span>(fit2, <span class="dt">summary =</span> F)<span class="op">$</span>CompanionNumber[, , <span class="st">&quot;Intercept&quot;</span>] <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1635-2" data-line-number="2"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1635-3" data-line-number="3"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">range =</span> Pregnant1 <span class="op">-</span><span class="st"> </span>Virgin8) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1635-4" data-line-number="4"><span class="st">  </span><span class="kw">mode_hdi</span>(range)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 6
##   range .lower .upper .width .point .interval
##   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1  25.9   17.6   33.4   0.95 mode   hdi</code></pre>
<p>And indeed, the range between the two groups is larger. Now the posterior mode for their difference has almost converged to that of the raw data. Kruschke then went on to recommend using a single-level model in such situations, instead.</p>
<blockquote>
<p>That is why the two-group model in Section 16.3 did not use hierarchical structure, as illustrated in Figure 16.11 (p. 468). That model also used a <span class="math inline">\(t\)</span> distribution to accommodate outliers in the data, and that model allowed for heterogeneous variances across groups. Thus, for two groups, it is more appropriate to use the model of Section 16.3. The hierarchical multi-group model is generalized to accommodate outliers and heterogeneous variances in Section 19.5. (p. 568)</p>
</blockquote>
<p>As a refresher, here’s what the <strong>brms</strong> code for that Chapter 16 model looked like.</p>
<div class="sourceCode" id="cb1637"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1637-1" data-line-number="1">fit3 &lt;-</a>
<a class="sourceLine" id="cb1637-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1637-3" data-line-number="3">      <span class="dt">family =</span> student,</a>
<a class="sourceLine" id="cb1637-4" data-line-number="4">      <span class="kw">bf</span>(Score <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Group, sigma <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Group),</a>
<a class="sourceLine" id="cb1637-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1637-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="kw">log</span>(sd_y)), <span class="dt">class =</span> b, <span class="dt">dpar =</span> sigma),</a>
<a class="sourceLine" id="cb1637-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">exponential</span>(one_over_twentynine), <span class="dt">class =</span> nu)),</a>
<a class="sourceLine" id="cb1637-8" data-line-number="8">      <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1637-9" data-line-number="9">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>Let’s adjust it for our data. Since we have a reduced data set, we’ll need to re-compute our <code>stanvars</code> values, which were based on the raw data.</p>
<div class="sourceCode" id="cb1638"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1638-1" data-line-number="1"><span class="co"># it&#39;s easier to just make a reduced data set</span></a>
<a class="sourceLine" id="cb1638-2" data-line-number="2">my_small_data &lt;-</a>
<a class="sourceLine" id="cb1638-3" data-line-number="3"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1638-4" data-line-number="4"><span class="st">  </span><span class="kw">filter</span>(CompanionNumber <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Pregnant1&quot;</span>, <span class="st">&quot;Virgin8&quot;</span>))</a>
<a class="sourceLine" id="cb1638-5" data-line-number="5">  </a>
<a class="sourceLine" id="cb1638-6" data-line-number="6">(mean_y &lt;-<span class="st"> </span><span class="kw">mean</span>(my_small_data<span class="op">$</span>Longevity))</a></code></pre></div>
<pre><code>## [1] 51.76</code></pre>
<div class="sourceCode" id="cb1640"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1640-1" data-line-number="1">(sd_y &lt;-<span class="st"> </span><span class="kw">sd</span>(my_small_data<span class="op">$</span>Longevity))</a></code></pre></div>
<pre><code>## [1] 19.11145</code></pre>
<div class="sourceCode" id="cb1642"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1642-1" data-line-number="1">omega &lt;-<span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb1642-2" data-line-number="2">sigma &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y</a>
<a class="sourceLine" id="cb1642-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1642-4" data-line-number="4">(s_r &lt;-<span class="st"> </span><span class="kw">gamma_a_b_from_omega_sigma</span>(<span class="dt">mode =</span> omega, <span class="dt">sd =</span> sigma))</a></code></pre></div>
<pre><code>## $shape
## [1] 1.283196
## 
## $rate
## [1] 0.02963623</code></pre>
<p>Here we update <code>stanvars</code>.</p>
<div class="sourceCode" id="cb1644"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1644-1" data-line-number="1">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1644-2" data-line-number="2"><span class="st">  </span><span class="kw">stanvar</span>(mean_y,    <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1644-3" data-line-number="3"><span class="st">  </span><span class="kw">stanvar</span>(sd_y,      <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1644-4" data-line-number="4"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>shape, <span class="dt">name =</span> <span class="st">&quot;alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1644-5" data-line-number="5"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>rate,  <span class="dt">name =</span> <span class="st">&quot;beta&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1644-6" data-line-number="6"><span class="st">  </span><span class="kw">stanvar</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">29</span>,      <span class="dt">name =</span> <span class="st">&quot;one_over_twentynine&quot;</span>)</a></code></pre></div>
<p>Note that our priors, here, are something of a blend of those from Chapter 16 and those from our hierarchical model, <code>fit1</code>.</p>
<div class="sourceCode" id="cb1645"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1645-1" data-line-number="1">fit3 &lt;-</a>
<a class="sourceLine" id="cb1645-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_small_data,</a>
<a class="sourceLine" id="cb1645-3" data-line-number="3">      <span class="dt">family =</span> student,</a>
<a class="sourceLine" id="cb1645-4" data-line-number="4">      <span class="kw">bf</span>(Longevity <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>CompanionNumber, sigma <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>CompanionNumber),</a>
<a class="sourceLine" id="cb1645-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1645-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="kw">log</span>(sd_y)), <span class="dt">class =</span> b, <span class="dt">dpar =</span> sigma),</a>
<a class="sourceLine" id="cb1645-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">exponential</span>(one_over_twentynine), <span class="dt">class =</span> nu)),</a>
<a class="sourceLine" id="cb1645-8" data-line-number="8">      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1645-9" data-line-number="9">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1645-10" data-line-number="10">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>Here’s the model summary.</p>
<div class="sourceCode" id="cb1646"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1646-1" data-line-number="1"><span class="kw">print</span>(fit3)</a></code></pre></div>
<pre><code>##  Family: student 
##   Links: mu = identity; sigma = log; nu = identity 
## Formula: Longevity ~ 0 + CompanionNumber 
##          sigma ~ 0 + CompanionNumber
##    Data: my_small_data (Number of observations: 50) 
## Samples: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Population-Level Effects: 
##                                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## CompanionNumberPregnant1          64.65      3.26    58.29    71.19 1.00    12438     8155
## CompanionNumberVirgin8            38.80      2.53    33.88    43.78 1.00    13341     8746
## sigma_CompanionNumberPregnant1     2.73      0.15     2.45     3.05 1.00    13345     9114
## sigma_CompanionNumberVirgin8       2.48      0.16     2.18     2.80 1.00    13031     8729
## 
## Family Specific Parameters: 
##    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## nu    39.61     31.02     6.01   120.48 1.00    12182     8961
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Man, look at those effective samples! As it turns out, they can be <a href="https://andrewgelman.com/2018/01/18/measuring-speed-stan-incorrectly-faster-thought-cases-due-antithetical-sampling/">greater than the number of post-warmup samples</a>. And here’s the range in posterior means.</p>
<div class="sourceCode" id="cb1648"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1648-1" data-line-number="1"><span class="kw">fixef</span>(fit3, <span class="dt">summary =</span> F) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1648-2" data-line-number="2"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1648-3" data-line-number="3"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">range =</span> CompanionNumberPregnant1 <span class="op">-</span><span class="st"> </span>CompanionNumberVirgin8) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1648-4" data-line-number="4"><span class="st">  </span><span class="kw">mode_hdi</span>(range)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 6
##   range .lower .upper .width .point .interval
##   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1  25.7   18.1   34.4   0.95 mode   hdi</code></pre>
<p>The results are pretty much the same as that of the two-group hierarchical model, maybe a touch larger. Yep, Kruschke was right. Hierarchical models with two groups and permissive priors on <span class="math inline">\(\sigma_\beta\)</span> don’t shrink the estimates to the grand mean all that much.</p>
</div>
</div>
<div id="including-a-metric-predictor" class="section level2">
<h2><span class="header-section-number">19.4</span> Including a metric predictor</h2>
<p>“In Figure 19.3, the data within each group have a large standard deviation. For example, longevities in the Virgin8 group range from 20 to 60 days” (p. 568). Turns out Kruschke’s slightly wrong on this. Probably just a typo.</p>
<div class="sourceCode" id="cb1650"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1650-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1650-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(CompanionNumber) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1650-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">min   =</span> <span class="kw">min</span>(Longevity),</a>
<a class="sourceLine" id="cb1650-4" data-line-number="4">            <span class="dt">max   =</span> <span class="kw">max</span>(Longevity),</a>
<a class="sourceLine" id="cb1650-5" data-line-number="5">            <span class="dt">range =</span> <span class="kw">max</span>(Longevity) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(Longevity))</a></code></pre></div>
<pre><code>## # A tibble: 5 x 4
##   CompanionNumber   min   max range
##   &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 None0              37    96    59
## 2 Pregnant1          42    97    55
## 3 Pregnant8          35    86    51
## 4 Virgin1            21    81    60
## 5 Virgin8            16    60    44</code></pre>
<p>But you get the point. For each group, there was quite a range. We might add predictors to the model to help account for those ranges.</p>
<blockquote>
<p>The additional metric predictor is sometimes called a covariate. In the experimental setting, the focus of interest is usually on the nominal predictor (i.e., the experimental treatments), and the covariate is typically thought of as an ancillary predictor to help isolate the effect of the nominal predictor. But mathematically the nominal and metric predictors have equal status in the model. Let’s denote the value of the metric covariate for subject <span class="math inline">\(i\)</span> as <span class="math inline">\(x_\text{cov}(i)\)</span>. Then the expected value of the predicted variable for subject <span class="math inline">\(i\)</span> is</p>
<p><span class="math display">\[\mu (i) = \beta_0 + \sum_j \beta_{[j]} x_{[j]} (i) + \beta_\text{cov}  x_\text{cov}(i)\]</span></p>
<p>with the usual sum-to-zero constraint on the deflections of the nominal predictor stated in Equation 19.2. In words, Equation 19.5 says that the predicted value for subject <span class="math inline">\(i\)</span> is a baseline plus a deflection due to the group of <span class="math inline">\(i\)</span> plus a shift due to the value of <span class="math inline">\(i\)</span> on the covariate. (p. 569)</p>
</blockquote>
<p>And the <span class="math inline">\(j\)</span> subscript, recall, denotes group membership. In this context, it often</p>
<blockquote>
<p>makes sense to set the intercept as the mean of predicted values if the covariate is re-centered at its mean value, which is denoted <span class="math inline">\(\overline x_\text{cov}\)</span>. Therefore Equation 19.5 is algebraically reformulated to make the baseline respect those constraints…. The first equation below is simply Equation 19.5 with <span class="math inline">\(x_\text{cov}\)</span> recentered on its mean, <span class="math inline">\(\overline x_\text{cov}\)</span>. The second line below merely algebraically rearranges the terms so that the nominal deflections sum to zero and the constants are combined into the overall baseline:</p>
<p><span class="math display">\[\begin{align*}
\mu &amp; = \alpha_0 + \sum_j \alpha_{[j]} x_{[j]} + \alpha_\text{cov} (x_\text{cov} - \overline{x}_\text{cov}) \\
    &amp; = \underbrace{\alpha_0 + \overline{\alpha} - \alpha_\text{cov} \overline{x}_\text{cov}}_{\beta_0} + \sum_j \underbrace{(\alpha_{[j]} - \overline{\alpha})}_{\beta_[j]} x_{[j]} + \underbrace{\alpha_\text{cov}}_{\beta_{\text{cov}}} x_\text{cov} \\
&amp; \text{where } \overline{\alpha} = \frac{1}{J} \sum^J_{j = 1} \alpha_{[j]}
\end{align*}\]</span>
(pp. 569–570)</p>
</blockquote>
<div id="example-sex-death-and-size." class="section level3">
<h3><span class="header-section-number">19.4.1</span> Example: Sex, death, and size.</h3>
<p>Kruschke recalled <code>fit1</code>’s estimate for <span class="math inline">\(\sigma_y\)</span> had a posterior mode around 14.8. Let’s confirm with a plot.</p>
<div class="sourceCode" id="cb1652"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1652-1" data-line-number="1"><span class="kw">posterior_samples</span>(fit1) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1652-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sigma, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1652-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">point_range =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">5</span>, <span class="fl">.95</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1652-4" data-line-number="4"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1652-5" data-line-number="5"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(sigma[y])) <span class="op">+</span></a>
<a class="sourceLine" id="cb1652-6" data-line-number="6"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-52-1.png" /><!-- --></p>
<p>Yep, that looks about right. That large of a difference in days would indeed make it difficult to detect between-group differences if those differences were typically on the scale of just a few days. Since <code>Thorax</code> is moderately correlated with <code>Longevity</code>, including <code>Thorax</code> in the statistical model should help shrink that <span class="math inline">\(\sigma_y\)</span> estimate, making it easier to compare group means. Following the sensibilities from the equations just above, here we’ll mean-center our covariate, first.</p>
<div class="sourceCode" id="cb1653"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1653-1" data-line-number="1">my_data &lt;-</a>
<a class="sourceLine" id="cb1653-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1653-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">thorax_c =</span> Thorax <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(Thorax))</a>
<a class="sourceLine" id="cb1653-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1653-5" data-line-number="5"><span class="kw">head</span>(my_data)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##   Longevity CompanionNumber Thorax thorax_c
##       &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;
## 1        35 Pregnant8         0.64  -0.181 
## 2        37 Pregnant8         0.68  -0.141 
## 3        49 Pregnant8         0.68  -0.141 
## 4        46 Pregnant8         0.72  -0.101 
## 5        63 Pregnant8         0.72  -0.101 
## 6        39 Pregnant8         0.76  -0.0610</code></pre>
<p>Our model code follows the structure of that in Kruschke’s <code>Jags-Ymet-Xnom1met1-MnormalHom-Example.R</code> and <code>Jags-Ymet-Xnom1met1-MnormalHom.R</code> files. As a preparatory step, we redefine the values necessary for <code>stanvars</code>.</p>
<div class="sourceCode" id="cb1655"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1655-1" data-line-number="1">(mean_y &lt;-<span class="st"> </span><span class="kw">mean</span>(my_data<span class="op">$</span>Longevity))</a></code></pre></div>
<pre><code>## [1] 57.44</code></pre>
<div class="sourceCode" id="cb1657"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1657-1" data-line-number="1">(sd_y &lt;-<span class="st"> </span><span class="kw">sd</span>(my_data<span class="op">$</span>Longevity))</a></code></pre></div>
<pre><code>## [1] 17.56389</code></pre>
<div class="sourceCode" id="cb1659"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1659-1" data-line-number="1">(sd_thorax_c &lt;-<span class="st"> </span><span class="kw">sd</span>(my_data<span class="op">$</span>thorax_c))</a></code></pre></div>
<pre><code>## [1] 0.07745367</code></pre>
<div class="sourceCode" id="cb1661"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1661-1" data-line-number="1">omega &lt;-<span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb1661-2" data-line-number="2">sigma &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y</a>
<a class="sourceLine" id="cb1661-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1661-4" data-line-number="4">(s_r &lt;-<span class="st"> </span><span class="kw">gamma_a_b_from_omega_sigma</span>(<span class="dt">mode =</span> omega, <span class="dt">sd =</span> sigma))</a></code></pre></div>
<pre><code>## $shape
## [1] 1.283196
## 
## $rate
## [1] 0.03224747</code></pre>
<div class="sourceCode" id="cb1663"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1663-1" data-line-number="1">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1663-2" data-line-number="2"><span class="st">  </span><span class="kw">stanvar</span>(mean_y,      <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1663-3" data-line-number="3"><span class="st">  </span><span class="kw">stanvar</span>(sd_y,        <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1663-4" data-line-number="4"><span class="st">  </span><span class="kw">stanvar</span>(sd_thorax_c, <span class="dt">name =</span> <span class="st">&quot;sd_thorax_c&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1663-5" data-line-number="5"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>shape,   <span class="dt">name =</span> <span class="st">&quot;alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1663-6" data-line-number="6"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>rate,    <span class="dt">name =</span> <span class="st">&quot;beta&quot;</span>)</a></code></pre></div>
<p>Now we’re ready to fit the <code>brm()</code> model, our hierarchical alternative to ANCOVA.</p>
<div class="sourceCode" id="cb1664"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1664-1" data-line-number="1">fit4 &lt;-</a>
<a class="sourceLine" id="cb1664-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1664-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1664-4" data-line-number="4">      Longevity <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>thorax_c <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>CompanionNumber),</a>
<a class="sourceLine" id="cb1664-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>),          <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1664-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span>sd_thorax_c), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1664-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">gamma</span>(alpha, beta),                <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1664-8" data-line-number="8">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, sd_y),                   <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1664-9" data-line-number="9">      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1664-10" data-line-number="10">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1664-11" data-line-number="11">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>),</a>
<a class="sourceLine" id="cb1664-12" data-line-number="12">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>Here’s the model summary.</p>
<div class="sourceCode" id="cb1665"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1665-1" data-line-number="1"><span class="kw">print</span>(fit4)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Longevity ~ 1 + thorax_c + (1 | CompanionNumber) 
##    Data: my_data (Number of observations: 125) 
## Samples: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Group-Level Effects: 
## ~CompanionNumber (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)    14.07      7.53     5.92    33.51 1.00     2575     4157
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    57.35      6.82    44.01    70.95 1.00     2429     3081
## thorax_c    136.07     12.48   111.30   160.49 1.00     7984     7348
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    10.61      0.69     9.34    12.05 1.00     7505     7602
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Let’s see if that <span class="math inline">\(\sigma_y\)</span> posterior shrank.</p>
<div class="sourceCode" id="cb1667"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1667-1" data-line-number="1"><span class="kw">posterior_samples</span>(fit4) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1667-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sigma, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1667-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">point_range =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">5</span>, <span class="fl">.95</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1667-4" data-line-number="4"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1667-5" data-line-number="5"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(sigma[y]))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-56-1.png" /><!-- --></p>
<p>Yep, sure did! Now our between-group comparisons should be more precise. Heck, if we wanted to we could even make a difference plot.</p>
<div class="sourceCode" id="cb1668"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1668-1" data-line-number="1"><span class="kw">bind_cols</span>(<span class="kw">posterior_samples</span>(fit1) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(sigma),</a>
<a class="sourceLine" id="cb1668-2" data-line-number="2">          <span class="kw">posterior_samples</span>(fit4) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1668-3" data-line-number="3"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">dif =</span> sigma <span class="op">-</span><span class="st"> </span>sigma1)</a></code></pre></div>
<pre><code>##              dif
## 1      3.3972048
## 2      3.0681945
## 3      4.8335352
## 4      5.1310374
## 5      3.1188734
## 6      2.6644530
## 7      3.1020339
## 8      3.7429947
## 9      3.0275030
## 10     4.7136865
## 11     4.1592947
## 12     3.8607439
## 13     3.1506333
## 14     4.4482659
## 15     3.8221819
## 16     3.4966344
## 17     5.0000231
## 18     6.0889588
## 19     3.4734502
## 20     3.0222053
## 21     5.5002528
## 22     3.1998220
## 23     4.9043308
## 24     5.1779230
## 25     4.9282246
## 26     3.2949168
## 27     7.3687648
## 28     5.1131540
## 29     6.0873412
## 30     4.3769872
## 31     3.0920017
## 32     2.0450944
## 33     2.5721241
## 34     5.6610027
## 35     5.4271752
## 36     3.6596136
## 37     2.8744491
## 38     4.1932875
## 39     3.4048672
## 40     3.4972328
## 41     4.4366429
## 42     5.1030603
## 43     3.6477213
## 44     5.1854505
## 45     2.6602789
## 46     4.5448669
## 47     5.8029030
## 48     5.8297208
## 49     4.5791002
## 50     2.5773963
## 51     6.1501844
## 52     7.4977679
## 53     5.1012194
## 54     4.1131402
## 55     5.2303503
## 56     5.1508667
## 57     4.7624444
## 58     5.1994097
## 59     4.7164191
## 60     3.0253202
## 61     3.9289381
## 62     4.3567889
## 63     3.2016256
## 64     3.3318311
## 65     3.6301448
## 66     4.9573506
## 67     4.5917268
## 68     4.4711619
## 69     4.4399156
## 70     4.7076201
## 71     3.3369616
## 72     4.2540872
## 73     3.4626918
## 74     3.3541511
## 75     3.9411314
## 76     5.4273675
## 77     5.4828952
## 78     4.8104312
## 79     5.5058565
## 80     3.9186942
## 81     0.5226669
## 82     4.2105226
## 83     5.5166552
## 84     4.9050061
## 85     4.3712814
## 86     2.5264057
## 87     4.2007175
## 88     4.4255702
## 89     4.5107911
## 90     4.2763132
## 91     3.8857338
## 92     2.8257934
## 93     4.6171861
## 94     5.2629383
## 95     5.1192125
## 96     4.6433158
## 97     4.5383956
## 98     4.8681959
## 99     4.6233511
## 100    4.3008114
## 101    5.4139362
## 102    5.0589072
## 103    4.2925938
## 104    5.0658795
## 105    5.8277691
## 106    3.5825696
## 107    3.1282296
## 108    3.2010975
## 109    3.8797425
## 110    5.1471379
## 111    5.8856801
## 112    4.6485851
## 113    2.2234912
## 114    1.0989876
## 115    4.3572769
## 116    5.2142077
## 117    4.9100484
## 118    5.1503650
## 119    5.0048247
## 120    3.5300541
## 121    4.8303684
## 122    6.0947525
## 123    6.0701089
## 124    5.3591647
## 125    5.0721509
## 126    5.5425977
## 127    6.0045247
## 128    3.9391191
## 129    2.7132114
## 130    4.6046462
## 131    3.4800530
## 132    3.6062384
## 133    4.0934252
## 134    3.3293005
## 135    5.5618260
## 136    4.3806404
## 137    4.7255615
## 138    4.4368004
## 139    5.3815645
## 140    3.4639914
## 141    6.5345821
## 142    1.2958430
## 143    1.5120683
## 144    2.6943372
## 145    4.2596929
## 146    4.2763959
## 147    6.1619069
## 148    1.3201606
## 149    3.0224611
## 150    1.8406185
## 151    3.5830718
## 152    4.3326189
## 153    4.9775535
## 154    4.1809982
## 155    4.1350539
## 156    3.9576372
## 157    4.1787902
## 158    2.4394879
## 159    2.8369562
## 160    2.8506337
## 161    1.6715757
## 162    2.0571439
## 163    3.9963842
## 164    4.3099740
## 165    4.1260131
## 166    3.2698427
## 167    4.8796432
## 168    3.7957656
## 169    4.5853798
## 170    4.3801215
## 171    5.5353984
## 172    4.8350714
## 173    5.7973328
## 174    3.0281907
## 175    3.7750719
## 176    3.4956839
## 177    4.8753836
## 178    5.0751461
## 179    5.4645794
## 180    5.1999280
## 181    6.2519004
## 182    4.9699134
## 183    3.6409409
## 184    4.1460473
## 185    3.4368963
## 186    2.6870038
## 187    3.8428239
## 188    4.2885918
## 189    5.2378914
## 190    5.4021266
## 191    5.4318732
## 192    4.3509272
## 193    3.8410434
## 194    3.6653779
## 195    3.4327174
## 196    4.3548762
## 197    2.4806903
## 198    4.5611855
## 199    4.4919624
## 200    4.2097931
## 201    4.2892871
## 202    3.9399679
## 203    3.5504974
## 204    3.1065080
## 205    5.7560979
## 206    4.7883474
## 207    3.8650031
## 208    4.1368811
## 209    4.3110522
## 210    2.9793898
## 211    4.4910444
## 212    4.4622593
## 213    5.0829130
## 214    7.0037230
## 215    4.2384921
## 216    4.5751666
## 217    4.5788062
## 218    4.4882508
## 219    3.7972335
## 220    4.6427960
## 221    4.1764932
## 222    4.8998471
## 223    2.6472770
## 224    3.3520902
## 225    6.5335346
## 226    6.9270320
## 227    4.7558305
## 228    3.7977751
## 229    4.7809446
## 230    3.8378395
## 231    3.2769918
## 232    4.1944681
## 233    4.8146429
## 234    5.0427129
## 235    3.6538557
## 236    3.3243671
## 237    4.2898971
## 238    5.6798904
## 239    3.9265774
## 240    3.7999675
## 241    3.4965232
## 242    4.4912168
## 243    4.2870166
## 244    2.8038343
## 245    1.5908905
## 246    6.9338790
## 247    4.7782840
## 248    5.4826905
## 249    5.4352555
## 250    5.2967877
## 251    4.9801710
## 252    6.6341811
## 253    3.9807907
## 254    3.9348436
## 255    3.4814733
## 256    4.0354077
## 257    3.5605922
## 258    4.1344762
## 259    4.4487034
## 260    6.1250039
## 261    3.6024295
## 262    6.2882964
## 263    2.4923781
## 264    3.8315798
## 265    3.1489993
## 266    3.6697475
## 267    5.1214171
## 268    4.5245791
## 269    3.6687390
## 270    3.6969854
## 271    5.5798524
## 272    5.3396652
## 273    4.6949698
## 274    6.7839921
## 275    6.0913195
## 276    6.1215281
## 277    3.5691391
## 278    5.7711368
## 279    4.9049693
## 280    4.1525293
## 281    3.6450523
## 282    5.1048598
## 283    4.5291360
## 284    4.1449389
## 285    3.7659919
## 286    3.2516544
## 287    3.6343564
## 288    5.4657501
## 289    2.7040177
## 290    3.3198687
## 291    3.1297135
## 292    4.3892576
## 293    2.6972641
## 294    2.9350322
## 295    3.4912474
## 296    3.3285546
## 297    4.0838362
## 298    3.5608679
## 299    3.6288692
## 300    3.5184523
## 301    4.1900251
## 302    5.0355629
## 303    4.1233665
## 304    4.3615433
## 305    4.6514450
## 306    3.2017173
## 307    4.6288157
## 308    3.2958645
## 309    3.4999315
## 310    3.5681434
## 311    4.5139770
## 312    3.7326334
## 313    4.4507178
## 314    2.3118083
## 315    3.7214369
## 316    4.2712735
## 317    4.1336661
## 318    4.6175553
## 319    4.2765711
## 320    3.7257971
## 321    3.9651988
## 322    4.1895064
## 323    4.5538481
## 324    3.0716104
## 325    5.4009496
## 326    2.6248126
## 327    2.7439567
## 328    5.2252472
## 329    4.1027588
## 330    4.0605515
## 331    3.4787663
## 332    2.1902811
## 333    2.8072919
## 334    3.4113470
## 335    3.9563381
## 336    6.1452907
## 337    5.6406894
## 338    4.8770190
## 339    2.7787173
## 340    4.7600064
## 341    3.7897549
## 342    3.6325165
## 343    8.0759197
## 344    4.5220316
## 345    5.0982051
## 346    5.8116481
## 347    5.0182932
## 348    4.6773334
## 349    2.5936637
## 350    4.2436607
## 351    3.7079848
## 352    4.4737530
## 353    5.5479445
## 354    5.3352701
## 355    4.8049375
## 356    5.2945868
## 357    5.8360413
## 358    3.0853737
## 359    4.0576618
## 360    4.3358881
## 361    3.6331893
## 362    4.0845817
## 363    4.8545830
## 364    3.8638408
## 365    2.9006229
## 366    2.9543058
## 367    3.5709357
## 368    2.8130402
## 369    4.0729981
## 370    1.9325826
## 371    1.3424251
## 372    1.9770096
## 373    4.8657590
## 374    4.3284129
## 375    3.7962654
## 376    4.2521621
## 377    4.9211593
## 378    3.7969652
## 379    4.6443098
## 380    4.6854604
## 381    4.9702520
## 382    4.9530550
## 383    4.9644905
## 384    2.6951358
## 385    2.9884850
## 386    2.8798391
## 387    3.8246886
## 388    2.2120591
## 389    4.3437242
## 390    4.5635982
## 391    4.0184117
## 392    5.4959308
## 393    3.1659744
## 394    4.1337165
## 395    1.3001951
## 396    4.1319100
## 397    5.1983909
## 398    5.3523244
## 399    4.7374151
## 400    5.2653703
## 401    3.3741399
## 402    3.3642618
## 403    3.7035400
## 404    3.2423934
## 405    3.2055676
## 406    6.8506413
## 407    6.1592294
## 408    3.2524620
## 409    4.4053514
## 410    4.7561713
## 411    4.9901163
## 412    5.0886218
## 413    4.3526219
## 414    2.8475369
## 415    6.0177562
## 416    4.7272910
## 417    3.1830625
## 418    5.4073433
## 419    3.8954866
## 420    4.3621043
## 421    3.7834440
## 422    3.8520938
## 423    4.6850541
## 424    5.0429912
## 425    4.6917326
## 426    5.8391084
## 427    4.0354053
## 428    6.5078000
## 429    3.6505226
## 430    3.3725586
## 431    3.8007863
## 432    4.5858709
## 433    3.8495703
## 434    4.2291131
## 435    5.4646663
## 436    5.5602835
## 437    3.4726486
## 438    6.1279182
## 439    5.4267749
## 440    3.7061421
## 441    3.2396374
## 442    6.5382313
## 443    5.4519368
## 444    4.1157763
## 445    4.1600822
## 446    2.9493329
## 447    3.4382274
## 448    6.2324414
## 449    5.7636954
## 450    6.4208577
## 451    5.6297600
## 452    2.9793958
## 453    5.8054953
## 454    5.7461174
## 455    3.3581508
## 456    5.3628448
## 457    3.6164415
## 458    2.9675953
## 459    4.5668833
## 460    4.2399772
## 461    5.8464357
## 462    4.9617600
## 463    4.9483554
## 464    6.4394261
## 465    2.6378356
## 466    5.3945255
## 467    4.4939139
## 468    4.3064410
## 469    4.1636821
## 470    3.5108331
## 471    3.2669215
## 472    3.7361445
## 473    3.8534452
## 474    3.4645815
## 475    3.3117735
## 476    2.9995521
## 477    3.0215139
## 478    3.6992213
## 479    3.9232197
## 480    1.8586719
## 481    2.4037888
## 482    3.0510762
## 483    3.8279486
## 484    4.4992880
## 485    5.4809251
## 486    3.7286641
## 487    3.5505769
## 488    3.8967887
## 489    4.0412612
## 490    3.9574500
## 491    3.8625351
## 492    4.8139389
## 493    3.8637197
## 494    5.7908367
## 495    6.1868463
## 496    4.7685539
## 497    4.6078168
## 498    3.4958586
## 499    3.5592869
## 500    2.9901003
## 501    4.5985102
## 502    3.0709873
## 503    3.5522605
## 504    4.6945757
## 505    3.9740027
## 506    4.3104975
## 507    4.8761040
## 508    5.2336553
## 509    4.9746113
## 510    6.2795627
## 511    5.9170569
## 512    4.2301665
## 513    4.3421673
## 514    4.7100607
## 515    5.2938362
## 516    4.7981634
## 517    4.7256391
## 518    5.1066219
## 519    5.2429397
## 520    4.8817716
## 521    5.5686648
## 522    3.6683968
## 523    2.5113087
## 524    5.4282303
## 525    5.9661381
## 526    7.1864009
## 527    3.0303955
## 528    2.9553174
## 529    4.4626225
## 530    3.3520888
## 531    2.7119272
## 532    4.2263836
## 533    3.6154245
## 534    2.8696238
## 535    4.2274410
## 536    5.4624323
## 537    4.6478865
## 538    5.2860350
## 539    4.7031787
## 540    4.5889823
## 541    2.9751587
## 542    3.8328702
## 543    3.0644881
## 544    4.3400886
## 545    4.2719350
## 546    5.7292258
## 547    5.3593960
## 548    6.6655325
## 549    4.5590796
## 550    6.9410291
## 551    3.4367997
## 552    3.9023867
## 553    6.4141128
## 554    1.2551277
## 555    4.4168068
## 556    3.7897817
## 557    4.6726679
## 558    3.6265744
## 559    2.1197444
## 560    2.2239080
## 561    1.5383691
## 562    4.0887839
## 563    4.4224372
## 564    3.7524035
## 565    4.3057351
## 566    2.1264532
## 567    6.6747485
## 568    6.9863544
## 569    7.4010383
## 570    5.7605839
## 571    5.4728982
## 572    2.9365962
## 573    3.0220355
## 574    5.0164716
## 575    3.6621437
## 576    2.5235910
## 577    4.8179191
## 578    3.5043425
## 579    5.9242904
## 580    2.9427332
## 581    3.4071322
## 582    4.6200100
## 583    4.9445768
## 584    2.7304670
## 585    4.2105175
## 586    4.8955166
## 587    4.9046889
## 588    6.3929803
## 589    1.7281101
## 590    1.7626060
## 591    4.9422597
## 592    2.7218931
## 593    4.1883859
## 594    4.7585670
## 595    3.7995016
## 596    1.8567815
## 597    3.6509673
## 598    3.8651192
## 599    3.4631097
## 600    6.2292499
## 601    5.3011243
## 602    5.2789094
## 603    5.6524120
## 604    7.2651456
## 605    5.8115662
## 606    5.8501700
## 607    6.1984612
## 608    3.7993192
## 609    4.8805351
## 610    4.0618506
## 611    3.3424427
## 612    1.5504169
## 613    3.9918188
## 614    3.3652950
## 615    4.7282997
## 616    3.6815057
## 617    3.9667096
## 618    3.8343749
## 619    4.2471469
## 620    4.7954731
## 621    3.7338618
## 622    4.6787041
## 623    4.8722882
## 624    5.5387835
## 625    4.2135978
## 626    3.8368087
## 627    4.5645056
## 628    4.5965363
## 629    2.6493720
## 630    4.7464432
## 631    5.0169051
## 632    4.1817353
## 633    2.7174318
## 634    3.3720075
## 635    4.4887245
## 636    5.8980943
## 637    4.0408620
## 638    3.6257449
## 639    4.8267650
## 640    4.7150549
## 641    5.3310805
## 642    3.7897584
## 643    4.0631618
## 644    4.3762620
## 645    4.5690662
## 646    4.7846686
## 647    4.5665134
## 648    4.4129442
## 649    4.4464437
## 650    4.5075756
## 651    3.8584977
## 652    5.3248543
## 653    3.8112146
## 654    4.5326266
## 655    4.4688496
## 656    4.0793197
## 657    3.8414732
## 658    3.8975976
## 659    4.3300926
## 660    3.4379833
## 661    6.9448172
## 662    6.7684071
## 663    5.2523557
## 664    2.9215008
## 665    4.2110875
## 666    4.2450215
## 667    3.8943672
## 668    2.3698234
## 669    3.9354630
## 670    3.8233244
## 671    4.5578785
## 672    5.3640379
## 673    5.6135403
## 674    5.0223868
## 675    4.3947695
## 676    4.3122202
## 677    5.1802860
## 678    2.6527892
## 679    3.5498525
## 680    4.8630994
## 681    5.1850877
## 682    4.4472832
## 683    4.2080683
## 684    2.9424084
## 685    3.7020031
## 686    2.9940364
## 687    4.6505792
## 688    5.2022433
## 689    5.8172747
## 690    3.4162669
## 691    2.7491348
## 692    5.3344076
## 693    4.2016151
## 694    4.0956511
## 695    3.3540304
## 696    4.8300744
## 697    2.6694345
## 698    2.5158298
## 699    2.9541521
## 700    7.0568691
## 701    5.3897999
## 702    1.8504427
## 703    4.7279741
## 704    5.7666367
## 705    3.9753834
## 706    4.1209753
## 707    6.4181893
## 708    4.6296355
## 709    4.0017899
## 710    1.8289861
## 711    3.4787121
## 712    3.7539695
## 713    3.3964601
## 714    4.8871911
## 715    5.6460231
## 716    5.5947572
## 717    3.7295369
## 718    4.4964810
## 719    5.1073446
## 720    4.6292657
## 721    5.0356998
## 722    2.1224437
## 723    3.4209875
## 724    4.5791688
## 725    3.5754222
## 726    3.6829833
## 727    5.6666207
## 728    4.7939304
## 729    4.8752090
## 730    3.0036423
## 731    3.4969054
## 732    5.6457699
## 733    3.9181254
## 734    3.3705823
## 735    5.1957333
## 736    4.2617065
## 737    4.0703882
## 738    4.3565531
## 739    2.2318368
## 740    3.5960916
## 741    4.0577006
## 742    4.1247783
## 743    4.1936410
## 744    3.8906613
## 745    6.2760037
## 746    3.8136039
## 747    3.2781265
## 748    6.5105451
## 749    5.5871110
## 750    4.9986330
## 751    4.9770481
## 752    5.3653065
## 753    7.3042344
## 754    7.0167791
## 755    6.8167335
## 756    6.6696765
## 757    3.1548330
## 758    3.9872152
## 759    4.0374414
## 760    5.5988876
## 761    5.4976116
## 762    4.9687655
## 763    3.4408697
## 764    4.2096883
## 765    4.2035456
## 766    5.5424716
## 767    5.4065855
## 768    2.9563745
## 769    5.1967356
## 770    4.5461563
## 771    4.0546092
## 772    4.1234221
## 773    4.3861940
## 774    4.2972106
## 775    6.1247858
## 776    6.4960353
## 777    3.5688533
## 778    3.7712157
## 779    2.5513722
## 780    4.6595639
## 781    4.7767288
## 782    4.2907761
## 783    5.0725495
## 784    3.4540305
## 785    3.9035085
## 786    3.4062946
## 787    3.6245165
## 788    3.2870845
## 789    3.7677237
## 790    4.7725795
## 791    4.6128555
## 792    4.7882070
## 793    3.6837005
## 794    6.0202555
## 795    5.7029268
## 796    4.9452369
## 797    3.8367467
## 798    3.5135476
## 799    5.2427762
## 800    3.8925061
## 801    2.9466264
## 802    5.0884416
## 803    5.1037561
## 804    2.8702699
## 805    3.8762385
## 806    3.0444337
## 807    2.3051266
## 808    3.1390835
## 809    5.0041802
## 810    3.7369639
## 811    4.5222193
## 812    4.7709138
## 813    3.3810203
## 814    3.8213376
## 815    5.1047980
## 816    3.8945924
## 817    3.8045676
## 818    3.8459944
## 819    3.9702160
## 820    4.4514479
## 821    5.5310211
## 822    3.2266905
## 823    4.5385488
## 824    4.7477298
## 825    4.8852568
## 826    4.0367400
## 827    3.9267234
## 828    2.7710692
## 829    2.4167414
## 830    3.6012990
## 831    4.4589178
## 832    5.0645655
## 833    6.1729940
## 834    5.4647398
## 835    4.1402859
## 836    4.5118446
## 837    4.6597392
## 838    4.5140722
## 839    4.4842489
## 840    4.8444188
## 841    5.0079809
## 842    4.8340931
## 843    3.4081698
## 844    3.4414761
## 845    6.6606732
## 846    4.3512193
## 847    4.0222228
## 848    3.9537487
## 849    5.1527731
## 850    7.0420730
## 851    5.6573408
## 852    3.6387039
## 853    3.4073400
## 854    5.1231655
## 855    4.5349305
## 856    5.3411604
## 857    4.6768015
## 858    4.1820739
## 859    4.3596849
## 860    5.7852022
## 861    3.8701256
## 862    2.7831484
## 863    1.6220721
## 864    2.0039044
## 865    2.4560357
## 866    3.1917695
## 867    3.5635254
## 868    3.6877859
## 869    4.1304963
## 870    3.1620227
## 871    3.8100682
## 872    4.0235192
## 873    4.4061762
## 874    3.2754479
## 875    5.3059942
## 876    3.3736801
## 877    5.2136383
## 878    6.3309336
## 879    3.9453217
## 880    2.4436065
## 881    2.8191841
## 882    4.9619412
## 883    2.5656459
## 884    3.5763530
## 885    3.2477352
## 886    2.3289787
## 887    7.0426093
## 888    6.1578744
## 889    6.5304001
## 890    2.7434620
## 891    2.9916211
## 892    2.4216418
## 893    2.0265699
## 894    2.4483775
## 895    2.3457018
## 896    1.7055322
## 897    3.5704739
## 898    3.6932842
## 899    4.0047941
## 900    4.0634237
## 901    6.6696810
## 902    6.5291663
## 903    4.2155721
## 904    4.9658450
## 905    3.8812170
## 906    5.6990875
## 907    3.1069244
## 908    3.1961203
## 909    2.6058986
## 910    6.1323497
## 911    4.0355325
## 912    3.7867505
## 913    4.3678831
## 914    4.8435867
## 915    4.9430672
## 916    5.1438392
## 917    4.3216883
## 918    4.2852198
## 919    3.3762261
## 920    5.3573373
## 921    4.3799603
## 922    4.6562479
## 923    4.4677039
## 924    3.5796366
## 925    4.2490955
## 926    4.4359849
## 927    4.1051209
## 928    3.2325484
## 929    4.3569386
## 930    3.7087294
## 931    3.5425867
## 932    3.9355220
## 933    3.2358465
## 934    5.6892167
## 935    3.3829554
## 936    5.2985975
## 937    5.0566271
## 938    4.3574202
## 939    3.3224050
## 940    3.2481185
## 941    4.8663675
## 942    5.4380625
## 943    4.5953325
## 944    5.9081823
## 945    5.6459670
## 946    3.6705684
## 947    3.5660948
## 948    4.0160081
## 949    3.0941461
## 950    6.0642165
## 951    5.5724262
## 952    5.2160128
## 953    5.4537541
## 954    3.4964851
## 955    4.2067165
## 956    4.1180502
## 957    4.8966708
## 958    4.1262470
## 959    4.0890061
## 960    2.8765538
## 961    3.7744474
## 962    3.4799557
## 963    2.5346645
## 964    3.5411501
## 965    4.8239276
## 966    2.9489560
## 967    4.1371295
## 968    3.2453955
## 969    5.5138804
## 970    5.1368237
## 971    5.6612020
## 972    4.0550629
## 973    2.7760941
## 974    4.7977818
## 975    2.5618015
## 976    2.2772799
## 977    1.8239509
## 978    4.9135104
## 979    2.3798013
## 980    2.8332584
## 981    2.6119109
## 982    3.5147216
## 983    3.7358686
## 984    4.2261929
## 985    4.5291214
## 986    5.5553447
## 987    4.6017500
## 988    4.2341190
## 989    3.0009517
## 990    5.6674052
## 991    5.6946436
## 992    5.9193697
## 993    4.6579522
## 994    5.7611488
## 995    3.5042142
## 996    3.6351507
## 997    4.3601447
## 998    4.4036410
## 999    3.5701931
## 1000   2.2388856
## 1001   6.3425331
## 1002   4.2855887
## 1003   3.8714991
## 1004   1.9960157
## 1005   2.5313232
## 1006   1.2742852
## 1007   2.8765446
## 1008   5.1670844
## 1009   4.9346485
## 1010   5.0316376
## 1011   4.8077951
## 1012   3.7991368
## 1013   4.0528098
## 1014   3.5595041
## 1015   4.1486020
## 1016   3.0833698
## 1017   4.4701500
## 1018   3.7094165
## 1019   2.7064152
## 1020   5.8529753
## 1021   5.1217912
## 1022   4.5583455
## 1023   2.2831382
## 1024   5.8458243
## 1025   4.5169093
## 1026   4.9415040
## 1027   2.7071504
## 1028   3.4755361
## 1029   5.5591878
## 1030   5.5413418
## 1031   4.5487311
## 1032   5.9899480
## 1033   4.2543350
## 1034   4.3552677
## 1035   3.6069298
## 1036   4.4504167
## 1037   4.3149827
## 1038   4.1309065
## 1039   3.7116425
## 1040   4.6235393
## 1041   3.8929776
## 1042   3.9323411
## 1043   3.1620586
## 1044   3.5192414
## 1045   4.4673151
## 1046   4.4200540
## 1047   4.6875282
## 1048   4.2531500
## 1049   3.7450779
## 1050   3.6181845
## 1051   4.9869290
## 1052   4.8154390
## 1053   3.8900917
## 1054   3.4134258
## 1055   4.0332496
## 1056   4.9562185
## 1057   3.7915998
## 1058   5.0537346
## 1059   3.0275427
## 1060   4.4451039
## 1061   4.8180902
## 1062   3.5445218
## 1063   3.9858121
## 1064   5.1242691
## 1065   4.4480191
## 1066   5.8672364
## 1067   4.6151536
## 1068   3.1278751
## 1069   3.9104134
## 1070   4.8752064
## 1071   5.8407416
## 1072   5.5182010
## 1073   6.7042718
## 1074   4.5284212
## 1075   6.2080772
## 1076   6.4191023
## 1077   3.7920320
## 1078   4.0398647
## 1079   4.8563433
## 1080   4.2702738
## 1081   3.7791359
## 1082   3.2428210
## 1083   4.1786679
## 1084   4.9068388
## 1085   4.7937226
## 1086   3.9192894
## 1087   4.2743617
## 1088   4.2271796
## 1089   4.4069247
## 1090   4.5390861
## 1091   2.7327395
## 1092   2.2467980
## 1093   5.8698706
## 1094   2.8139030
## 1095   5.0968310
## 1096   4.3256581
## 1097   3.9453572
## 1098   1.9978093
## 1099   2.6867684
## 1100   3.4739275
## 1101   3.4673106
## 1102   4.1498869
## 1103   4.4679729
## 1104   4.7575995
## 1105   4.5079115
## 1106   3.4303074
## 1107   3.8948357
## 1108   4.8755693
## 1109   4.3698885
## 1110   3.6161956
## 1111   4.8290110
## 1112   4.5854669
## 1113   5.6152373
## 1114   6.0201221
## 1115   5.0618126
## 1116   4.9321191
## 1117   2.9657742
## 1118   5.4021901
## 1119   3.9573388
## 1120   3.5667332
## 1121   4.6502641
## 1122   4.0715912
## 1123   3.2866190
## 1124   3.2059643
## 1125   4.8113459
## 1126   3.0726400
## 1127   6.8241144
## 1128   5.3225793
## 1129   5.0968662
## 1130   4.2298637
## 1131   3.3575352
## 1132   3.0256786
## 1133   4.7187263
## 1134   5.0531145
## 1135   5.3447448
## 1136   5.4190755
## 1137   4.9911427
## 1138   5.9764369
## 1139   4.0653503
## 1140   3.8265380
## 1141   4.3362680
## 1142   3.8949477
## 1143   3.4977007
## 1144   4.9007277
## 1145   5.6874134
## 1146   3.2767570
## 1147   3.5025757
## 1148   4.2939522
## 1149   4.6711050
## 1150   4.5999589
## 1151   4.2987045
## 1152   3.9115383
## 1153   3.5715235
## 1154   5.7201910
## 1155   5.7222720
## 1156   4.4821634
## 1157   2.9286552
## 1158   2.2833691
## 1159   2.5530602
## 1160   3.8431913
## 1161   4.8379909
## 1162   2.3785773
## 1163   4.5656227
## 1164   4.9419944
## 1165   4.8605500
## 1166   4.6026424
## 1167   4.2218888
## 1168   4.2397022
## 1169   6.2704256
## 1170   6.0198279
## 1171   6.4648973
## 1172   3.2794879
## 1173   3.8409147
## 1174   3.4284576
## 1175   3.0061553
## 1176   3.3303217
## 1177   4.1038245
## 1178   4.5224635
## 1179   3.3106351
## 1180   5.2195956
## 1181   3.8903211
## 1182   3.4861103
## 1183   2.0591800
## 1184   6.1455995
## 1185   3.8037631
## 1186   3.0118349
## 1187   1.9624425
## 1188   2.8679217
## 1189   3.7292218
## 1190   3.4692805
## 1191   2.0385431
## 1192   3.2227951
## 1193   5.0643390
## 1194   4.2632197
## 1195   6.6405099
## 1196   4.0053168
## 1197   4.3980653
## 1198   3.2445391
## 1199   2.9263789
## 1200   3.3359445
## 1201   3.0083054
## 1202   2.7337027
## 1203   3.9214369
## 1204   2.5283640
## 1205   3.0585449
## 1206   4.4922254
## 1207   3.0215238
## 1208   4.2181565
## 1209   3.5357233
## 1210   3.5340186
## 1211   3.4533159
## 1212   3.9748895
## 1213   0.7878773
## 1214   0.8472454
## 1215   2.0075773
## 1216   5.7783637
## 1217   3.3879090
## 1218   3.6826418
## 1219   4.0486957
## 1220   3.8896327
## 1221   3.9814007
## 1222   5.1037737
## 1223   5.3098291
## 1224   2.1216823
## 1225   2.4097438
## 1226   3.4113338
## 1227   4.7607143
## 1228   4.3244559
## 1229   4.3078906
## 1230   4.7936162
## 1231   4.3716914
## 1232   5.2599054
## 1233   4.0597622
## 1234   6.1910684
## 1235   5.6756348
## 1236   4.6288952
## 1237   4.4845901
## 1238   3.8871692
## 1239   3.6198474
## 1240   5.2728942
## 1241   3.8821763
## 1242   6.2008882
## 1243   3.1611263
## 1244   3.9389017
## 1245   3.7892140
## 1246   4.4767949
## 1247   3.4023547
## 1248   5.3329027
## 1249   5.4539256
## 1250   5.3905459
## 1251   4.4072913
## 1252   2.9338388
## 1253   4.8139224
## 1254   5.0157926
## 1255   4.7563057
## 1256   5.9511380
## 1257   5.8701228
## 1258   3.6008223
## 1259   5.0306244
## 1260   3.1851445
## 1261   5.6643146
## 1262   4.2816000
## 1263   4.0371294
## 1264   3.7923712
## 1265   3.4355561
## 1266   4.5727663
## 1267   5.0785083
## 1268   4.7567250
## 1269   2.8170008
## 1270   6.5355976
## 1271   3.5979946
## 1272   2.0041309
## 1273   3.7378090
## 1274   4.6426974
## 1275   3.6769105
## 1276   2.5847036
## 1277   3.9347303
## 1278   2.4282123
## 1279   2.5922154
## 1280   1.6390807
## 1281   5.0567665
## 1282   3.5883990
## 1283   4.9096026
## 1284   4.0942044
## 1285   5.1077536
## 1286   4.8480335
## 1287   4.0193577
## 1288   2.1649172
## 1289   4.0633201
## 1290   6.9822714
## 1291   5.6800228
## 1292   6.0833915
## 1293   6.6281769
## 1294   1.6582261
## 1295   4.6205084
## 1296   6.4561707
## 1297   6.5022833
## 1298   5.3109010
## 1299   4.1891275
## 1300   4.0721356
## 1301   4.2043713
## 1302   4.2860274
## 1303   3.0996456
## 1304   5.0443562
## 1305   4.8494975
## 1306   3.4702441
## 1307   3.7675665
## 1308   4.7653132
## 1309   3.3536887
## 1310   3.7632431
## 1311   3.8297259
## 1312   4.1546004
## 1313   4.7937060
## 1314   3.1481956
## 1315   5.3317375
## 1316   5.6501596
## 1317   2.9110168
## 1318   3.0265317
## 1319   3.7781429
## 1320   5.0438590
## 1321   3.1812034
## 1322   3.0234847
## 1323   3.4613855
## 1324   4.9209524
## 1325   5.4722889
## 1326   3.6624486
## 1327   4.5862369
## 1328   3.6323702
## 1329   4.5604595
## 1330   2.7324090
## 1331   2.9008274
## 1332   5.2440985
## 1333   5.7442266
## 1334   4.1906508
## 1335   2.5600538
## 1336   2.6675490
## 1337   2.8944546
## 1338   2.1768805
## 1339   3.6383243
## 1340   6.6778590
## 1341   5.0663925
## 1342   3.5699705
## 1343   3.5410294
## 1344   5.1688543
## 1345   4.8108563
## 1346   5.2888901
## 1347   5.2075437
## 1348   3.3466310
## 1349   2.6074532
## 1350   5.0927413
## 1351   5.0405943
## 1352   2.0647739
## 1353   3.5045498
## 1354   3.3082702
## 1355   4.3849095
## 1356   5.8144065
## 1357   4.6745933
## 1358   4.9523926
## 1359   2.4730063
## 1360   3.2708838
## 1361   4.0619448
## 1362   2.5934813
## 1363   3.6036518
## 1364   5.4228126
## 1365   3.3559144
## 1366   3.2543949
## 1367   3.7575409
## 1368   4.4074480
## 1369   3.5012464
## 1370   6.4062766
## 1371   3.3895458
## 1372   6.2121825
## 1373   4.9120580
## 1374   3.2442505
## 1375   4.3558183
## 1376   2.7967583
## 1377   4.7044100
## 1378   5.0750175
## 1379   4.1508118
## 1380   4.8752687
## 1381   5.1695254
## 1382   5.9454146
## 1383   7.5551762
## 1384   4.7867238
## 1385   4.9855348
## 1386   4.1151790
## 1387   4.7216246
## 1388   4.6419746
## 1389   3.5083458
## 1390   4.6782338
## 1391   4.9283626
## 1392   4.5028231
## 1393   4.3529571
## 1394   4.7275051
## 1395   4.9518720
## 1396   5.2455744
## 1397   4.7587455
## 1398   3.6623739
## 1399   2.7338176
## 1400   3.7618740
## 1401   2.0240412
## 1402   3.0224328
## 1403   2.6783930
## 1404   4.6959987
## 1405   3.1685715
## 1406   3.8108926
## 1407   4.3876782
## 1408   2.6775742
## 1409   3.7605442
## 1410   6.0437588
## 1411   4.0953393
## 1412   4.9663979
## 1413   3.1683560
## 1414   4.2907635
## 1415   4.6503201
## 1416   3.8106945
## 1417   3.5335487
## 1418   3.1038686
## 1419   3.5104215
## 1420   3.5517757
## 1421   3.8022194
## 1422   4.4493719
## 1423   3.7351564
## 1424   3.7628915
## 1425   5.5242362
## 1426   3.3197019
## 1427   3.8929792
## 1428   4.6169652
## 1429   4.9919635
## 1430   3.1578988
## 1431   3.5973166
## 1432   6.3742773
## 1433   4.2656624
## 1434   5.4751668
## 1435   4.0011423
## 1436   4.3726555
## 1437   3.6245952
## 1438   4.1407901
## 1439   5.4101954
## 1440   4.9191405
## 1441   3.7735570
## 1442   4.0871452
## 1443   3.5056742
## 1444   3.9478777
## 1445   3.9360271
## 1446   4.1988565
## 1447   4.4305298
## 1448   4.1789952
## 1449   5.3073558
## 1450   5.6373210
## 1451   5.1266808
## 1452   4.7846624
## 1453   4.1300393
## 1454   4.5233815
## 1455   4.3549327
## 1456   3.9686222
## 1457   5.4570199
## 1458   3.4633302
## 1459   5.4595450
## 1460   6.7874980
## 1461   6.1602064
## 1462   3.1507845
## 1463   2.6234617
## 1464   3.8494964
## 1465   5.1709941
## 1466   3.6137342
## 1467   3.0663247
## 1468   0.1461465
## 1469   1.4910142
## 1470   6.2996977
## 1471   5.8142693
## 1472   6.2013982
## 1473   4.3102241
## 1474   3.1939531
## 1475   4.4339670
## 1476   5.1121185
## 1477   4.6037845
## 1478   4.8625410
## 1479   4.2451746
## 1480   2.3616576
## 1481   3.2205237
## 1482   5.6348397
## 1483   5.4874232
## 1484   4.6995694
## 1485   4.5510621
## 1486   4.5994931
## 1487   4.0713327
## 1488   4.5364287
## 1489   2.9494397
## 1490   4.4035869
## 1491   5.7896607
## 1492   4.8055484
## 1493   2.8472613
## 1494   2.7693207
## 1495   4.6066565
## 1496   3.6288897
## 1497   5.3574855
## 1498   3.9082947
## 1499   6.2010210
## 1500   4.3491027
## 1501   4.8398116
## 1502   4.6363327
## 1503   3.8470014
## 1504   4.7444203
## 1505   4.8507445
## 1506   4.1819213
## 1507   3.5290327
## 1508   4.9445375
## 1509   4.6964014
## 1510   4.8481564
## 1511   5.2301572
## 1512   4.8663984
## 1513   4.8937737
## 1514   5.8248722
## 1515   5.4308651
## 1516   3.9066486
## 1517   5.9270772
## 1518   6.3199315
## 1519   3.7700498
## 1520   3.5048480
## 1521   4.1694228
## 1522   4.2884355
## 1523   3.6210442
## 1524   5.8048404
## 1525   5.9962477
## 1526   4.1516470
## 1527   3.6996113
## 1528   3.8679236
## 1529   2.5511466
## 1530   4.6809500
## 1531   5.7600269
## 1532   4.4680601
## 1533   5.7638138
## 1534   5.0949142
## 1535   4.1732751
## 1536   2.4766113
## 1537   3.8391026
## 1538   4.3853405
## 1539   2.8773673
## 1540   3.9690440
## 1541   4.3123040
## 1542   4.6343995
## 1543   4.1175300
## 1544   4.9868464
## 1545   6.5820497
## 1546   4.6768724
## 1547   3.3877907
## 1548   4.4293646
## 1549   4.1858740
## 1550   3.5982551
## 1551   3.9031308
## 1552   6.0217776
## 1553   3.9938752
## 1554   5.0282850
## 1555   5.4735167
## 1556   4.1150377
## 1557   1.6155130
## 1558   3.1557966
## 1559   3.2080421
## 1560   2.8726325
## 1561   2.7569769
## 1562   7.0111474
## 1563   5.5170467
## 1564   5.4813437
## 1565   5.6159421
## 1566   4.8430679
## 1567   5.8119204
## 1568   5.2222410
## 1569   4.7193289
## 1570   5.8208056
## 1571   4.9144057
## 1572   4.0635635
## 1573   3.9662102
## 1574   2.7260794
## 1575   2.4479031
## 1576   6.3573655
## 1577   3.2713535
## 1578   4.3400737
## 1579   5.3188802
## 1580   5.7007153
## 1581   4.4967263
## 1582   4.2140078
## 1583   4.7819238
## 1584   4.1447361
## 1585   4.3382739
## 1586   3.3318550
## 1587   5.0356014
## 1588   5.1842886
## 1589   5.1672109
## 1590   5.1815038
## 1591   6.0426852
## 1592   4.6993812
## 1593   3.5793581
## 1594   2.7026805
## 1595   4.1907897
## 1596   5.0700718
## 1597   4.8331361
## 1598   5.1738176
## 1599   2.1608641
## 1600   2.3096730
## 1601   2.7357094
## 1602   2.6165572
## 1603   6.2245514
## 1604   3.3447107
## 1605   3.4804175
## 1606   6.0773191
## 1607   3.4460339
## 1608   5.6440714
## 1609   4.9073279
## 1610   4.2486435
## 1611   4.8094090
## 1612   4.0355768
## 1613   3.6846549
## 1614   3.7158254
## 1615   3.2912648
## 1616   5.5525639
## 1617   7.3912971
## 1618   3.4120443
## 1619   2.9494565
## 1620   3.8170090
## 1621   1.8261589
## 1622   4.1765831
## 1623   3.5453224
## 1624   5.2058726
## 1625   4.3351520
## 1626   4.3786176
## 1627   3.7152773
## 1628   5.5346660
## 1629   5.3491336
## 1630   4.5637502
## 1631   5.5128498
## 1632   2.2359130
## 1633   2.7907807
## 1634   3.3973719
## 1635   1.8370174
## 1636   4.0891896
## 1637   5.0764727
## 1638   2.7722977
## 1639   3.4118230
## 1640   4.3763580
## 1641   3.8844279
## 1642   5.1187766
## 1643   4.8087127
## 1644   4.7529314
## 1645   3.8011702
## 1646   4.5800115
## 1647   6.4894826
## 1648   3.2136046
## 1649   5.0168364
## 1650   2.8604827
## 1651   4.0706983
## 1652   4.8101271
## 1653   4.9129108
## 1654   4.2613721
## 1655   4.2468936
## 1656   4.2706879
## 1657   4.9118915
## 1658   5.0397452
## 1659   3.6551056
## 1660   1.4660082
## 1661   2.5823044
## 1662   4.0047538
## 1663   4.8149800
## 1664   4.4565067
## 1665   5.3384022
## 1666   6.0236181
## 1667   4.9695109
## 1668   3.1857918
## 1669   2.5230636
## 1670   2.7884437
## 1671   6.2974602
## 1672   3.5946986
## 1673   5.8852051
## 1674   6.1539866
## 1675   5.3135378
## 1676   4.1940231
## 1677   6.7129551
## 1678   6.6418678
## 1679   7.5444807
## 1680   6.6572735
## 1681   6.6198980
## 1682   4.2928333
## 1683   5.5683781
## 1684   3.1435474
## 1685   5.7855007
## 1686   3.7989946
## 1687   6.2205751
## 1688   6.0584435
## 1689   6.6230421
## 1690   4.4767716
## 1691   4.3466167
## 1692   3.4530902
## 1693   4.1220493
## 1694   3.0335011
## 1695   5.0896941
## 1696   5.0197351
## 1697   4.5351687
## 1698   3.9210674
## 1699   3.6005052
## 1700   3.5085660
## 1701   3.0908357
## 1702   3.8342255
## 1703   3.3071244
## 1704   2.7960827
## 1705   3.5432531
## 1706   4.2189329
## 1707   3.2448811
## 1708   3.7029345
## 1709   4.5340811
## 1710   6.3268968
## 1711   3.7161714
## 1712   5.0550973
## 1713   3.8109223
## 1714   6.9382915
## 1715   6.6918544
## 1716   6.5243913
## 1717   5.4199487
## 1718   3.3493681
## 1719   5.0007800
## 1720   5.8262832
## 1721   5.6328449
## 1722   4.0276298
## 1723   6.5080843
## 1724   4.2170923
## 1725   4.5055635
## 1726   4.2331645
## 1727   5.1436089
## 1728   2.8459449
## 1729   4.0281989
## 1730   5.5131819
## 1731   5.7733246
## 1732   3.4496359
## 1733   4.1227762
## 1734   3.8516583
## 1735   5.5401141
## 1736   3.9857150
## 1737   4.8025465
## 1738   3.1830255
## 1739   2.9562664
## 1740   3.6932211
## 1741   3.5037737
## 1742   3.4038060
## 1743   4.3612747
## 1744   6.3444816
## 1745   6.0644366
## 1746   4.6347994
## 1747   4.5732787
## 1748   4.8395006
## 1749   4.5991699
## 1750   3.6908764
## 1751   5.4533722
## 1752   3.3030122
## 1753   5.7689372
## 1754   5.3679008
## 1755   4.8262725
## 1756   4.5355861
## 1757   3.2147883
## 1758   2.8050695
## 1759   6.1432430
## 1760   3.3262951
## 1761   2.9969417
## 1762   6.1306552
## 1763   6.3096584
## 1764   6.3684874
## 1765   1.4047528
## 1766   6.6877128
## 1767   4.1028281
## 1768   4.2889954
## 1769   6.5006105
## 1770   5.1728914
## 1771   5.1916272
## 1772   5.6652464
## 1773   5.5269787
## 1774   4.4921899
## 1775   6.0583781
## 1776   3.1292947
## 1777   6.2546370
## 1778   3.5190676
## 1779   3.7765596
## 1780   3.1454943
## 1781   5.1702012
## 1782   3.8741324
## 1783   2.8770397
## 1784   4.2279908
## 1785   3.9772869
## 1786   4.2345378
## 1787   3.5899652
## 1788   5.8862807
## 1789   6.4177227
## 1790   4.3955564
## 1791   4.8993573
## 1792   2.6128468
## 1793   2.4800517
## 1794   3.0396787
## 1795   3.2437672
## 1796   3.4105332
## 1797   5.6354222
## 1798   5.0738647
## 1799   4.9808965
## 1800   3.9118284
## 1801   4.3210064
## 1802   3.6686854
## 1803   3.2241575
## 1804   5.9563670
## 1805   5.9232237
## 1806   5.9100934
## 1807   2.8094934
## 1808   5.3381820
## 1809   2.4359251
## 1810   3.7638421
## 1811   6.1159858
## 1812   5.9533524
## 1813   4.2641845
## 1814   4.0762991
## 1815   2.8997347
## 1816   4.5949249
## 1817   3.3576650
## 1818   4.8837695
## 1819   5.0790956
## 1820   4.2270225
## 1821   4.9236279
## 1822   3.6330317
## 1823   6.0561820
## 1824   4.9046908
## 1825   1.7303620
## 1826   1.0985204
## 1827   3.1624351
## 1828   5.1389127
## 1829   2.7123505
## 1830   4.4165787
## 1831   4.7471355
## 1832   2.6341201
## 1833   3.4210899
## 1834   5.0307041
## 1835   5.1875208
## 1836   5.2464963
## 1837   4.1928740
## 1838   5.1262796
## 1839   5.9937889
## 1840   6.6389768
## 1841   7.6041851
## 1842   5.0009799
## 1843   3.9308301
## 1844   3.4558973
## 1845   5.4062753
## 1846   4.1049939
## 1847   5.7079967
## 1848   5.6808814
## 1849   5.6286796
## 1850   6.5505836
## 1851   5.2735423
## 1852   3.6686039
## 1853   6.3637966
## 1854   2.3568322
## 1855   3.0376498
## 1856   3.2416181
## 1857   3.2635294
## 1858   3.3398443
## 1859   4.8752097
## 1860   4.3864520
## 1861   3.5333448
## 1862   3.9997662
## 1863   4.5861505
## 1864   4.2081068
## 1865   4.0364036
## 1866   3.6433147
## 1867   3.8542446
## 1868   3.4052570
## 1869   2.8361203
## 1870   4.3655353
## 1871   3.7547682
## 1872   3.8745549
## 1873   3.7124881
## 1874   3.2895086
## 1875   3.5537200
## 1876   2.7864526
## 1877   2.8636888
## 1878   3.3341640
## 1879   3.5866871
## 1880   3.7605092
## 1881   3.5417825
## 1882   4.6113235
## 1883   5.1954508
## 1884   5.7283763
## 1885   6.9457677
## 1886   3.0472257
## 1887   2.6923180
## 1888   5.8476782
## 1889   5.4040081
## 1890   6.2036478
## 1891   5.7880763
## 1892   2.6475960
## 1893   5.8434246
## 1894   6.6211556
## 1895   2.6985025
## 1896   3.2492725
## 1897   3.2099009
## 1898   5.1523026
## 1899   3.5056011
## 1900   5.4709445
## 1901   4.9592663
## 1902   3.5765250
## 1903   6.7389263
## 1904   6.4638194
## 1905   6.2498953
## 1906   6.6466515
## 1907   6.0791413
## 1908   6.1030608
## 1909   4.2343763
## 1910   4.2656232
## 1911   3.7375805
## 1912   5.0912360
## 1913   5.7486412
## 1914   5.2599986
## 1915   5.9070908
## 1916   4.3346535
## 1917   4.0823142
## 1918   4.3471945
## 1919   4.3590448
## 1920   5.4696322
## 1921   4.9416685
## 1922   4.9427660
## 1923   2.9301581
## 1924   1.6893174
## 1925   3.8360670
## 1926   4.5641642
## 1927   4.0961734
## 1928   3.1574459
## 1929   3.9081309
## 1930   4.9781213
## 1931   4.4446026
## 1932   4.2438776
## 1933   3.1301590
## 1934   3.0569931
## 1935   1.8438185
## 1936   3.3519898
## 1937   4.4950403
## 1938   4.6476610
## 1939   5.6570601
## 1940   4.4859661
## 1941   5.6281884
## 1942   4.1910683
## 1943   5.6275250
## 1944   4.6605191
## 1945   5.2609781
## 1946   6.3904120
## 1947   6.4051045
## 1948   1.4839308
## 1949   4.1334466
## 1950   1.4486728
## 1951   3.4429320
## 1952   2.3486096
## 1953   4.6611239
## 1954   5.3261543
## 1955   4.8724499
## 1956   6.7453906
## 1957   3.5229635
## 1958   4.7363444
## 1959   2.7357947
## 1960   7.0424293
## 1961   6.7397741
## 1962   5.1798976
## 1963   4.0150399
## 1964   3.8138110
## 1965   5.7379308
## 1966   4.1809722
## 1967   6.2163160
## 1968   4.5540101
## 1969   4.7456411
## 1970   3.1921293
## 1971   3.7312971
## 1972   3.3384922
## 1973   3.5587123
## 1974   3.1985338
## 1975   3.2954289
## 1976   5.2950314
## 1977   4.9128859
## 1978   4.8526496
## 1979   5.1791686
## 1980   3.6706418
## 1981   3.9736296
## 1982   3.6441131
## 1983   6.0455505
## 1984   3.7333845
## 1985   4.6432948
## 1986   4.2238291
## 1987   5.3682820
## 1988   6.1359372
## 1989   3.0841056
## 1990   4.3146193
## 1991   4.6308468
## 1992   3.3622523
## 1993   3.1557273
## 1994   3.9684610
## 1995   5.1036597
## 1996   4.2004484
## 1997   4.6842641
## 1998   3.8262028
## 1999   5.3007592
## 2000   2.8755782
## 2001   5.8243207
## 2002   3.5956342
## 2003   4.3264600
## 2004   3.6066801
## 2005   3.5664029
## 2006   4.1519536
## 2007   4.1117646
## 2008   3.7262361
## 2009   4.2332956
## 2010   5.1988920
## 2011   4.9430121
## 2012   5.2013231
## 2013   5.1116535
## 2014   4.0734951
## 2015   4.5789565
## 2016   4.9440335
## 2017   5.6750137
## 2018   2.8959571
## 2019   4.2035560
## 2020   4.0566240
## 2021   3.0079296
## 2022   2.7480760
## 2023   2.7089097
## 2024   3.7941794
## 2025   3.9249310
## 2026   5.4152645
## 2027   3.0139103
## 2028   6.4519160
## 2029   6.7415945
## 2030   7.3467313
## 2031   3.2779727
## 2032   6.0362286
## 2033   2.3220751
## 2034   5.6843089
## 2035   3.6762560
## 2036   4.5311681
## 2037   4.3714770
## 2038   3.4440069
## 2039   4.9471615
## 2040   2.5978167
## 2041   6.3360671
## 2042   6.0519436
## 2043   4.0751752
## 2044   3.4001666
## 2045   5.2077578
## 2046   4.9069294
## 2047   4.5600949
## 2048   5.1696284
## 2049   3.0912623
## 2050   4.9532886
## 2051   5.6126117
## 2052   4.8933454
## 2053   6.0509243
## 2054   3.8454489
## 2055   3.6324982
## 2056   3.4392455
## 2057   3.9370664
## 2058   5.4304414
## 2059   5.6937487
## 2060   3.7798786
## 2061   4.6127710
## 2062   4.5576768
## 2063   4.5386266
## 2064   3.4904456
## 2065   1.7039320
## 2066   4.9125354
## 2067   4.6648819
## 2068   3.2691914
## 2069   4.2581688
## 2070   3.7466034
## 2071   4.4126214
## 2072   4.2456356
## 2073   4.9132319
## 2074   5.9228249
## 2075   4.5593967
## 2076   4.4216820
## 2077   4.5865972
## 2078   5.2805720
## 2079   4.7070155
## 2080   5.1877991
## 2081   6.3643383
## 2082   4.0609389
## 2083   4.8289501
## 2084   3.7615590
## 2085   5.8606205
## 2086   5.1000451
## 2087   5.8999826
## 2088   5.3703401
## 2089   3.3323894
## 2090   1.9201906
## 2091   2.3668146
## 2092   3.9871534
## 2093   3.8603406
## 2094   5.3041385
## 2095   5.6942216
## 2096   5.8079110
## 2097   5.9843181
## 2098   7.5827684
## 2099   5.3385668
## 2100   5.6153687
## 2101   4.9971756
## 2102   4.8625532
## 2103   4.5021742
## 2104   5.0906145
## 2105   4.3880428
## 2106   4.0270029
## 2107   3.5846954
## 2108   3.4020867
## 2109   5.8282212
## 2110   5.1126214
## 2111   6.0870621
## 2112   4.9265266
## 2113   4.0531820
## 2114   4.1262906
## 2115   2.5056666
## 2116   6.4845973
## 2117   4.0109911
## 2118   4.3175781
## 2119   5.4256144
## 2120   4.4303140
## 2121   5.1281891
## 2122   3.0702331
## 2123   4.9590621
## 2124   2.0867603
## 2125   4.7806343
## 2126   4.6956011
## 2127   2.2732321
## 2128   3.3635638
## 2129   4.3053941
## 2130   4.5438566
## 2131   4.4964972
## 2132   3.8116220
## 2133   2.9480050
## 2134   7.1098252
## 2135   2.7022540
## 2136   2.5377639
## 2137   3.7503577
## 2138   3.7106085
## 2139   3.9121634
## 2140   5.2573804
## 2141   4.9894235
## 2142   5.0256438
## 2143   4.6602058
## 2144   3.7675825
## 2145   5.0296361
## 2146   5.5351875
## 2147   6.5533200
## 2148   2.3419494
## 2149   3.9331052
## 2150   4.5646313
## 2151   4.5470689
## 2152   4.3331345
## 2153   4.0262610
## 2154   4.9793141
## 2155   5.2961153
## 2156   4.7086975
## 2157   5.5733120
## 2158   5.3303809
## 2159   4.3261340
## 2160   3.8571276
## 2161   5.9464844
## 2162   3.7771987
## 2163   4.9723342
## 2164   5.5140634
## 2165   4.7378483
## 2166   4.7463847
## 2167   6.4597334
## 2168   2.8334985
## 2169   5.4327764
## 2170   5.6311743
## 2171   3.3741421
## 2172   5.3460457
## 2173   4.3136006
## 2174   4.4671641
## 2175   4.6463652
## 2176   4.1707190
## 2177   3.8962037
## 2178   3.8077160
## 2179   5.5109099
## 2180   3.2305270
## 2181   4.9529092
## 2182   5.5124169
## 2183   5.3079496
## 2184   5.0050700
## 2185   5.5927677
## 2186   2.5263487
## 2187   4.7026333
## 2188   6.1533148
## 2189   5.3517578
## 2190   3.7555335
## 2191   3.5707462
## 2192   1.8773272
## 2193   0.9459378
## 2194   2.4908055
## 2195   3.3455050
## 2196   4.2885534
## 2197   4.7242973
## 2198   4.1462793
## 2199   4.6737224
## 2200   3.8922170
## 2201   3.5650082
## 2202   2.7709088
## 2203   4.5401595
## 2204   4.5767331
## 2205   4.0821185
## 2206   4.7261982
## 2207   4.1848988
## 2208   5.4978067
## 2209   5.2157531
## 2210   4.6355109
## 2211   3.1405114
## 2212   4.7333021
## 2213   5.6129613
## 2214   5.6970797
## 2215   5.6248857
## 2216   5.2725656
## 2217   4.9266281
## 2218   4.9965075
## 2219   3.8917789
## 2220   3.7609052
## 2221   3.0509674
## 2222   3.2829640
## 2223   3.9543433
## 2224   4.7320938
## 2225   4.8923381
## 2226   3.8155798
## 2227   4.3214412
## 2228   5.5048326
## 2229   5.5762343
## 2230   4.4843855
## 2231   5.3866394
## 2232   3.9292079
## 2233   4.9576021
## 2234   4.8368876
## 2235   5.5967718
## 2236   2.0683320
## 2237   4.3277129
## 2238   4.7102884
## 2239   4.3654516
## 2240   4.4416128
## 2241   3.4072033
## 2242   5.5169835
## 2243   5.1603749
## 2244   2.5891813
## 2245   3.5813362
## 2246   4.2767431
## 2247   2.9222048
## 2248   3.6746077
## 2249   5.0841400
## 2250   5.4199358
## 2251   4.2301975
## 2252   4.6025674
## 2253   1.8561131
## 2254   6.2760504
## 2255   4.8246624
## 2256   4.7011539
## 2257   5.6627220
## 2258   4.2537660
## 2259   6.1157362
## 2260   5.6652892
## 2261   6.6554648
## 2262   6.7777544
## 2263   2.1845887
## 2264   3.8228926
## 2265   5.5168937
## 2266   3.0524033
## 2267   4.8528805
## 2268   5.2846603
## 2269   3.6327850
## 2270   4.4506576
## 2271   5.9673345
## 2272   5.4713625
## 2273   2.6112493
## 2274   2.1784039
## 2275   1.8930730
## 2276   3.9743491
## 2277   4.2366067
## 2278   3.9182086
## 2279   3.2301753
## 2280   4.1253919
## 2281   2.6292967
## 2282   5.3200634
## 2283   5.1121309
## 2284   4.4558279
## 2285   4.0087459
## 2286   5.0896332
## 2287   5.3932927
## 2288   3.9782945
## 2289   3.9510837
## 2290   4.2737620
## 2291   3.0958331
## 2292   5.7423193
## 2293   4.2725420
## 2294   3.7821904
## 2295   2.9812784
## 2296   3.2981875
## 2297   2.9308294
## 2298   5.1327018
## 2299   5.0470265
## 2300   4.2800943
## 2301   3.7404528
## 2302   3.0169441
## 2303   2.5835699
## 2304   3.0043029
## 2305   4.8883375
## 2306   6.1180837
## 2307   5.0675950
## 2308   5.6182390
## 2309   5.5945842
## 2310   6.6136684
## 2311   6.2696990
## 2312   5.9581515
## 2313   3.2025356
## 2314   5.0623056
## 2315   5.0376465
## 2316   6.0920439
## 2317   6.8769950
## 2318   5.6090604
## 2319   5.0924521
## 2320   4.0636265
## 2321   3.0022986
## 2322   2.9720373
## 2323   2.5798853
## 2324   3.8090262
## 2325   3.8943667
## 2326   3.6259061
## 2327   3.6884820
## 2328   5.6773578
## 2329   4.0114326
## 2330   3.9899787
## 2331   3.6402954
## 2332   4.4895127
## 2333   4.5778307
## 2334   3.5637600
## 2335   4.2614631
## 2336   4.6234896
## 2337   5.7984466
## 2338   3.1225587
## 2339   3.4541518
## 2340   4.4798361
## 2341   2.8556159
## 2342   2.6636332
## 2343   4.9198354
## 2344   4.4223170
## 2345   4.6421671
## 2346   4.2882436
## 2347   3.5377237
## 2348   4.4905159
## 2349   3.5799331
## 2350   3.0448210
## 2351   3.8513769
## 2352   3.7908611
## 2353   4.5069974
## 2354   4.2566440
## 2355   4.0054844
## 2356   5.0646124
## 2357   3.6121742
## 2358   3.8917140
## 2359   3.5768793
## 2360   2.2869643
## 2361   4.8639047
## 2362   3.6070391
## 2363   5.3957257
## 2364   1.6690984
## 2365   4.2648418
## 2366   3.2458176
## 2367   3.5084274
## 2368   5.2084989
## 2369   4.2339850
## 2370   5.9069559
## 2371   4.7438238
## 2372   2.5851285
## 2373   1.8460155
## 2374   4.6738765
## 2375   6.0393752
## 2376   5.9307907
## 2377   5.6941322
## 2378   5.2325517
## 2379   5.3759026
## 2380   5.1904433
## 2381   3.6157765
## 2382   5.1630470
## 2383   4.6906532
## 2384   5.8439738
## 2385   5.6051156
## 2386   2.5854946
## 2387   3.5539906
## 2388   2.9400336
## 2389   5.4707119
## 2390   5.0935089
## 2391   5.8389232
## 2392   4.5107547
## 2393   4.5585105
## 2394   3.2971530
## 2395   4.7686560
## 2396   4.5948097
## 2397   4.6169157
## 2398   5.1000217
## 2399   6.4117341
## 2400   5.7093344
## 2401   2.9206295
## 2402   3.0701289
## 2403   3.3742008
## 2404   2.1322362
## 2405   3.1304807
## 2406   3.6087101
## 2407   4.1360562
## 2408   4.5183640
## 2409   4.7603403
## 2410   6.7957169
## 2411   2.8825471
## 2412   3.8293549
## 2413   4.7793423
## 2414   4.0395391
## 2415   4.6386996
## 2416   5.7457639
## 2417   5.4048362
## 2418   4.1143394
## 2419   4.0195478
## 2420   4.3680767
## 2421   4.1239141
## 2422   2.5679935
## 2423   5.5172462
## 2424   3.1361084
## 2425   2.2855442
## 2426   4.6604842
## 2427   4.0601785
## 2428   3.4319546
## 2429   2.1951519
## 2430   3.8078879
## 2431   3.8696216
## 2432   4.7523073
## 2433   4.2561022
## 2434   4.3072921
## 2435   3.5886300
## 2436   3.4519827
## 2437   3.8694318
## 2438   3.7875102
## 2439   3.0330244
## 2440   3.0897365
## 2441   4.0804218
## 2442   4.6652329
## 2443   4.0113664
## 2444   4.3650332
## 2445   4.5765835
## 2446   4.7539099
## 2447   5.1533051
## 2448   6.8499012
## 2449   6.3714572
## 2450   4.4189020
## 2451   3.2897860
## 2452   4.1750633
## 2453   4.1217413
## 2454   2.8173015
## 2455   4.0340203
## 2456   4.3080409
## 2457   5.1627677
## 2458   5.0665376
## 2459   4.0567866
## 2460   4.2727549
## 2461   3.6786357
## 2462   3.7707913
## 2463   4.1947774
## 2464   3.5688667
## 2465   4.2465093
## 2466   3.7498758
## 2467   5.8315019
## 2468   3.7232309
## 2469   3.2100244
## 2470   5.2795222
## 2471   1.9465958
## 2472   4.4944095
## 2473   4.8768562
## 2474   4.1387267
## 2475   4.1469858
## 2476   2.5983585
## 2477   2.7013319
## 2478   2.9887766
## 2479   4.7296699
## 2480   2.2114493
## 2481   2.1510503
## 2482   2.4766019
## 2483   6.0859018
## 2484   4.6071582
## 2485   4.6012385
## 2486   6.7470027
## 2487   4.2091542
## 2488   4.4252314
## 2489   3.6780537
## 2490   3.8531446
## 2491   2.8917234
## 2492   6.4702548
## 2493   3.1139009
## 2494   2.3161801
## 2495   4.7317085
## 2496   1.7318639
## 2497   2.9898349
## 2498   2.2963485
## 2499   1.5232200
## 2500   3.9136328
## 2501   3.0191812
## 2502   4.2322151
## 2503   4.5122743
## 2504   3.4960406
## 2505   4.3422236
## 2506   4.5665501
## 2507   3.8478226
## 2508   3.9313773
## 2509   3.3656654
## 2510   3.3772071
## 2511   2.9565836
## 2512   5.7873513
## 2513   6.4558829
## 2514   4.1476677
## 2515   4.0906711
## 2516   6.7531002
## 2517   5.3265332
## 2518   3.8641056
## 2519   3.7799334
## 2520   3.2920081
## 2521   3.1017608
## 2522   4.5655559
## 2523   4.2027722
## 2524   3.9425948
## 2525   3.3190906
## 2526   4.1266964
## 2527   4.9701155
## 2528   4.2072515
## 2529   4.6303334
## 2530   3.5875803
## 2531   6.0670636
## 2532   5.4812931
## 2533   3.6540722
## 2534   4.5008325
## 2535   2.8784292
## 2536   2.1647966
## 2537   3.2925004
## 2538   4.5059121
## 2539   3.4689500
## 2540   3.6966489
## 2541   5.3742676
## 2542   5.0040919
## 2543   5.7577844
## 2544   3.0932530
## 2545   2.8769720
## 2546   4.9554836
## 2547   4.6722947
## 2548   5.8785220
## 2549   6.1360991
## 2550   5.6988777
## 2551   4.7280096
## 2552   4.4491875
## 2553   5.8906681
## 2554   5.7964579
## 2555   6.1029844
## 2556   5.6279517
## 2557   5.4513445
## 2558   5.3132526
## 2559   4.2946094
## 2560   4.5098165
## 2561   3.4866792
## 2562   4.9378416
## 2563   7.2505852
## 2564   6.8985659
## 2565   5.8610407
## 2566   4.0739795
## 2567   3.2370798
## 2568   6.3676003
## 2569   2.3597151
## 2570   3.1161264
## 2571   2.8991143
## 2572   6.2226315
## 2573   5.8873452
## 2574   4.4245120
## 2575   3.9657365
## 2576   4.6438916
## 2577   4.7198001
## 2578   4.9916628
## 2579   4.3631194
## 2580   3.9786063
## 2581   5.9399841
## 2582   3.5961306
## 2583   3.3013179
## 2584   4.9102460
## 2585   4.3700873
## 2586   5.1261800
## 2587   4.5126862
## 2588   2.4852453
## 2589   3.6721134
## 2590   3.6078390
## 2591   3.9455269
## 2592   4.4702563
## 2593   4.1998627
## 2594   4.1476482
## 2595   3.7948207
## 2596   2.4755355
## 2597   3.8350865
## 2598   3.5048610
## 2599   5.3735707
## 2600   6.7258636
## 2601   3.2040049
## 2602   3.8371056
## 2603   5.2298804
## 2604   3.6350128
## 2605   3.4671210
## 2606   5.2424702
## 2607   3.5691517
## 2608   3.7134467
## 2609   5.7779566
## 2610   4.5597773
## 2611   4.3287734
## 2612   3.6642648
## 2613   3.7740751
## 2614   4.5371858
## 2615   3.7436611
## 2616   3.8354066
## 2617   3.7721361
## 2618   2.8948884
## 2619   2.6579343
## 2620   6.3897561
## 2621   4.6426308
## 2622   4.9946621
## 2623   3.1442451
## 2624   5.3527797
## 2625   2.4402664
## 2626   5.7946058
## 2627   4.4521250
## 2628   1.8293899
## 2629   7.7717444
## 2630   1.9343391
## 2631   3.2549593
## 2632   3.1078141
## 2633   4.1818464
## 2634   6.4927707
## 2635   7.4104240
## 2636   4.3308999
## 2637   6.3825582
## 2638   4.4324161
## 2639   3.6673446
## 2640   3.4897474
## 2641   5.1304603
## 2642   5.4451222
## 2643   2.3706966
## 2644   3.3542064
## 2645   4.2418299
## 2646   4.7920883
## 2647   4.2447672
## 2648   4.2781059
## 2649   4.8740973
## 2650   4.6399994
## 2651   5.8315323
## 2652   4.0048233
## 2653   5.6338214
## 2654   4.2429018
## 2655   3.5623892
## 2656   5.3381410
## 2657   5.3864633
## 2658   5.6156028
## 2659   5.1563822
## 2660   4.8291625
## 2661   2.7822549
## 2662   2.1489599
## 2663   4.5751480
## 2664   5.2506898
## 2665   3.3184695
## 2666   6.4960530
## 2667   6.8064102
## 2668   4.6452676
## 2669   5.0311473
## 2670   4.6138016
## 2671   4.2803227
## 2672   3.2005817
## 2673   5.2726735
## 2674   4.3377187
## 2675   3.7309450
## 2676   4.3642107
## 2677   4.9015908
## 2678   6.4731625
## 2679   2.6112011
## 2680   3.1128563
## 2681   2.2921873
## 2682   5.6274233
## 2683   4.1726495
## 2684   5.7590960
## 2685   4.8858495
## 2686   6.0356305
## 2687   5.9116942
## 2688   2.8275597
## 2689   5.1604878
## 2690   6.3483171
## 2691   3.6415439
## 2692   3.9289902
## 2693   3.8176661
## 2694   4.0344423
## 2695   4.0117792
## 2696   5.0187306
## 2697   6.3072463
## 2698   3.9663936
## 2699   4.9007780
## 2700   4.9331055
## 2701   6.8008100
## 2702   3.8772733
## 2703   6.9806626
## 2704   6.0904148
## 2705   5.7692935
## 2706   3.2781148
## 2707   4.2946863
## 2708   5.7383523
## 2709   4.0552031
## 2710   2.3520710
## 2711   1.8283303
## 2712   2.2804583
## 2713   4.6419175
## 2714   3.2594247
## 2715   3.9361931
## 2716   4.1473200
## 2717   3.3861413
## 2718   3.5550355
## 2719   4.7811627
## 2720   4.5220214
## 2721   2.7752595
## 2722   3.0868793
## 2723   3.6910862
## 2724   4.6011462
## 2725   4.5513447
## 2726   4.3828331
## 2727   3.6264506
## 2728   3.4823136
## 2729   3.1314949
## 2730   3.3767721
## 2731   1.0025989
## 2732   4.2395358
## 2733   4.2682174
## 2734   4.4924037
## 2735   5.4715914
## 2736   6.8536054
## 2737   2.8379167
## 2738   4.2732429
## 2739   3.1463330
## 2740   2.0561737
## 2741   3.2697835
## 2742   4.8328398
## 2743   6.4504381
## 2744   6.6194635
## 2745   5.8954300
## 2746   2.7752742
## 2747   2.8497129
## 2748   3.0386305
## 2749   3.9175743
## 2750   3.8482339
## 2751   4.9029151
## 2752   2.9518533
## 2753   2.5380376
## 2754   3.8824403
## 2755   4.4975403
## 2756   4.2670965
## 2757   4.8329108
## 2758   4.1133774
## 2759   5.2020853
## 2760   4.9871680
## 2761   4.6477243
## 2762   3.2863177
## 2763   3.5930089
## 2764   3.6057641
## 2765   3.8047405
## 2766   4.1107199
## 2767   5.2496667
## 2768   5.0487701
## 2769   5.0081986
## 2770   4.1972066
## 2771   3.7835707
## 2772   5.0309051
## 2773   3.2249551
## 2774   3.4288511
## 2775   5.5257754
## 2776   3.2914097
## 2777   5.0515048
## 2778   5.0267552
## 2779   4.7285876
## 2780   4.5798652
## 2781   4.3974286
## 2782   3.6644726
## 2783   3.3887243
## 2784   3.8043229
## 2785   3.1603800
## 2786   4.3659154
## 2787   7.0959892
## 2788   3.4876701
## 2789   3.7290275
## 2790   3.7558112
## 2791   3.0035802
## 2792   5.7387593
## 2793   2.7481861
## 2794   6.6743620
## 2795   4.4247293
## 2796   3.5416018
## 2797   3.2553107
## 2798   4.4949424
## 2799   3.3114858
## 2800   3.9136364
## 2801   5.4358743
## 2802   2.9675764
## 2803   3.3607643
## 2804   3.7731978
## 2805   4.1734259
## 2806   4.6026057
## 2807   2.6867894
## 2808   4.7220027
## 2809   2.8335988
## 2810   5.0746582
## 2811   3.1235934
## 2812   3.4833778
## 2813   2.2888298
## 2814   2.2053102
## 2815   2.9136247
## 2816   4.6236866
## 2817   4.2899017
## 2818   5.0883515
## 2819   4.0944080
## 2820   4.7463395
## 2821   3.6720229
## 2822   2.8262068
## 2823   4.2329950
## 2824   2.8646108
## 2825   4.6110786
## 2826   5.0038035
## 2827   4.7678118
## 2828   4.4054303
## 2829   6.0300018
## 2830   5.9501983
## 2831   4.6767996
## 2832   3.5638316
## 2833   4.5426308
## 2834   3.7266830
## 2835   4.2405399
## 2836   6.3627351
## 2837   6.4385689
## 2838   4.4230266
## 2839   4.6067873
## 2840   4.6869545
## 2841   5.3983389
## 2842   3.9412738
## 2843   3.1054151
## 2844   3.4918359
## 2845   4.2732819
## 2846   2.2956904
## 2847   3.7811772
## 2848   3.6719316
## 2849   4.8706251
## 2850   4.2212867
## 2851   4.8182307
## 2852   4.6976203
## 2853   3.6750978
## 2854   3.2414994
## 2855   1.3685496
## 2856   2.8503774
## 2857   5.2910296
## 2858   6.5555384
## 2859   4.1245905
## 2860   3.2461342
## 2861   5.6048138
## 2862   3.5955584
## 2863   3.7390286
## 2864   3.8719484
## 2865   6.4631805
## 2866   3.4991519
## 2867   4.2360701
## 2868   4.0440461
## 2869   4.9552465
## 2870   5.0663000
## 2871   3.3188898
## 2872   2.8469624
## 2873   2.2066005
## 2874   3.9306091
## 2875   4.8195571
## 2876   4.6467547
## 2877   2.6057827
## 2878   4.4304300
## 2879   4.2251563
## 2880   1.8013558
## 2881   2.7839925
## 2882   2.6646991
## 2883   3.3532703
## 2884   4.1036787
## 2885   3.5951498
## 2886   4.3470375
## 2887   6.4792945
## 2888   6.6193069
## 2889   3.8931879
## 2890   3.9445699
## 2891   4.1473037
## 2892   5.6419831
## 2893   3.6364081
## 2894   3.4009580
## 2895   3.8651011
## 2896   5.0630754
## 2897   3.8854901
## 2898   3.9398842
## 2899   6.0639400
## 2900   4.9868336
## 2901   4.5802138
## 2902   4.6656794
## 2903   3.5955889
## 2904   6.7876160
## 2905   6.3799698
## 2906   6.4785869
## 2907   7.4129195
## 2908   6.6489090
## 2909   4.7636900
## 2910   4.7641522
## 2911   5.8178790
## 2912   4.5614068
## 2913   4.1106062
## 2914   4.5156086
## 2915   4.2840242
## 2916   5.1189935
## 2917   4.0736761
## 2918   2.6793634
## 2919   4.0786668
## 2920   5.6428874
## 2921   5.1913170
## 2922   5.2904210
## 2923   4.8818735
## 2924   4.0189530
## 2925   4.3271764
## 2926   4.2729467
## 2927   4.5053243
## 2928   3.6348177
## 2929   4.5932419
## 2930   4.2481065
## 2931   4.3969449
## 2932   4.2103881
## 2933   3.8131916
## 2934   4.1212002
## 2935   4.9919219
## 2936   5.0092550
## 2937   2.2422419
## 2938   4.2236759
## 2939   3.2870761
## 2940   2.9314835
## 2941   2.7207464
## 2942   2.9083019
## 2943   3.6482998
## 2944   4.2573265
## 2945   3.0952719
## 2946   2.7882203
## 2947   4.3486897
## 2948   2.4218191
## 2949   4.8368377
## 2950   5.4293034
## 2951   4.3456694
## 2952   4.8767207
## 2953   5.0435538
## 2954   5.7181702
## 2955   3.0183628
## 2956   3.6852981
## 2957   7.0287795
## 2958   3.3071858
## 2959   4.5335345
## 2960   4.3134257
## 2961   3.0360983
## 2962   6.3821301
## 2963   7.4843192
## 2964   2.8640952
## 2965   4.4732934
## 2966   5.3793244
## 2967   4.8339447
## 2968   4.1173004
## 2969   2.6877942
## 2970   4.3632905
## 2971   1.8730686
## 2972   4.5433023
## 2973   5.9320540
## 2974   6.1931906
## 2975   4.4161007
## 2976   6.5609265
## 2977   7.0559908
## 2978   2.7603182
## 2979   5.1092158
## 2980   2.9297429
## 2981   3.5195167
## 2982   3.8653167
## 2983   5.4931610
## 2984   4.8255857
## 2985   4.4796326
## 2986   4.2036335
## 2987   3.0378033
## 2988   4.6378716
## 2989   3.4001181
## 2990   3.0302095
## 2991   2.1489864
## 2992   4.6992871
## 2993   3.3644101
## 2994   3.2550836
## 2995   3.6239128
## 2996   3.7318192
## 2997   4.6628471
## 2998   2.7591504
## 2999   5.3627892
## 3000   3.3049084
## 3001   6.2872034
## 3002   5.1228150
## 3003   6.3106964
## 3004   4.0830741
## 3005   4.8787351
## 3006   4.6326205
## 3007   3.6098837
## 3008   5.2231103
## 3009   2.0988225
## 3010   4.0980494
## 3011   5.2381088
## 3012   5.0036368
## 3013   3.6932204
## 3014   4.4517017
## 3015   3.8264413
## 3016   5.6560362
## 3017   3.4521625
## 3018   3.1350337
## 3019   2.7025350
## 3020   3.2301113
## 3021   4.6486223
## 3022   3.3335689
## 3023   4.4396215
## 3024   5.7028978
## 3025   4.6454916
## 3026   5.9266833
## 3027   5.6843638
## 3028   5.5664948
## 3029   5.1782529
## 3030   4.3521072
## 3031   3.5433810
## 3032   2.6155255
## 3033   3.1325188
## 3034   3.1195180
## 3035   2.9642752
## 3036   5.2550154
## 3037   3.6739854
## 3038   3.5545931
## 3039   3.8534230
## 3040   3.9324640
## 3041   2.8367844
## 3042   4.7040952
## 3043   5.1126434
## 3044   7.3876378
## 3045   4.9021734
## 3046   6.8604372
## 3047   6.7065870
## 3048   6.2485545
## 3049   4.1436793
## 3050   5.9005774
## 3051   6.5461376
## 3052   5.9825405
## 3053   5.5080743
## 3054   6.2624558
## 3055   2.5622125
## 3056   4.1379970
## 3057   3.8098306
## 3058   6.1272070
## 3059   2.8295566
## 3060   4.8564977
## 3061   3.9437967
## 3062   4.2045117
## 3063   5.5070665
## 3064   7.8894586
## 3065   6.5121533
## 3066   4.9536982
## 3067   6.2981853
## 3068   2.4421215
## 3069   3.5554180
## 3070   7.2619594
## 3071   7.2473463
## 3072   6.3333305
## 3073   5.6984565
## 3074   5.2936198
## 3075   3.1737514
## 3076   5.9886899
## 3077   4.9339792
## 3078   4.2440306
## 3079   4.4042666
## 3080   2.9037168
## 3081   3.3132646
## 3082   3.1527857
## 3083   2.0706058
## 3084   1.9427071
## 3085   4.8802706
## 3086   5.6189470
## 3087   4.1517729
## 3088   5.1665336
## 3089   5.4870791
## 3090   5.9003315
## 3091   2.0749825
## 3092   3.7257456
## 3093   4.3905687
## 3094   3.7623819
## 3095   4.2994699
## 3096   8.7779626
## 3097   6.4104896
## 3098   5.3411737
## 3099   4.7500514
## 3100   3.5112863
## 3101   4.3683503
## 3102   3.5361933
## 3103   4.1227402
## 3104   3.6412496
## 3105   2.4353405
## 3106   2.6216174
## 3107   4.6767803
## 3108   6.8355635
## 3109   4.5421651
## 3110   3.7848901
## 3111   4.0090918
## 3112   4.1470598
## 3113   4.3887100
## 3114   4.1333302
## 3115   5.2748507
## 3116   4.8504260
## 3117   4.1515212
## 3118   3.2287588
## 3119   5.5640653
## 3120   3.7368681
## 3121   3.4574360
## 3122   4.7101549
## 3123   5.4268374
## 3124   5.7883863
## 3125   5.8629362
## 3126   3.8531538
## 3127   2.7338418
## 3128   4.1865225
## 3129   4.2810369
## 3130   4.1049466
## 3131   4.7401199
## 3132   2.4565330
## 3133   3.6390279
## 3134   4.1100517
## 3135   4.0012608
## 3136   3.7252070
## 3137   3.8975287
## 3138   3.6713778
## 3139   4.1429001
## 3140   4.8316906
## 3141   5.0622422
## 3142   3.7882988
## 3143   2.2986603
## 3144   7.4144500
## 3145   6.1850490
## 3146   4.0282387
## 3147   4.9693306
## 3148   4.1081359
## 3149   2.6004862
## 3150   2.9889030
## 3151   2.0264617
## 3152   5.1498177
## 3153   5.7522749
## 3154   4.2079465
## 3155   6.3873822
## 3156   4.2178939
## 3157   2.9316225
## 3158   3.1307917
## 3159   4.8484620
## 3160   4.0347043
## 3161   4.0432192
## 3162   3.2091827
## 3163   4.2731495
## 3164   4.4276648
## 3165   2.9405462
## 3166   2.6748024
## 3167   4.1990606
## 3168   5.5495925
## 3169   4.0020614
## 3170   3.8968846
## 3171   4.3953341
## 3172   4.2803848
## 3173   5.5417720
## 3174   4.6083064
## 3175   6.5510333
## 3176   6.6794974
## 3177   5.7826175
## 3178   2.9322411
## 3179   3.9643644
## 3180   3.7083837
## 3181   1.7853071
## 3182   2.0954593
## 3183   5.6089148
## 3184   6.1443794
## 3185   4.3542949
## 3186   4.7637252
## 3187   2.7886520
## 3188   2.2471561
## 3189   2.5945106
## 3190   5.2315547
## 3191   4.6736991
## 3192   3.6949048
## 3193   5.1409949
## 3194   3.9726858
## 3195   4.4347655
## 3196   4.3193342
## 3197   4.6516460
## 3198   4.2340027
## 3199   3.1364844
## 3200   3.1114351
## 3201   2.3570128
## 3202   1.9872816
## 3203   1.7044259
## 3204   4.6542633
## 3205   4.2604948
## 3206   4.1144915
## 3207   3.8705583
## 3208   5.0470979
## 3209   5.1171411
## 3210   3.2360856
## 3211   3.9779847
## 3212   5.3046441
## 3213   4.0909504
## 3214   2.3444216
## 3215   4.5881085
## 3216   2.4897571
## 3217   3.1529877
## 3218   1.0217443
## 3219   4.3966686
## 3220   4.0384275
## 3221   4.7193411
## 3222   4.7284776
## 3223   4.2447171
## 3224   4.0272011
## 3225   4.7381165
## 3226   4.4645353
## 3227   4.7041755
## 3228   4.9150436
## 3229   5.1562450
## 3230   5.0316591
## 3231   5.7002307
## 3232   5.7939047
## 3233   3.3608251
## 3234   6.3786454
## 3235   3.4441705
## 3236   4.6405608
## 3237   4.1469917
## 3238   4.2341288
## 3239   4.6419990
## 3240   4.7344432
## 3241   5.4499523
## 3242   5.1438621
## 3243   5.7892932
## 3244   6.3449114
## 3245   4.6756648
## 3246   4.5785119
## 3247   4.6685400
## 3248   3.9423407
## 3249   3.4831511
## 3250   4.4054048
## 3251   4.8714819
## 3252   4.5742592
## 3253   5.1514191
## 3254   6.0437039
## 3255   3.2429057
## 3256   2.2619365
## 3257   3.0769795
## 3258   4.9777688
## 3259   3.1361839
## 3260   3.2433142
## 3261   5.9849442
## 3262   8.1847411
## 3263   8.4686181
## 3264   5.3370297
## 3265   5.1802432
## 3266   3.3750567
## 3267   1.9529449
## 3268   2.5465726
## 3269   3.9432193
## 3270   5.6587961
## 3271   5.6129034
## 3272   5.3444286
## 3273   4.6373344
## 3274   5.3470912
## 3275   6.0320611
## 3276   3.3723361
## 3277   4.4043362
## 3278   5.0683900
## 3279   5.0695882
## 3280   3.5127904
## 3281   4.8134156
## 3282   2.4262725
## 3283   3.1850353
## 3284   2.4319492
## 3285   3.8085324
## 3286   3.9944685
## 3287   1.6680110
## 3288   6.7736525
## 3289   5.4798630
## 3290   3.6820384
## 3291   4.0162775
## 3292   6.5309927
## 3293   7.0272676
## 3294   7.4845028
## 3295   2.6808929
## 3296   4.7480459
## 3297   3.3643194
## 3298   3.8697876
## 3299   4.2775383
## 3300   3.8690233
## 3301   4.3415707
## 3302   5.6204417
## 3303   4.9657913
## 3304   7.1112071
## 3305   6.6157738
## 3306   5.7487798
## 3307   6.0491623
## 3308   5.9959053
## 3309   5.7594890
## 3310   3.5055418
## 3311   3.9423360
## 3312   3.6255152
## 3313   6.4208841
## 3314   4.6816050
## 3315   3.5524841
## 3316   4.8032335
## 3317   4.3909525
## 3318   6.5289899
## 3319   5.2964284
## 3320   4.4726184
## 3321   3.8181133
## 3322   4.7169023
## 3323   4.7820162
## 3324   4.5197492
## 3325   3.9302745
## 3326   3.7717887
## 3327   2.8387403
## 3328   3.8617262
## 3329   3.2713325
## 3330   3.0815061
## 3331   4.2747921
## 3332   4.0251593
## 3333   4.7033011
## 3334   4.1415038
## 3335   4.4273854
## 3336   5.3184168
## 3337   2.8422543
## 3338   5.4747075
## 3339   3.1378894
## 3340   2.7077155
## 3341   5.3930196
## 3342   6.3715850
## 3343   5.0848096
## 3344   4.2573589
## 3345   4.6532338
## 3346   3.2825724
## 3347   3.8732815
## 3348   4.3698018
## 3349   3.7428778
## 3350   5.4103854
## 3351   3.6749429
## 3352   6.3824621
## 3353   2.9662403
## 3354   3.5407341
## 3355   4.0598899
## 3356   4.5073645
## 3357   4.0592040
## 3358   5.1011385
## 3359   4.3341228
## 3360   3.7446846
## 3361   4.7286371
## 3362   2.6083458
## 3363   3.7940215
## 3364   3.6120304
## 3365   3.7657987
## 3366   4.5966399
## 3367   3.3348186
## 3368   3.1015778
## 3369   4.3416988
## 3370   3.9836655
## 3371   5.2711727
## 3372   3.5128309
## 3373   3.5125544
## 3374   4.4045767
## 3375   4.0654563
## 3376   4.2424859
## 3377   4.0006319
## 3378   3.7542166
## 3379   4.3497412
## 3380   3.9688107
## 3381   3.0558715
## 3382   3.5040723
## 3383   1.8879421
## 3384   5.0162542
## 3385   4.2530498
## 3386   6.2833734
## 3387   4.8716347
## 3388   4.8891617
## 3389   4.9756546
## 3390   5.1792155
## 3391   5.1081897
## 3392   3.4229799
## 3393   4.3765302
## 3394   4.4186275
## 3395   5.9793020
## 3396   3.5593526
## 3397   5.5934373
## 3398   4.0289976
## 3399   1.7414021
## 3400   4.6826125
## 3401   5.4816650
## 3402   3.6046756
## 3403   2.3040741
## 3404   2.9444428
## 3405   3.9223686
## 3406   4.9733846
## 3407   2.7864356
## 3408   1.8284911
## 3409   3.4882780
## 3410   5.6492769
## 3411   5.8296007
## 3412   3.8896757
## 3413   2.7425932
## 3414   4.6164739
## 3415   4.9042340
## 3416   3.7490325
## 3417   5.1889110
## 3418   4.6863746
## 3419   2.3624445
## 3420   5.6841995
## 3421   3.6981884
## 3422   3.6465941
## 3423   3.5094031
## 3424   2.8997263
## 3425   4.9789977
## 3426   3.5842777
## 3427   3.7693390
## 3428   3.8616120
## 3429   2.8468319
## 3430   5.9614346
## 3431   4.7961504
## 3432   2.3209084
## 3433   2.8796314
## 3434   2.5876003
## 3435   2.6539607
## 3436   2.5759610
## 3437   3.7041174
## 3438   3.4083249
## 3439   4.2275118
## 3440   3.4461359
## 3441   4.8203583
## 3442   3.5025496
## 3443   2.9847047
## 3444   3.4157880
## 3445   4.5488185
## 3446   5.0543222
## 3447   3.0236163
## 3448   4.3985892
## 3449   3.7300446
## 3450   3.8869607
## 3451   4.2124365
## 3452   3.4790581
## 3453   3.2505266
## 3454   5.3927231
## 3455   3.3652635
## 3456   5.6323563
## 3457   4.6064367
## 3458   4.9984685
## 3459   4.9552363
## 3460   4.8739944
## 3461   3.5112676
## 3462   1.4256031
## 3463   3.2287808
## 3464   6.2519710
## 3465   6.5198403
## 3466   3.6430871
## 3467   4.6853817
## 3468   5.7702726
## 3469   6.0767940
## 3470   4.8536526
## 3471   3.7635086
## 3472   2.5689325
## 3473   2.6822107
## 3474   2.6146125
## 3475   3.7473706
## 3476   5.0508463
## 3477   4.6954493
## 3478   1.8618132
## 3479   5.9462923
## 3480   4.3135803
## 3481   3.2515572
## 3482   7.6320506
## 3483   4.3948986
## 3484   3.8294244
## 3485   5.3060095
## 3486   5.5127451
## 3487   5.6009186
## 3488   6.5066657
## 3489   4.8336258
## 3490   3.9890525
## 3491   4.9727355
## 3492   4.9489398
## 3493   3.6913778
## 3494   4.6980104
## 3495   4.6201926
## 3496   2.6920985
## 3497   3.4308126
## 3498   5.0045161
## 3499   4.6012400
## 3500   4.1390522
## 3501   3.5531845
## 3502   5.8225160
## 3503   6.6456374
## 3504   7.1422562
## 3505   2.5645212
## 3506   3.8049339
## 3507   4.7582565
## 3508   4.8479139
## 3509   4.7678763
## 3510   5.4935350
## 3511   5.3232608
## 3512   3.3496579
## 3513   3.0697958
## 3514   4.1972452
## 3515   4.3924094
## 3516   5.8030894
## 3517   4.2542893
## 3518   6.2211164
## 3519   3.0186113
## 3520   3.1761010
## 3521   3.1993100
## 3522   4.3824922
## 3523   4.1708109
## 3524   5.7208899
## 3525   6.1904109
## 3526   4.2465668
## 3527   4.2455693
## 3528   4.2603039
## 3529   3.7818337
## 3530   4.4042035
## 3531   5.7733556
## 3532   3.8111190
## 3533   3.0474420
## 3534   3.9209895
## 3535   2.3267391
## 3536   1.9479854
## 3537   3.6663633
## 3538   2.7102086
## 3539   4.4369365
## 3540   5.5995109
## 3541   3.2881222
## 3542   5.6631875
## 3543   3.2279044
## 3544   2.6718717
## 3545   4.0505712
## 3546   2.0820101
## 3547   4.9864070
## 3548   4.5746469
## 3549   3.8118844
## 3550   4.8448829
## 3551   3.7683287
## 3552   4.3555707
## 3553   3.2939413
## 3554   3.6463732
## 3555   4.9230398
## 3556   5.1573509
## 3557   5.9593234
## 3558   5.3038577
## 3559   5.3304757
## 3560   3.5580902
## 3561   5.7997135
## 3562   6.0003831
## 3563   3.2101926
## 3564   3.8912873
## 3565   4.2206084
## 3566   2.3191172
## 3567   2.1681169
## 3568   2.3739082
## 3569   4.5378401
## 3570   3.4594705
## 3571   3.7399430
## 3572   4.1241466
## 3573   3.2728301
## 3574   5.0150632
## 3575   4.5481912
## 3576   3.8083238
## 3577   3.9611377
## 3578   4.5679328
## 3579   4.4739636
## 3580   3.2134737
## 3581   4.1110219
## 3582   3.4278131
## 3583   5.2135875
## 3584   5.3133378
## 3585   2.6828259
## 3586   3.2205372
## 3587   2.3932200
## 3588   3.2475060
## 3589   3.0208237
## 3590   4.3425195
## 3591   4.0928964
## 3592   4.4120313
## 3593   5.9969442
## 3594   4.0297417
## 3595   4.2316899
## 3596   5.7373090
## 3597   6.1466465
## 3598   3.7471641
## 3599   4.7682100
## 3600   4.1636367
## 3601   3.6361677
## 3602   4.5213312
## 3603   4.7693521
## 3604   4.9199465
## 3605   5.4982821
## 3606   5.4607283
## 3607   5.2377967
## 3608   5.0173417
## 3609   4.1431334
## 3610   4.1818057
## 3611   4.9007952
## 3612   4.6447425
## 3613   3.6270116
## 3614   4.4175181
## 3615   4.4083211
## 3616   6.1732247
## 3617   5.0162574
## 3618   4.8159803
## 3619   5.3539140
## 3620   5.4440061
## 3621   4.7583752
## 3622   4.2971479
## 3623   4.3697863
## 3624   4.9969368
## 3625   5.1434356
## 3626   3.3665941
## 3627   4.5280800
## 3628   4.1223941
## 3629   3.4610208
## 3630   4.1352610
## 3631   3.7521069
## 3632   3.9790987
## 3633   4.4387884
## 3634   4.4108653
## 3635   4.2672336
## 3636   6.3828918
## 3637   4.0616002
## 3638   4.0574894
## 3639   3.1109418
## 3640   3.5044964
## 3641   4.8197913
## 3642   4.7110736
## 3643   3.8671143
## 3644   4.7094842
## 3645   4.9321618
## 3646   5.5699603
## 3647   5.1929676
## 3648   5.7322959
## 3649   4.0014813
## 3650   3.5649744
## 3651   3.9611841
## 3652   3.2678728
## 3653   6.2160218
## 3654   3.6843473
## 3655   4.9282473
## 3656   4.6501729
## 3657   4.5955260
## 3658   4.9109410
## 3659   5.8650935
## 3660   4.6129844
## 3661   6.5230797
## 3662   5.9895500
## 3663   5.9750949
## 3664   4.0764424
## 3665   4.3908341
## 3666   3.2827490
## 3667   3.5467346
## 3668   3.5103066
## 3669   5.5493322
## 3670   1.5369269
## 3671   3.8975497
## 3672   4.3417863
## 3673   3.3261344
## 3674   5.1600574
## 3675   4.1582759
## 3676   3.0431836
## 3677   4.3664962
## 3678   6.5418104
## 3679   5.4121178
## 3680   6.0564137
## 3681   4.2234600
## 3682   4.3612468
## 3683   4.9429256
## 3684   5.4051531
## 3685   4.7401880
## 3686   4.5045376
## 3687   4.6005308
## 3688   4.6399221
## 3689   4.6541759
## 3690   5.0322001
## 3691   5.5926637
## 3692   5.9588629
## 3693   3.3781458
## 3694   4.4152615
## 3695   3.4699170
## 3696   5.6055002
## 3697   5.0632557
## 3698   6.3564865
## 3699   5.2601232
## 3700   2.4061985
## 3701   3.1424836
## 3702   3.2251202
## 3703   4.9202758
## 3704   5.0318805
## 3705   3.2426193
## 3706   3.1476036
## 3707   6.0871942
## 3708   3.0837690
## 3709   5.7315320
## 3710   4.8167257
## 3711   5.3161197
## 3712   5.5741703
## 3713   5.1086703
## 3714   5.8884290
## 3715   4.6531298
## 3716   6.7053580
## 3717   4.8243143
## 3718   2.6717958
## 3719   2.5514098
## 3720   2.6397348
## 3721   4.0885790
## 3722   5.0610047
## 3723   5.9209211
## 3724   6.3834684
## 3725   6.2751916
## 3726   4.9975462
## 3727   4.6885733
## 3728   6.1817847
## 3729   6.4431428
## 3730   5.2075904
## 3731   1.5067152
## 3732   4.0632374
## 3733   4.2024431
## 3734   4.3896306
## 3735   4.9650084
## 3736   4.5059218
## 3737   4.2052656
## 3738   5.4245029
## 3739   5.4169994
## 3740   5.3895580
## 3741   2.5547606
## 3742   2.9616805
## 3743   3.0703918
## 3744   3.2322654
## 3745   3.2259162
## 3746   3.3765052
## 3747   3.8342296
## 3748   3.9266882
## 3749   4.5304625
## 3750   5.0172448
## 3751   4.2634765
## 3752   6.0013311
## 3753   4.5501377
## 3754   5.9884127
## 3755   3.2310539
## 3756   4.2785566
## 3757   3.6421996
## 3758   3.9052885
## 3759   2.6069923
## 3760   4.1058379
## 3761   4.6581106
## 3762   5.1728497
## 3763   5.9725127
## 3764   8.0104688
## 3765   5.6222577
## 3766   2.9979337
## 3767   3.7299005
## 3768   5.7893892
## 3769   5.3938188
## 3770   3.7163478
## 3771   4.3791123
## 3772   4.7410788
## 3773   4.4679297
## 3774   4.2071295
## 3775   6.6165335
## 3776   2.4646749
## 3777   3.2179848
## 3778   5.0905595
## 3779   4.8192528
## 3780   4.5389492
## 3781   3.7763673
## 3782   3.7195480
## 3783   0.6221865
## 3784   2.9232562
## 3785   4.5854792
## 3786   5.2626899
## 3787   2.4883982
## 3788   3.7504918
## 3789   3.3321552
## 3790   4.5480119
## 3791   4.9728596
## 3792   4.7648873
## 3793   3.6633552
## 3794   4.2161884
## 3795  -0.3937101
## 3796   1.4015177
## 3797   2.4634823
## 3798   2.7087108
## 3799   3.3330809
## 3800   3.8983004
## 3801   4.8521967
## 3802   4.4983979
## 3803   4.5173221
## 3804   5.0905290
## 3805   4.6818254
## 3806   3.8625861
## 3807   2.1163339
## 3808   3.3648760
## 3809   5.4940107
## 3810   2.2658720
## 3811   3.1028488
## 3812   3.3825933
## 3813   4.6367176
## 3814   5.1602104
## 3815   3.2957431
## 3816   3.9211932
## 3817   6.2555170
## 3818   5.0916589
## 3819   5.1451839
## 3820   5.3337007
## 3821   5.1433158
## 3822   4.2652693
## 3823   5.3906362
## 3824   2.9520170
## 3825   3.0577212
## 3826   2.7822683
## 3827   4.6745405
## 3828   3.2083866
## 3829   3.5160008
## 3830   4.9651184
## 3831   5.0713659
## 3832   5.2696162
## 3833   4.7403219
## 3834   4.4116907
## 3835   2.9787970
## 3836   2.5985540
## 3837   3.0821159
## 3838   3.8890381
## 3839   3.3709232
## 3840   3.9005542
## 3841   2.9563007
## 3842   4.7971611
## 3843   4.7807559
## 3844   6.4277389
## 3845   4.8965407
## 3846   4.4188885
## 3847   2.7520831
## 3848   2.9858125
## 3849   4.4309000
## 3850   4.6433182
## 3851   5.2295304
## 3852   4.3253718
## 3853   3.5655523
## 3854   5.8452957
## 3855   5.1206749
## 3856   2.7503484
## 3857   1.9213496
## 3858   3.8793148
## 3859   4.5297978
## 3860   2.9901237
## 3861   3.6362614
## 3862   5.5841640
## 3863   3.6085757
## 3864   3.8306955
## 3865   4.6376531
## 3866   4.4779504
## 3867   4.2320207
## 3868   3.6128067
## 3869   4.3868737
## 3870   6.2110010
## 3871   1.9869049
## 3872   4.2397844
## 3873   3.5816103
## 3874   3.0420758
## 3875   2.4952110
## 3876   2.4554729
## 3877   2.8785335
## 3878   3.3575545
## 3879   4.5988173
## 3880   4.9609796
## 3881   3.1609326
## 3882   3.4478651
## 3883   4.3239121
## 3884   4.6080811
## 3885   5.4703990
## 3886   5.4170062
## 3887   2.1085187
## 3888   4.5484764
## 3889   5.2753215
## 3890   5.0573587
## 3891   4.6673499
## 3892   4.3470267
## 3893   3.3105963
## 3894   3.7838603
## 3895   3.5536621
## 3896   3.3044444
## 3897   6.3421826
## 3898   3.9775312
## 3899   4.4631958
## 3900   4.0304185
## 3901   3.5352898
## 3902   3.2770877
## 3903   4.1843515
## 3904   5.0252238
## 3905   1.7119223
## 3906   2.8726950
## 3907   4.4158172
## 3908   4.4400766
## 3909   2.2742477
## 3910   2.5762235
## 3911   3.9610183
## 3912   3.3520149
## 3913   4.7519938
## 3914   3.8638133
## 3915   4.7748699
## 3916   4.0324411
## 3917   2.7711294
## 3918   2.6948542
## 3919   3.2326255
## 3920   2.5448630
## 3921   2.5331465
## 3922   1.9308798
## 3923   4.8427046
## 3924   6.2719929
## 3925   6.3259480
## 3926   4.8343091
## 3927   4.6971697
## 3928   4.5272353
## 3929   4.3391224
## 3930   3.6291844
## 3931   3.8551282
## 3932   3.0137029
## 3933   3.8425410
## 3934   4.6025040
## 3935   4.3269405
## 3936   2.3978409
## 3937   6.1425077
## 3938   3.1507746
## 3939   2.8375503
## 3940   5.1089513
## 3941   3.8588741
## 3942   3.6920379
## 3943   5.1538865
## 3944   2.9423375
## 3945   6.8884894
## 3946   4.8215435
## 3947   4.9264247
## 3948   5.6076982
## 3949   4.7379000
## 3950   3.8520300
## 3951   5.0688806
## 3952   3.0421073
## 3953   3.7183477
## 3954   4.1484022
## 3955   5.2614783
## 3956   4.4932070
## 3957   4.9225104
## 3958   3.5708731
## 3959   3.6209674
## 3960   6.2557603
## 3961   6.5997257
## 3962   6.7961043
## 3963   3.3000186
## 3964   1.6595872
## 3965   3.5838727
## 3966   5.3680159
## 3967   4.8068428
## 3968   4.8928025
## 3969   5.4380288
## 3970   5.0299351
## 3971   4.8190365
## 3972   5.4665147
## 3973   4.1943124
## 3974   3.2659122
## 3975   5.3509186
## 3976   5.1150824
## 3977   6.2038246
## 3978   6.3323609
## 3979   6.6488464
## 3980   6.1079667
## 3981   5.2278040
## 3982   5.3594855
## 3983   4.3986487
## 3984   4.2165867
## 3985   4.5596099
## 3986   3.4978181
## 3987   3.2665268
## 3988   4.4545247
## 3989   5.0847747
## 3990   6.8682862
## 3991   6.0366783
## 3992   3.7324629
## 3993   3.8647846
## 3994   3.8236972
## 3995   4.7629820
## 3996   5.0458895
## 3997   2.5558009
## 3998   2.2263052
## 3999   1.6516053
## 4000   3.7644370
## 4001   3.7646510
## 4002   4.8301528
## 4003   5.8574614
## 4004   4.9222526
## 4005   4.0521035
## 4006   4.5503398
## 4007   4.0914532
## 4008   3.9461048
## 4009   3.5777803
## 4010   4.5399870
## 4011   2.4968627
## 4012   3.1223344
## 4013   4.2230657
## 4014   6.2355869
## 4015   5.7361162
## 4016   5.0950964
## 4017   4.5582297
## 4018   4.1026563
## 4019   2.3691251
## 4020   2.2292232
## 4021   6.5533617
## 4022   5.4752948
## 4023   4.8226154
## 4024   3.5020373
## 4025   2.3986499
## 4026   3.6469553
## 4027   3.4144476
## 4028   2.6599974
## 4029   2.9342867
## 4030   4.3016257
## 4031   3.5405478
## 4032   3.9886366
## 4033   5.6131497
## 4034   6.3269194
## 4035   5.5847221
## 4036   5.5022374
## 4037   5.7347062
## 4038   4.8705816
## 4039   5.5297483
## 4040   3.3014326
## 4041   4.3498404
## 4042   2.4756011
## 4043   4.1080160
## 4044   3.2227906
## 4045   3.8999901
## 4046   4.6341401
## 4047   3.7194281
## 4048   3.5533691
## 4049   5.5253856
## 4050   4.0259698
## 4051   4.4547554
## 4052   5.1843473
## 4053   5.1718093
## 4054   3.9389546
## 4055   1.5984322
## 4056   5.5716307
## 4057   5.6748387
## 4058   2.5174434
## 4059   4.6193085
## 4060   4.7479525
## 4061   3.7486183
## 4062   3.7744298
## 4063   5.5779608
## 4064   5.0840451
## 4065   4.3422982
## 4066   4.5660433
## 4067   3.7814486
## 4068   2.1583609
## 4069   6.1851724
## 4070   4.2588572
## 4071   4.5265920
## 4072   3.8747648
## 4073   3.2573201
## 4074   3.7256461
## 4075   5.6901783
## 4076   3.8560305
## 4077   3.3882224
## 4078   4.6859299
## 4079   4.9220907
## 4080   4.9806513
## 4081   3.1509679
## 4082   3.5997430
## 4083   3.6738246
## 4084   3.3884208
## 4085   4.7517182
## 4086   4.5036754
## 4087   3.7648001
## 4088   5.2106588
## 4089   4.7109303
## 4090   4.3673277
## 4091   4.0196165
## 4092   4.5169835
## 4093   3.3701725
## 4094   1.3992966
## 4095   2.0474969
## 4096   4.2542669
## 4097   4.0813241
## 4098   4.4094775
## 4099   4.2072426
## 4100   4.8249449
## 4101   6.7280085
## 4102   2.1265261
## 4103   2.5921454
## 4104   2.8713377
## 4105   5.6258004
## 4106   6.3540445
## 4107   5.8950016
## 4108   4.9882137
## 4109   4.0163433
## 4110   4.8757733
## 4111   4.1467043
## 4112   2.6428722
## 4113   5.8436068
## 4114   4.3453858
## 4115   4.4495198
## 4116   4.7097104
## 4117   3.3053174
## 4118   2.9135790
## 4119   2.4482555
## 4120   2.6834536
## 4121   5.2221949
## 4122   4.1786851
## 4123   2.4414115
## 4124   4.0775878
## 4125   4.8582164
## 4126   4.5384468
## 4127   3.8678398
## 4128   3.3371065
## 4129   5.0835604
## 4130   4.9956894
## 4131   4.2242845
## 4132   5.5320885
## 4133   5.8619033
## 4134   3.8867848
## 4135   3.6627464
## 4136   3.1530989
## 4137   2.2037816
## 4138   3.9962226
## 4139   4.1662941
## 4140   4.5601844
## 4141   4.8028590
## 4142   5.3105247
## 4143   3.3299492
## 4144   4.8261469
## 4145   3.6179303
## 4146   3.3644177
## 4147   3.0188894
## 4148   3.6411095
## 4149   4.2390531
## 4150   5.5322296
## 4151   3.8652972
## 4152   5.1265885
## 4153   3.7795167
## 4154   4.8909195
## 4155   5.1506540
## 4156   2.7389828
## 4157   3.4345853
## 4158   3.2956117
## 4159   4.5465045
## 4160   4.3728269
## 4161   4.0337561
## 4162   5.6082617
## 4163   1.9582979
## 4164   2.8750131
## 4165   0.8462849
## 4166   4.2849490
## 4167   2.5726440
## 4168   4.6348579
## 4169   5.9297550
## 4170   6.0306840
## 4171   6.1200564
## 4172   3.9877323
## 4173   4.8825661
## 4174   4.5347617
## 4175   5.1851750
## 4176   5.7144026
## 4177   6.2169070
## 4178   6.0955423
## 4179   5.4171047
## 4180   5.7463750
## 4181   4.9883159
## 4182   4.0774206
## 4183   7.0536687
## 4184   5.9891864
## 4185   4.4622608
## 4186   5.5646886
## 4187   6.9610773
## 4188   3.0591018
## 4189   5.6797903
## 4190   5.9348457
## 4191   6.0563022
## 4192   6.2630442
## 4193   4.7202758
## 4194   4.6793889
## 4195   3.7393566
## 4196   4.1707890
## 4197   3.3656795
## 4198   3.5876382
## 4199   4.2827859
## 4200   4.8922190
## 4201   4.3651579
## 4202   3.2443779
## 4203   4.3640604
## 4204   5.1316296
## 4205   4.9747195
## 4206   4.4034934
## 4207   4.0233824
## 4208   5.3900385
## 4209   5.3070961
## 4210   2.8520234
## 4211   3.4075488
## 4212   5.3583082
## 4213   5.6355802
## 4214   4.9259485
## 4215   5.6990436
## 4216   5.3235912
## 4217   3.3506988
## 4218   4.0785158
## 4219   3.3733388
## 4220   4.6331592
## 4221   2.6162036
## 4222   3.5821129
## 4223   3.6347907
## 4224   3.5039436
## 4225   3.1990609
## 4226   4.0346507
## 4227   4.6445782
## 4228   4.6903479
## 4229   3.8149114
## 4230   2.8615320
## 4231   6.3673460
## 4232   4.7898646
## 4233   4.8705049
## 4234   5.2866459
## 4235   3.3742828
## 4236   4.1753227
## 4237   4.3115797
## 4238   4.6438777
## 4239   5.2560356
## 4240   4.8025798
## 4241   4.7141239
## 4242   4.5623718
## 4243   4.0859990
## 4244   3.9350293
## 4245   5.3709751
## 4246   4.9381790
## 4247   4.2985386
## 4248   5.1771061
## 4249   5.6590507
## 4250   5.7301002
## 4251   6.7053616
## 4252   6.8407856
## 4253   6.4351289
## 4254   4.9749095
## 4255   5.0263463
## 4256   4.8577413
## 4257   2.8853836
## 4258   4.3828388
## 4259   4.1156269
## 4260   4.6930047
## 4261   3.4028716
## 4262   4.4073465
## 4263   5.9343105
## 4264   6.1987165
## 4265   6.7476587
## 4266   6.3426370
## 4267   2.3065688
## 4268   3.5415452
## 4269   4.7573837
## 4270   4.1280077
## 4271   5.3973451
## 4272   4.3788490
## 4273   3.5079331
## 4274   3.3608740
## 4275   1.7026377
## 4276   3.3384742
## 4277   6.1299746
## 4278   5.6745710
## 4279   5.1968137
## 4280   3.7098765
## 4281   4.4684027
## 4282   3.4333922
## 4283   3.8815757
## 4284   5.2231225
## 4285   6.4885082
## 4286   5.5488431
## 4287   6.4232791
## 4288   6.0118961
## 4289   3.2346047
## 4290   4.5916823
## 4291   3.2542629
## 4292   3.5158566
## 4293   3.7858732
## 4294   3.4061250
## 4295   5.7408840
## 4296   4.1453556
## 4297   5.0040396
## 4298   3.5667069
## 4299   4.2011770
## 4300   6.3327792
## 4301   7.0350673
## 4302   3.7016432
## 4303   5.6919508
## 4304   5.1784262
## 4305   4.2860140
## 4306   4.4164545
## 4307   4.5217195
## 4308   6.3842097
## 4309   3.1486832
## 4310   5.2214728
## 4311   5.1514048
## 4312   6.4992888
## 4313   5.9475863
## 4314   4.9137584
## 4315   2.4537968
## 4316   1.7861182
## 4317   6.0303291
## 4318   5.5111997
## 4319   3.2074335
## 4320   4.3026705
## 4321   3.6105140
## 4322   3.6381588
## 4323   2.4014917
## 4324   6.2246627
## 4325   6.1690133
## 4326   5.0558235
## 4327   4.2803520
## 4328   2.7713722
## 4329   4.1796882
## 4330   3.2224992
## 4331   3.1042664
## 4332   4.1543357
## 4333   3.9553647
## 4334   4.5595457
## 4335   2.3258046
## 4336   1.7653475
## 4337   3.0541497
## 4338   6.5978644
## 4339   4.3604817
## 4340   2.3742050
## 4341   4.3988782
## 4342   4.2725798
## 4343   3.3681096
## 4344   3.7732280
## 4345   4.0892953
## 4346   4.3144028
## 4347   4.0227958
## 4348   2.5739284
## 4349   1.9007611
## 4350   0.5499026
## 4351   5.7357224
## 4352   2.7070013
## 4353   3.0551718
## 4354   2.9033576
## 4355   3.3647038
## 4356   3.5668378
## 4357   3.8275013
## 4358   4.6000692
## 4359   3.4340984
## 4360   3.4398723
## 4361   4.6892494
## 4362   4.0424404
## 4363   3.9221666
## 4364   4.5186784
## 4365   4.8556617
## 4366   2.7609429
## 4367   3.4918258
## 4368   4.1014679
## 4369   3.4834410
## 4370   4.9168404
## 4371   4.5524799
## 4372   4.4477702
## 4373   4.1509261
## 4374   4.3531972
## 4375   2.7580947
## 4376   2.9335534
## 4377   3.0971853
## 4378   5.3371381
## 4379   4.3740288
## 4380   4.3762583
## 4381   4.7275079
## 4382   4.4271550
## 4383   4.5140173
## 4384   3.4047399
## 4385   4.7088586
## 4386   2.1125326
## 4387   4.3638638
## 4388   3.4494346
## 4389   4.1976869
## 4390   3.6951590
## 4391   3.9447144
## 4392   3.5783904
## 4393   3.8937528
## 4394   3.4064784
## 4395   4.5861129
## 4396   4.7462953
## 4397   5.2862058
## 4398   5.2893563
## 4399   2.4634687
## 4400   3.3882136
## 4401   2.0675680
## 4402   2.9147685
## 4403   2.4209873
## 4404   3.6059298
## 4405   6.6944558
## 4406   2.4324370
## 4407   5.2193849
## 4408   4.9769976
## 4409   5.2885915
## 4410   3.3907516
## 4411   4.5836049
## 4412   5.4164930
## 4413   3.3675698
## 4414   5.1091841
## 4415   3.7535141
## 4416   3.4706065
## 4417   3.5329782
## 4418   3.5321530
## 4419   2.2812994
## 4420   4.2868973
## 4421   4.6227673
## 4422   4.9919770
## 4423   5.2769068
## 4424   4.8637453
## 4425   5.1330250
## 4426   6.1090480
## 4427   5.2795373
## 4428   3.9101019
## 4429   3.9642893
## 4430   4.9595574
## 4431   2.5753459
## 4432   3.9324364
## 4433   3.3313847
## 4434   3.6955335
## 4435   4.9601556
## 4436   4.0327080
## 4437   3.7363546
## 4438   3.7702095
## 4439   3.9479100
## 4440   5.0473933
## 4441   5.7347889
## 4442   4.2978694
## 4443   5.2852922
## 4444   6.2050224
## 4445   2.3382428
## 4446   2.5828280
## 4447   4.9605014
## 4448   3.8639535
## 4449   3.6903980
## 4450   5.1356205
## 4451   3.4244594
## 4452   5.8642547
## 4453   4.6127196
## 4454   5.3804208
## 4455   4.0284219
## 4456   4.1245514
## 4457   3.5309477
## 4458   5.3714212
## 4459   4.6496441
## 4460   5.2272523
## 4461   4.1921198
## 4462   5.5712842
## 4463   2.7392029
## 4464   3.7017167
## 4465   4.7847117
## 4466   5.0665893
## 4467   4.2320311
## 4468   3.7253823
## 4469   2.6444649
## 4470   6.5566664
## 4471   5.7149352
## 4472   4.4248505
## 4473   5.1845318
## 4474   4.1177050
## 4475   4.8129065
## 4476   4.7544916
## 4477   3.0489615
## 4478   2.8638003
## 4479   2.3509364
## 4480   2.6882243
## 4481   3.3951082
## 4482   6.1959366
## 4483   6.7523251
## 4484   4.5673882
## 4485   4.3630157
## 4486   3.0564478
## 4487   3.9829830
## 4488   4.9934037
## 4489   3.4407571
## 4490   3.9362644
## 4491   3.9939291
## 4492   4.5171662
## 4493   4.0686749
## 4494   4.0923202
## 4495   5.7464275
## 4496   4.0081297
## 4497   3.0809973
## 4498   2.7602013
## 4499   3.1160868
## 4500   3.4864772
## 4501   4.1313283
## 4502   4.8627362
## 4503   4.7468214
## 4504   4.8575266
## 4505   4.5343627
## 4506   3.7970009
## 4507   5.2127776
## 4508   6.1138824
## 4509   2.8294758
## 4510   4.7201530
## 4511   4.5066907
## 4512   4.4790024
## 4513   6.0915562
## 4514   7.4259690
## 4515   5.8029161
## 4516   2.8142572
## 4517   4.1058242
## 4518   4.7981091
## 4519   3.7474043
## 4520   4.1064085
## 4521   5.0931395
## 4522   5.9070155
## 4523   2.1796233
## 4524   5.3544274
## 4525   4.4940281
## 4526   2.0561318
## 4527   3.0687878
## 4528   5.9362392
## 4529   4.8469710
## 4530   5.1657176
## 4531   2.8359921
## 4532   4.5128675
## 4533   5.1241565
## 4534   2.9056637
## 4535   4.0457876
## 4536   3.8654361
## 4537   3.6539077
## 4538   3.7611245
## 4539   4.9650440
## 4540   4.1484551
## 4541   3.5639871
## 4542   4.0693858
## 4543   2.6298967
## 4544   3.4566355
## 4545   3.1988928
## 4546   4.8488713
## 4547   2.6762855
## 4548   2.3490062
## 4549   2.1197360
## 4550   3.3746522
## 4551   3.8068637
## 4552   4.9901841
## 4553   4.6050107
## 4554   3.3227341
## 4555   6.0332333
## 4556   5.1599102
## 4557   3.2790694
## 4558   5.7232946
## 4559   5.9608517
## 4560   4.2225904
## 4561   4.1834438
## 4562   4.3715463
## 4563   3.7253882
## 4564   5.1544301
## 4565   5.5728685
## 4566   5.9970785
## 4567   6.1961506
## 4568   5.1035832
## 4569   2.2491897
## 4570   6.0584259
## 4571   6.0177602
## 4572   6.1329735
## 4573   5.9950993
## 4574   4.7446825
## 4575   4.2297060
## 4576   4.5889129
## 4577   5.3007818
## 4578   4.4927034
## 4579   5.7049018
## 4580   6.1428820
## 4581   4.7495864
## 4582   6.0584638
## 4583   5.0569718
## 4584   4.8013444
## 4585   4.5999998
## 4586   4.1524899
## 4587   5.1615616
## 4588   3.8406864
## 4589   3.1828298
## 4590   2.6224453
## 4591   2.6639973
## 4592   6.2398585
## 4593   7.8671097
## 4594   6.2997969
## 4595   6.1678679
## 4596   7.5325768
## 4597   6.5380016
## 4598   6.5404927
## 4599   2.8440582
## 4600   3.1746667
## 4601   3.2063796
## 4602   3.5113106
## 4603   3.6431470
## 4604   3.9335281
## 4605   4.6420835
## 4606   4.6865007
## 4607   6.4814922
## 4608   6.1272730
## 4609   5.4658682
## 4610   5.2865535
## 4611   3.5004338
## 4612   3.8916186
## 4613   3.6554577
## 4614   4.5549631
## 4615   2.4393193
## 4616   3.6173323
## 4617   5.7966129
## 4618   5.3460155
## 4619   4.1214112
## 4620   5.2123121
## 4621   4.8759008
## 4622   2.7011477
## 4623   5.3400544
## 4624   3.7565047
## 4625   3.9232445
## 4626   4.3601489
## 4627   5.1118226
## 4628   3.6508238
## 4629   4.4808675
## 4630   4.2465628
## 4631   5.3672501
## 4632   5.8461415
## 4633   3.5350749
## 4634   3.8913759
## 4635   4.5467689
## 4636   4.9382521
## 4637   5.6043789
## 4638   4.1543199
## 4639   6.3156528
## 4640   3.9278040
## 4641   3.4727422
## 4642   6.7593706
## 4643   7.2042843
## 4644   1.9019180
## 4645   6.9987492
## 4646   4.5756872
## 4647   6.8653358
## 4648   6.2541032
## 4649   6.0204031
## 4650   4.5656514
## 4651   3.2992852
## 4652   3.8665593
## 4653   2.2516246
## 4654   2.6310839
## 4655   3.5841018
## 4656   2.2130961
## 4657   4.2820541
## 4658   3.5803512
## 4659   2.6406906
## 4660   1.6748283
## 4661   3.6603635
## 4662   5.1652122
## 4663   4.1741289
## 4664   2.2090730
## 4665   4.4699387
## 4666   5.1435908
## 4667   3.7240630
## 4668   4.5459529
## 4669   4.3870170
## 4670   3.6947376
## 4671   3.7571143
## 4672   3.5971330
## 4673   2.5044727
## 4674   2.8183174
## 4675   7.6961976
## 4676   8.2231622
## 4677   4.3370877
## 4678   5.8038760
## 4679   3.9161290
## 4680   5.0898770
## 4681   3.5768587
## 4682   5.0493459
## 4683   4.6837600
## 4684   5.3602075
## 4685   5.1463662
## 4686   3.9794952
## 4687   3.8344800
## 4688   2.7481252
## 4689   3.3821207
## 4690   1.7916387
## 4691   2.2094190
## 4692   1.6403056
## 4693   7.9122498
## 4694   4.6293891
## 4695   4.0894166
## 4696   4.0294734
## 4697   1.9417080
## 4698   2.3356798
## 4699   5.4886917
## 4700   2.5080871
## 4701   3.1486338
## 4702   3.3338750
## 4703   4.3707283
## 4704   6.1078984
## 4705   6.4076344
## 4706   6.1297122
## 4707   6.3209598
## 4708   3.5150565
## 4709   5.4462738
## 4710   3.7164150
## 4711   4.3572413
## 4712   4.6592214
## 4713   4.1503085
## 4714   5.3299341
## 4715   5.5524238
## 4716   4.2959929
## 4717   3.2660975
## 4718   3.4454284
## 4719   3.5360146
## 4720   3.8487061
## 4721   4.4023130
## 4722   4.1454683
## 4723   4.8956195
## 4724   3.2630838
## 4725   3.7998084
## 4726   4.7642465
## 4727   4.3768151
## 4728   4.7807801
## 4729   3.5849089
## 4730   5.0307864
## 4731   3.4858889
## 4732   5.2146318
## 4733   5.4698635
## 4734   3.7031591
## 4735   3.6696727
## 4736   6.5080104
## 4737   6.8962177
## 4738   2.7656863
## 4739   3.3519119
## 4740   3.3825633
## 4741   2.8512489
## 4742   4.3853100
## 4743   5.8794389
## 4744   5.5634716
## 4745   5.7143333
## 4746   6.3196550
## 4747   4.8161582
## 4748   2.1338679
## 4749   4.7873974
## 4750   4.8261262
## 4751   3.1664466
## 4752   7.7122986
## 4753   5.1436907
## 4754   6.0468372
## 4755   5.9782906
## 4756   4.5602396
## 4757   5.4998142
## 4758   4.1556684
## 4759   4.3589648
## 4760   5.1642968
## 4761   3.9014431
## 4762   4.2316411
## 4763   4.1628966
## 4764   4.0954291
## 4765   4.4836465
## 4766   3.2280896
## 4767   3.3091216
## 4768   3.6065953
## 4769   3.8397601
## 4770   5.7108049
## 4771   4.1440829
## 4772   5.2027696
## 4773   5.2461529
## 4774   3.8314360
## 4775   4.1100116
## 4776   4.5644357
## 4777   4.5435770
## 4778   4.3578537
## 4779   4.8580728
## 4780   4.5422725
## 4781   4.0985611
## 4782   5.8436135
## 4783   3.5677600
## 4784   4.9976670
## 4785   5.5463075
## 4786   4.0897836
## 4787   4.9424292
## 4788   4.8651054
## 4789   6.1435074
## 4790   5.3038955
## 4791   4.7535306
## 4792   3.2697509
## 4793   4.1947928
## 4794   4.0009304
## 4795   4.5849975
## 4796   4.7095630
## 4797   4.0914548
## 4798   6.5143353
## 4799   4.8635166
## 4800   4.6636326
## 4801   4.5775931
## 4802   5.1504250
## 4803   3.0383065
## 4804   3.2694615
## 4805   3.9593710
## 4806   5.2444938
## 4807   5.8870581
## 4808   4.5398699
## 4809   2.5343604
## 4810   4.7821109
## 4811   3.2161600
## 4812   4.2834184
## 4813   5.4373953
## 4814   3.3589927
## 4815   2.2042583
## 4816   4.8470164
## 4817   3.6187813
## 4818   4.1370085
## 4819   4.1067572
## 4820   6.8308255
## 4821   3.1452152
## 4822   5.2808640
## 4823   1.6421084
## 4824   4.0878178
## 4825   1.5046621
## 4826   1.6422235
## 4827   1.0108594
## 4828   2.9444279
## 4829   4.4690775
## 4830   4.1946345
## 4831   3.7202541
## 4832   4.9554351
## 4833   4.2157387
## 4834   3.6555389
## 4835   3.8067258
## 4836   4.0411735
## 4837   3.9174337
## 4838   3.2953294
## 4839   3.6417323
## 4840   4.9972492
## 4841   3.0056892
## 4842   4.0215424
## 4843   3.6730369
## 4844   2.4059900
## 4845   4.6396881
## 4846   4.5639916
## 4847   3.6211737
## 4848   3.8278408
## 4849   4.5524350
## 4850   3.3247450
## 4851   5.6922881
## 4852   5.6800107
## 4853   6.0603085
## 4854   5.1096245
## 4855   5.3254670
## 4856   4.9978975
## 4857   4.8392374
## 4858   5.5105656
## 4859   4.2190474
## 4860   5.4308114
## 4861   4.7040195
## 4862   6.0738261
## 4863   4.7039468
## 4864   4.0935227
## 4865   5.8945179
## 4866   7.0045868
## 4867   3.7249068
## 4868   4.2098527
## 4869   3.7851783
## 4870   3.6283797
## 4871   3.9997617
## 4872   2.9174014
## 4873   4.4195070
## 4874   3.4004104
## 4875   6.5131346
## 4876   2.9516218
## 4877   4.5092181
## 4878   5.3132812
## 4879   4.6791622
## 4880   2.9414832
## 4881   4.0426829
## 4882   4.7420771
## 4883   4.0252561
## 4884   3.4276434
## 4885   2.7673163
## 4886   3.1303587
## 4887   2.8938058
## 4888   3.7903985
## 4889   6.4663437
## 4890   7.1932336
## 4891   5.3817724
## 4892   5.8138125
## 4893   4.6243658
## 4894   3.2166182
## 4895   3.6204043
## 4896   2.9571470
## 4897   4.5487983
## 4898   2.7855349
## 4899   3.5959296
## 4900   2.4960505
## 4901   3.3043852
## 4902   2.7203847
## 4903   6.2254132
## 4904   4.2175528
## 4905   4.9442057
## 4906   3.3480243
## 4907   4.7792397
## 4908   5.9791533
## 4909   4.8928067
## 4910   4.0455669
## 4911   6.3415251
## 4912   4.0741156
## 4913   4.2316836
## 4914   4.6343229
## 4915   1.4296941
## 4916   4.7097926
## 4917   4.9216369
## 4918   1.7693536
## 4919   3.2190722
## 4920   0.4024424
## 4921   4.5897954
## 4922   5.2449366
## 4923   5.6758246
## 4924   1.8592511
## 4925   5.7507902
## 4926   5.7451007
## 4927   2.4518072
## 4928   4.4953928
## 4929   3.5853792
## 4930   3.7425596
## 4931   5.7144576
## 4932   5.8174847
## 4933   5.1580989
## 4934   5.5175353
## 4935   5.1945242
## 4936   4.0860381
## 4937   3.2524337
## 4938   4.7078700
## 4939   4.6150914
## 4940   6.0364251
## 4941   5.3829147
## 4942   5.0601900
## 4943   4.3405727
## 4944   3.3358629
## 4945   6.2179611
## 4946   4.7998326
## 4947   3.8960983
## 4948   5.2417072
## 4949   6.0904815
## 4950   5.3933905
## 4951   3.4702981
## 4952   5.9919233
## 4953   3.6953334
## 4954   3.6782089
## 4955   3.2060031
## 4956   3.6143259
## 4957   4.2882787
## 4958   3.9474036
## 4959   4.9152731
## 4960   5.7779953
## 4961   4.4948398
## 4962   4.6471544
## 4963   3.4593648
## 4964   5.7341518
## 4965   3.5957251
## 4966   4.7970988
## 4967   3.8123449
## 4968   4.1930300
## 4969   2.4349675
## 4970   3.9407804
## 4971   4.1208086
## 4972   4.9462370
## 4973   3.0572137
## 4974   5.7146005
## 4975   6.1466424
## 4976   3.3342934
## 4977   3.6816663
## 4978   2.7713901
## 4979   3.2218983
## 4980   4.7104642
## 4981   5.1527173
## 4982   4.0471191
## 4983   3.8225023
## 4984   4.4726693
## 4985   4.5687593
## 4986   5.5367827
## 4987   4.3790246
## 4988   5.2543823
## 4989   4.4010542
## 4990   3.8917861
## 4991   2.3693041
## 4992   1.6961708
## 4993   5.2431874
## 4994   4.9286164
## 4995   5.2654452
## 4996   3.7597367
## 4997   3.4335276
## 4998   3.9967223
## 4999   3.1240025
## 5000   3.9962314
## 5001   5.5553307
## 5002   5.2406703
## 5003   4.0157578
## 5004   4.0807096
## 5005   4.9822235
## 5006   6.2982104
## 5007   3.8084445
## 5008   4.0094528
## 5009   3.8446857
## 5010   3.3760131
## 5011   5.5208496
## 5012   2.4753186
## 5013   4.4892901
## 5014   2.8866709
## 5015   2.9099476
## 5016   5.4300916
## 5017   3.8149100
## 5018   4.5681214
## 5019   4.7104397
## 5020   4.0774223
## 5021   3.9263373
## 5022   2.3157561
## 5023   4.6135663
## 5024   5.3398229
## 5025   5.2854747
## 5026   5.9421330
## 5027   3.6996208
## 5028   3.2241439
## 5029   4.4423052
## 5030   3.7601761
## 5031   2.9107537
## 5032   3.3014736
## 5033   5.7457398
## 5034   6.3002225
## 5035   5.8189374
## 5036   3.7468689
## 5037   4.6935338
## 5038   3.3057144
## 5039   3.0149186
## 5040   4.9920152
## 5041   4.4006617
## 5042   3.7295137
## 5043   4.5492545
## 5044   5.1981393
## 5045   5.2472942
## 5046   4.6635442
## 5047   5.3954502
## 5048   4.2312564
## 5049   5.1674438
## 5050   3.1483348
## 5051   1.8445767
## 5052   3.8075535
## 5053   4.3284413
## 5054   3.4369603
## 5055   4.6009672
## 5056   4.7218509
## 5057   6.4069747
## 5058   5.6131614
## 5059   6.1106514
## 5060   5.3280218
## 5061   4.6777161
## 5062   5.2829190
## 5063   4.5737221
## 5064   5.5152001
## 5065   5.4373788
## 5066   4.0183626
## 5067   4.8431005
## 5068   3.3123621
## 5069   3.6053384
## 5070   3.4026113
## 5071   3.4964239
## 5072   5.6965706
## 5073   3.5844364
## 5074   4.3756317
## 5075   3.6678896
## 5076   3.8388943
## 5077   3.0802231
## 5078   4.2143986
## 5079   4.9660847
## 5080   4.3132374
## 5081   3.7848607
## 5082   3.8774520
## 5083   3.5633420
## 5084   3.5896017
## 5085   4.1682445
## 5086   4.9022807
## 5087   5.3519205
## 5088   4.7263445
## 5089   4.8756933
## 5090   4.9288559
## 5091   4.1949389
## 5092   3.9101468
## 5093   3.4517372
## 5094   3.7983323
## 5095   4.1024081
## 5096   3.5707853
## 5097   3.7762536
## 5098   4.1434728
## 5099   2.0189902
## 5100   7.1634470
## 5101   7.6902727
## 5102   4.9965419
## 5103   5.5884915
## 5104   4.0826789
## 5105   3.7867772
## 5106   5.1785144
## 5107   3.4668474
## 5108   4.6689537
## 5109   3.6167333
## 5110   3.1265024
## 5111   3.5001161
## 5112   3.5440399
## 5113   3.8262208
## 5114   4.6717822
## 5115   4.3572126
## 5116   3.4266119
## 5117   6.3932701
## 5118   3.4953418
## 5119   3.3693491
## 5120   4.2108599
## 5121   2.3301314
## 5122   3.2084485
## 5123   4.9116715
## 5124   4.9382486
## 5125   3.8538061
## 5126   3.2966556
## 5127   4.5387096
## 5128   5.4087132
## 5129   5.4829426
## 5130   1.5008316
## 5131   7.4343050
## 5132   8.0491584
## 5133   5.4996056
## 5134   6.4645443
## 5135   6.4308403
## 5136   6.8682783
## 5137   4.5767026
## 5138   2.4871128
## 5139   3.8018933
## 5140   2.9015222
## 5141   4.3293183
## 5142   2.8904924
## 5143   5.0573103
## 5144   4.8357454
## 5145   3.9446814
## 5146   2.9459439
## 5147   3.8111161
## 5148   5.7114174
## 5149   4.6342189
## 5150   4.7971153
## 5151   5.7826323
## 5152   3.0969936
## 5153   3.3783960
## 5154   4.3031774
## 5155   4.4011737
## 5156   3.5309706
## 5157   2.8946222
## 5158   2.8832814
## 5159   3.0610143
## 5160   2.6753528
## 5161   2.9859842
## 5162   3.0506589
## 5163   5.8957234
## 5164   6.7726576
## 5165   5.8632748
## 5166   5.4509249
## 5167   5.6500016
## 5168   2.5671615
## 5169   6.0334416
## 5170   4.0120744
## 5171   6.8204246
## 5172   6.6276833
## 5173   3.3949517
## 5174   5.5344291
## 5175   6.4358188
## 5176   6.4044745
## 5177   4.5623128
## 5178   4.0540506
## 5179   3.1351438
## 5180   3.7417556
## 5181   2.7604173
## 5182   4.8435575
## 5183   4.8195162
## 5184   3.2281614
## 5185   4.9827919
## 5186   5.0505220
## 5187   3.7000614
## 5188   4.9967287
## 5189   4.0080404
## 5190   5.4590134
## 5191   6.0815991
## 5192   2.9997242
## 5193   4.2610293
## 5194   4.6187169
## 5195   5.2476105
## 5196   4.9248821
## 5197   4.4236889
## 5198   4.7229681
## 5199   5.5776938
## 5200   4.6718099
## 5201   5.3590930
## 5202   6.3690653
## 5203   5.1061002
## 5204   5.6841944
## 5205   2.0868672
## 5206   4.2466600
## 5207   5.3631570
## 5208   4.4113106
## 5209   4.9989694
## 5210   4.1475145
## 5211   2.6522076
## 5212   4.7161856
## 5213   7.3550781
## 5214   4.6474399
## 5215   4.7821564
## 5216   5.2633506
## 5217   4.8678600
## 5218   4.1081494
## 5219   4.4944672
## 5220   2.5525289
## 5221   2.8565094
## 5222   4.6958060
## 5223   4.4520414
## 5224   6.2748045
## 5225   3.8759827
## 5226   4.1394869
## 5227   3.3361145
## 5228   3.7599759
## 5229   2.1926679
## 5230   2.4020497
## 5231   4.8812765
## 5232   3.2504980
## 5233   3.1884624
## 5234   5.0174152
## 5235   3.2664750
## 5236   4.0825551
## 5237   5.2011807
## 5238   3.7973704
## 5239   4.0295266
## 5240   5.3349335
## 5241   3.8209166
## 5242   7.1506089
## 5243   5.1181501
## 5244   5.0604960
## 5245   5.5562718
## 5246   5.5664695
## 5247   5.8396837
## 5248   6.5090325
## 5249   5.1089505
## 5250   3.7473929
## 5251   4.2734291
## 5252   4.0318165
## 5253   3.3283348
## 5254   3.9222779
## 5255   5.0775354
## 5256   7.5781635
## 5257   6.9141010
## 5258   2.4807416
## 5259   3.5507407
## 5260   4.9940929
## 5261   5.7049780
## 5262   5.7143078
## 5263   4.6572524
## 5264   5.0633878
## 5265   5.5765438
## 5266   4.6921103
## 5267   4.4335414
## 5268   4.4297740
## 5269   4.1301952
## 5270   2.7508501
## 5271   3.3336808
## 5272   4.5975638
## 5273   5.5217122
## 5274   5.2131382
## 5275   2.7723747
## 5276   4.9093705
## 5277   6.4849277
## 5278   6.4836435
## 5279   5.1450857
## 5280   5.6782185
## 5281   4.0885210
## 5282   5.6463425
## 5283   4.4540639
## 5284   5.6365823
## 5285   5.9190382
## 5286   4.2259334
## 5287   1.7995615
## 5288   4.2327130
## 5289   4.8482319
## 5290   5.2829588
## 5291   2.5261590
## 5292   4.1524221
## 5293   4.2492126
## 5294   5.3992171
## 5295   3.3723457
## 5296   3.3177094
## 5297   4.6250438
## 5298   3.5957853
## 5299   4.9582340
## 5300   4.3989896
## 5301   4.3466014
## 5302   3.6863886
## 5303   5.2496299
## 5304   5.2575838
## 5305   4.6375807
## 5306   5.8704214
## 5307   6.0424363
## 5308   4.0450544
## 5309   3.7128497
## 5310   7.0232572
## 5311   7.1392228
## 5312   6.2569702
## 5313   6.2156056
## 5314   4.0066131
## 5315   4.3486188
## 5316   4.6097823
## 5317   2.8269645
## 5318   5.1879169
## 5319   4.7127131
## 5320   6.1591924
## 5321   4.5702143
## 5322   5.0025261
## 5323   5.6147980
## 5324   3.4139213
## 5325   2.3491979
## 5326   5.5088226
## 5327   3.0075895
## 5328   4.2686164
## 5329   3.8022648
## 5330   4.3938300
## 5331   4.9181486
## 5332   4.3738457
## 5333   6.0058241
## 5334   4.9334920
## 5335   3.2535203
## 5336   5.3284255
## 5337   3.9911118
## 5338   4.3147188
## 5339   5.2856352
## 5340   4.4421315
## 5341   3.0236404
## 5342   3.3668743
## 5343   5.0937873
## 5344   5.0103833
## 5345   5.7215154
## 5346   6.6581216
## 5347   5.0047116
## 5348   5.7876338
## 5349   4.0390080
## 5350   3.6192776
## 5351   3.7130018
## 5352   5.9433305
## 5353   5.3420100
## 5354   4.5148485
## 5355   6.6750368
## 5356   2.5564771
## 5357   3.7182910
## 5358   4.9067456
## 5359   4.7937003
## 5360   3.8501384
## 5361   3.7110370
## 5362   4.1354951
## 5363   5.6832580
## 5364   3.7133897
## 5365   4.3050662
## 5366   3.6147566
## 5367   2.4588329
## 5368   4.3239129
## 5369   3.4197783
## 5370   4.0508703
## 5371   4.3456481
## 5372   5.0025046
## 5373   3.3513996
## 5374   5.3212153
## 5375   4.1401778
## 5376   2.6545918
## 5377   3.9933673
## 5378   3.3337428
## 5379   2.1669592
## 5380   3.0009144
## 5381   4.6813977
## 5382   4.5612437
## 5383   5.6318577
## 5384   4.4826737
## 5385   4.6751804
## 5386   4.4843173
## 5387   3.6405298
## 5388   4.4104554
## 5389   4.5533060
## 5390   3.4356070
## 5391   4.0458392
## 5392   3.9439000
## 5393   6.6066809
## 5394   3.6431047
## 5395   2.4470374
## 5396   3.0478485
## 5397   4.5283142
## 5398   2.8366656
## 5399   1.8859183
## 5400   3.8318458
## 5401   2.9816302
## 5402   3.1429450
## 5403   4.5026052
## 5404   4.7824809
## 5405   5.3001293
## 5406   5.7142786
## 5407   4.7831566
## 5408   3.1962760
## 5409   3.7875827
## 5410   3.9712036
## 5411   5.8233125
## 5412   4.6803664
## 5413   3.9283079
## 5414   3.1668784
## 5415   4.3341098
## 5416   3.1866363
## 5417   5.2528603
## 5418   5.0826100
## 5419   5.2958337
## 5420   5.3646853
## 5421   4.0751367
## 5422   3.3047662
## 5423   4.3079697
## 5424   5.2042555
## 5425   3.8131699
## 5426   5.5147553
## 5427   6.2151115
## 5428   5.3199761
## 5429   5.3084181
## 5430   5.3943212
## 5431   4.6569445
## 5432   5.1311779
## 5433   5.1174173
## 5434   6.0597780
## 5435   4.9996095
## 5436   3.8160953
## 5437   5.0739731
## 5438   4.0747193
## 5439   4.1205097
## 5440   3.5012545
## 5441   3.9859594
## 5442   4.0615114
## 5443   4.7515206
## 5444   3.5359821
## 5445   4.3130753
## 5446   6.5398746
## 5447   5.4823458
## 5448   4.6501421
## 5449   3.3207885
## 5450   4.4228541
## 5451   5.6464727
## 5452   5.1025763
## 5453   5.3244019
## 5454   3.7264430
## 5455   4.7357849
## 5456   3.1670648
## 5457   3.9500250
## 5458   4.2902024
## 5459   3.6715048
## 5460   3.6353226
## 5461   3.9446707
## 5462   3.4801118
## 5463   2.9866147
## 5464   3.2353362
## 5465   4.0212280
## 5466   3.3060394
## 5467   3.9941553
## 5468   4.7402759
## 5469   2.9528015
## 5470   4.4473791
## 5471   3.1176528
## 5472   6.4341363
## 5473   6.8156430
## 5474   5.2582820
## 5475   3.4538795
## 5476   5.0550417
## 5477   2.8437904
## 5478   2.7129995
## 5479   7.6615546
## 5480   5.4602116
## 5481   3.5236379
## 5482   7.8508508
## 5483   6.2665393
## 5484   5.2453031
## 5485   1.5946751
## 5486   3.3138016
## 5487   4.3380317
## 5488   4.5468614
## 5489   1.8020702
## 5490   2.7936977
## 5491   3.1057524
## 5492   3.4965769
## 5493   2.7244968
## 5494   3.5284575
## 5495   5.6975619
## 5496   5.9565543
## 5497   7.1022164
## 5498   6.0642194
## 5499   6.0811895
## 5500   5.5167230
## 5501   5.4721253
## 5502   5.3290675
## 5503   5.2569236
## 5504   4.9701989
## 5505   6.9967457
## 5506   3.8747418
## 5507   3.5519886
## 5508   2.5102097
## 5509   2.2376605
## 5510   6.1002448
## 5511   2.5920261
## 5512   4.4250482
## 5513   4.4746343
## 5514   3.1790609
## 5515   4.8512503
## 5516   4.4180434
## 5517   4.0470046
## 5518   4.1624318
## 5519   2.6297546
## 5520   4.9122516
## 5521   4.3720262
## 5522   4.9784901
## 5523   4.6385835
## 5524   2.1841161
## 5525   2.3227358
## 5526   2.4083635
## 5527   2.5522046
## 5528   5.9157849
## 5529   5.2985658
## 5530   2.4620685
## 5531   4.0418291
## 5532   4.4030357
## 5533   3.1767126
## 5534   5.3127605
## 5535   6.2433300
## 5536   6.2808169
## 5537   6.6551496
## 5538   5.1797343
## 5539   5.0740621
## 5540   4.4398789
## 5541   4.2716991
## 5542   4.9804590
## 5543   4.4625015
## 5544   3.1454515
## 5545   2.6851463
## 5546   3.7001072
## 5547   5.7754293
## 5548   3.8572047
## 5549   7.2963072
## 5550   3.5605905
## 5551   3.8281399
## 5552   4.1987194
## 5553   3.9808347
## 5554   4.2900667
## 5555   4.3314438
## 5556   4.7390940
## 5557   5.4057818
## 5558   5.3665119
## 5559   2.6757788
## 5560   5.7249694
## 5561   3.9505193
## 5562   5.4183210
## 5563   7.6841682
## 5564   7.1267255
## 5565   2.8932395
## 5566   5.2567590
## 5567   3.4992103
## 5568   5.3760120
## 5569   4.9767335
## 5570   3.1499198
## 5571   3.5032757
## 5572   2.7045173
## 5573   2.4706051
## 5574   2.1200699
## 5575   6.1542177
## 5576   5.0404451
## 5577   6.1759875
## 5578   3.6614498
## 5579   5.9215605
## 5580   2.4610993
## 5581   5.8467547
## 5582   3.5673024
## 5583   3.1839702
## 5584   3.3702385
## 5585   3.9261088
## 5586   6.6765012
## 5587   6.0077550
## 5588   5.0250476
## 5589   5.6514524
## 5590   4.0787635
## 5591   3.9154405
## 5592   4.7393703
## 5593   4.7145022
## 5594   2.3706412
## 5595   3.6382809
## 5596   2.4887247
## 5597   3.4346846
## 5598   4.3799659
## 5599   3.2965741
## 5600   4.9328234
## 5601   5.7040695
## 5602   6.2982744
## 5603   6.7162194
## 5604   6.8730558
## 5605   3.4209487
## 5606   2.6173821
## 5607   3.9588785
## 5608   5.8928104
## 5609   6.0206877
## 5610   3.1445330
## 5611   2.8705849
## 5612   5.0166082
## 5613   4.2642745
## 5614   3.6067026
## 5615   2.8880651
## 5616   2.7255186
## 5617   7.0407164
## 5618   3.7505272
## 5619   2.5298192
## 5620   5.0774595
## 5621   4.5485148
## 5622   5.1579967
## 5623   3.0751376
## 5624   3.6541776
## 5625   4.9554736
## 5626   4.1085412
## 5627   5.2590754
## 5628   5.0949229
## 5629   5.7045881
## 5630   4.0346125
## 5631   6.3212906
## 5632   5.2093862
## 5633   2.1771905
## 5634   2.8217589
## 5635   4.2700904
## 5636   4.0091342
## 5637   5.3193132
## 5638   4.1308034
## 5639   3.0921919
## 5640   4.2859430
## 5641   5.4824948
## 5642   5.5969079
## 5643   4.6887214
## 5644   4.1327661
## 5645   2.7459335
## 5646   4.2622178
## 5647   4.3502130
## 5648   3.1494597
## 5649   3.2738389
## 5650   3.2728224
## 5651   3.3851003
## 5652   3.0675704
## 5653   2.4300578
## 5654   2.4475249
## 5655   5.2409163
## 5656   6.5578658
## 5657   4.8275332
## 5658   4.0277255
## 5659   4.2770125
## 5660   4.2737205
## 5661   3.5916957
## 5662   3.8937957
## 5663   4.7724044
## 5664   5.1590007
## 5665   4.4941238
## 5666   3.8467568
## 5667   3.8457014
## 5668   6.8740597
## 5669   2.4745319
## 5670   2.9500971
## 5671   5.0913926
## 5672   5.2888618
## 5673   4.6073435
## 5674   3.8218130
## 5675   4.2062174
## 5676   3.1200303
## 5677   3.7814795
## 5678   5.1895405
## 5679   4.3117263
## 5680   5.1956628
## 5681   4.3175447
## 5682   2.0313361
## 5683   2.2324560
## 5684   2.4608521
## 5685   3.0823375
## 5686   1.7132482
## 5687   3.2358469
## 5688   5.4935371
## 5689   2.6339282
## 5690   3.4945508
## 5691   3.0218593
## 5692   2.8166796
## 5693   2.9524985
## 5694   2.4853335
## 5695   1.8774740
## 5696   4.2088656
## 5697   3.7717147
## 5698   2.9466584
## 5699   4.6455346
## 5700   5.5331851
## 5701   4.0881964
## 5702   3.0400705
## 5703   2.2426556
## 5704   5.4007301
## 5705   4.4248743
## 5706   4.6390447
## 5707   4.7809477
## 5708   5.4062279
## 5709   5.3192045
## 5710   5.8280231
## 5711   4.6412755
## 5712   4.2228830
## 5713   6.5828289
## 5714   7.1158939
## 5715   3.4694452
## 5716   2.4015525
## 5717   3.8975254
## 5718   4.6728785
## 5719   3.7728599
## 5720   3.8877696
## 5721   3.3891072
## 5722   3.6412978
## 5723   3.4479984
## 5724   3.4961170
## 5725   6.4782366
## 5726   4.1976339
## 5727   3.8974710
## 5728   4.4777554
## 5729   3.5336585
## 5730   3.4423132
## 5731   4.6419098
## 5732   3.9653438
## 5733   3.6968100
## 5734   3.0688505
## 5735   3.4942534
## 5736   3.7128041
## 5737   3.1202543
## 5738   2.5506201
## 5739   4.8277602
## 5740   3.4337383
## 5741   5.2342357
## 5742   3.6922344
## 5743   4.1991107
## 5744   4.2944724
## 5745   4.9949417
## 5746   3.4675350
## 5747   6.0402607
## 5748   5.9816282
## 5749   3.7527631
## 5750   3.3609803
## 5751   5.6904153
## 5752   6.9858296
## 5753   3.4906046
## 5754   3.5853818
## 5755   3.1042227
## 5756   5.7926328
## 5757   4.7009188
## 5758   3.6092810
## 5759   3.5793367
## 5760   3.4936158
## 5761   5.1086091
## 5762   5.2946883
## 5763   6.1495831
## 5764   3.5311940
## 5765   4.4152631
## 5766   4.6810866
## 5767   3.6223667
## 5768   4.3811745
## 5769   4.3088447
## 5770   3.8471341
## 5771   4.4930978
## 5772   3.1514068
## 5773   3.9469961
## 5774   2.5076136
## 5775   3.4934282
## 5776   3.8525401
## 5777   3.9819576
## 5778   3.6780770
## 5779   4.0926659
## 5780   5.0653126
## 5781   4.1425177
## 5782   3.9010335
## 5783   4.5434916
## 5784   3.9859655
## 5785   3.4060550
## 5786   3.6305261
## 5787   4.6098513
## 5788   5.1117953
## 5789   5.4609954
## 5790   3.5806152
## 5791   4.0552513
## 5792   5.8235051
## 5793   5.8227715
## 5794   3.6549882
## 5795   2.8529979
## 5796   5.0010347
## 5797   3.4775798
## 5798   3.4715931
## 5799   4.0012770
## 5800   4.8840876
## 5801   6.0265585
## 5802   6.9309231
## 5803   4.6776789
## 5804   5.6802657
## 5805   4.5648894
## 5806   4.1403331
## 5807   4.2916163
## 5808   2.9116841
## 5809   6.9372047
## 5810   6.2774975
## 5811   2.8850709
## 5812   4.6750422
## 5813   2.9122119
## 5814   2.9006474
## 5815   3.0552293
## 5816   4.0388082
## 5817   4.0254348
## 5818   3.7787474
## 5819   4.2438251
## 5820   5.1711073
## 5821   4.5182811
## 5822   4.4404070
## 5823   2.3244280
## 5824   4.2548082
## 5825   4.7925880
## 5826   4.9978560
## 5827   4.6839178
## 5828   4.6852592
## 5829   2.8516865
## 5830   4.5380458
## 5831   3.9658516
## 5832   3.0494821
## 5833   6.5631759
## 5834   5.9119438
## 5835   4.4827251
## 5836   5.6852165
## 5837   4.7802732
## 5838   5.1469689
## 5839   4.2422633
## 5840   4.1479876
## 5841   2.9593498
## 5842   2.4000820
## 5843   3.0517426
## 5844   3.1740238
## 5845   3.4878180
## 5846   5.5174451
## 5847   4.2635985
## 5848   3.6205248
## 5849   3.7566408
## 5850   3.2397740
## 5851   2.6943762
## 5852   3.0651832
## 5853   5.0436563
## 5854   5.6942242
## 5855   4.0140987
## 5856   3.4284279
## 5857   4.4236159
## 5858   5.3487564
## 5859   3.9168646
## 5860   3.6352222
## 5861   5.7773632
## 5862   4.5790673
## 5863   2.9501902
## 5864   3.7989716
## 5865   4.8233436
## 5866   3.5085902
## 5867   6.5216371
## 5868   4.7480090
## 5869   5.3479805
## 5870   3.3859245
## 5871   3.2858455
## 5872   2.9342554
## 5873   5.5490204
## 5874   6.4605127
## 5875   5.7588618
## 5876   4.4476837
## 5877   1.8245384
## 5878   5.4469300
## 5879   4.5735680
## 5880   5.0402649
## 5881   4.8106909
## 5882   1.5008222
## 5883   3.5362182
## 5884   5.0403427
## 5885   4.3130800
## 5886   3.1273058
## 5887   4.7439552
## 5888   5.2455486
## 5889   2.9263209
## 5890   3.5992968
## 5891   2.7555299
## 5892   4.0700796
## 5893   3.0206698
## 5894   3.3720620
## 5895   3.2417702
## 5896   4.2981233
## 5897   3.6052619
## 5898   4.5861516
## 5899   4.7277808
## 5900   3.5273821
## 5901   3.5345625
## 5902   2.8065322
## 5903   3.7349295
## 5904   4.3045086
## 5905   3.9449619
## 5906   3.4747722
## 5907   4.1472999
## 5908   4.4152752
## 5909   4.0371214
## 5910   5.6708551
## 5911   5.4505318
## 5912   4.0562955
## 5913   4.5874339
## 5914   3.9511738
## 5915   4.5046932
## 5916   4.8284413
## 5917   6.0974850
## 5918   3.7004871
## 5919   2.8904297
## 5920   4.6674432
## 5921   4.6307755
## 5922   2.4840858
## 5923   3.3339984
## 5924   7.7248568
## 5925   8.1961330
## 5926   4.4736124
## 5927   4.1190817
## 5928   3.9702384
## 5929   4.5050053
## 5930   4.7723780
## 5931   4.4785144
## 5932   4.1355346
## 5933   4.6102121
## 5934   4.6619694
## 5935   6.0806818
## 5936   5.0917751
## 5937   2.4142428
## 5938   4.3826587
## 5939   3.6082991
## 5940   3.4525824
## 5941   4.3150600
## 5942   4.3317922
## 5943   4.9440372
## 5944   4.5707791
## 5945   5.5082962
## 5946   4.2380523
## 5947   3.7349455
## 5948   2.7978079
## 5949   3.3607372
## 5950   4.4836073
## 5951   4.1352536
## 5952   4.3472864
## 5953   3.7675449
## 5954   3.6154822
## 5955   3.0280143
## 5956   2.4215949
## 5957   1.7125137
## 5958   3.8698475
## 5959   6.2030287
## 5960   2.5873968
## 5961   5.8443461
## 5962   5.7707294
## 5963   6.1488642
## 5964   5.0846793
## 5965   5.3203850
## 5966   2.7843553
## 5967   5.1602063
## 5968   3.8455941
## 5969   4.3664353
## 5970   3.7621839
## 5971   4.3915810
## 5972   4.5594225
## 5973   4.8093785
## 5974   3.6738238
## 5975   2.9529219
## 5976   3.4024368
## 5977   2.5828810
## 5978   2.1455740
## 5979   2.3025113
## 5980   4.8356653
## 5981   4.7111178
## 5982   3.9717949
## 5983   4.1925256
## 5984   3.3667914
## 5985   2.4131621
## 5986   5.8900415
## 5987   3.5194633
## 5988   5.2328574
## 5989   3.3990306
## 5990   3.2892457
## 5991   2.7979513
## 5992   1.5506859
## 5993   2.2115001
## 5994   1.8955833
## 5995   2.4715145
## 5996   5.2145449
## 5997   5.1410645
## 5998   4.6427542
## 5999   3.6990794
## 6000   4.2300348
## 6001   4.7302647
## 6002   3.6924492
## 6003   1.9001986
## 6004   3.5216554
## 6005   3.9655339
## 6006   2.9091254
## 6007   3.5366092
## 6008   4.8625065
## 6009   3.1993030
## 6010   3.4372768
## 6011   3.3407815
## 6012   5.5489642
## 6013   2.8292123
## 6014   5.8100476
## 6015   4.6716535
## 6016   4.6101392
## 6017   4.8857549
## 6018   5.2521643
## 6019   4.8232995
## 6020   3.9762995
## 6021   5.0110334
## 6022   5.8400707
## 6023   5.9975176
## 6024   5.5252538
## 6025   4.3491004
## 6026   6.0222049
## 6027   7.4752341
## 6028   6.2948655
## 6029   7.1627866
## 6030   6.3239972
## 6031   4.8884150
## 6032   4.8268130
## 6033   5.8972857
## 6034   4.2736641
## 6035   5.8361339
## 6036   4.7642838
## 6037   3.7260209
## 6038   3.4524512
## 6039   4.8638627
## 6040   5.5149553
## 6041   5.4795611
## 6042   5.5889764
## 6043   4.3481992
## 6044   4.9678157
## 6045   3.8944972
## 6046   3.8164687
## 6047   3.1632192
## 6048   5.2252090
## 6049   2.1405867
## 6050   3.2019905
## 6051   4.9102739
## 6052   3.9947570
## 6053   4.6013237
## 6054   5.2288321
## 6055   3.8206912
## 6056   4.6122089
## 6057   4.7311455
## 6058   5.3325234
## 6059   4.1294470
## 6060   4.4537047
## 6061   3.7264370
## 6062   4.6410446
## 6063   2.0261862
## 6064   4.7523506
## 6065   5.5424114
## 6066   5.0622171
## 6067   4.4724782
## 6068   4.9445334
## 6069   6.2526081
## 6070   6.5316680
## 6071   3.8664052
## 6072   5.8160728
## 6073   2.6789348
## 6074   2.7570359
## 6075   3.5379466
## 6076   4.1905832
## 6077   4.0276071
## 6078   3.0506414
## 6079   4.2150889
## 6080   5.7052075
## 6081   5.0828866
## 6082   3.0354696
## 6083   4.0737426
## 6084   3.9980277
## 6085   3.4605716
## 6086   2.6263438
## 6087   4.3370699
## 6088   3.5937823
## 6089   3.6346858
## 6090   3.5863551
## 6091   4.4943534
## 6092   4.2243508
## 6093   4.0776232
## 6094   3.4498756
## 6095   2.4279488
## 6096   4.8952880
## 6097   4.1667497
## 6098   4.1996386
## 6099   5.1463332
## 6100   4.8990717
## 6101   3.4465344
## 6102   4.3404502
## 6103   4.4023524
## 6104   3.5419834
## 6105   3.0936653
## 6106   4.0992724
## 6107   4.3428560
## 6108   4.0133447
## 6109   4.3855544
## 6110   4.1994208
## 6111   4.9881299
## 6112   3.9861435
## 6113   3.6370217
## 6114   4.5696870
## 6115   3.1197638
## 6116   4.2012731
## 6117   3.4399247
## 6118   3.8635859
## 6119   6.3360379
## 6120   5.4233502
## 6121   4.5001284
## 6122   3.4828979
## 6123   2.7383843
## 6124   5.7887989
## 6125   4.7040722
## 6126   4.7862024
## 6127   2.4744923
## 6128   6.1572598
## 6129   5.1326940
## 6130   6.7085371
## 6131   4.6445384
## 6132   5.1104415
## 6133   4.8011873
## 6134   5.1414756
## 6135   3.4704072
## 6136   4.5309643
## 6137   2.2442863
## 6138   2.1044678
## 6139   5.9656939
## 6140   3.5595598
## 6141   3.8573371
## 6142   3.4061979
## 6143   2.3762732
## 6144   4.6662162
## 6145   3.0455954
## 6146   2.7373384
## 6147   5.3855232
## 6148   3.5388331
## 6149   3.3037318
## 6150   3.8847907
## 6151   5.2344137
## 6152   4.5460906
## 6153   6.8270468
## 6154   3.4868304
## 6155   2.1709981
## 6156   2.2957693
## 6157   4.3316148
## 6158   4.6945118
## 6159   3.3753404
## 6160   3.4572832
## 6161   2.6249473
## 6162   2.3250733
## 6163   2.6283867
## 6164   5.1480385
## 6165   4.4004800
## 6166   3.3875337
## 6167   5.4762203
## 6168   4.9489466
## 6169   4.3389857
## 6170   4.9166275
## 6171   4.4186529
## 6172   3.4599150
## 6173   3.7174192
## 6174   4.3576172
## 6175   4.4902085
## 6176   4.0191953
## 6177   4.6506106
## 6178   4.3040958
## 6179   3.9755398
## 6180   4.4300963
## 6181   4.6557465
## 6182   3.9738272
## 6183   6.4437801
## 6184   5.8117864
## 6185   4.3450686
## 6186   4.4941387
## 6187   4.7680809
## 6188   4.8994303
## 6189   5.4477207
## 6190   4.9345380
## 6191   4.4085776
## 6192   4.6213644
## 6193   5.2390914
## 6194   6.1250091
## 6195   6.0340919
## 6196   2.2905169
## 6197   2.2946675
## 6198   6.1852346
## 6199   4.7670942
## 6200   3.2279210
## 6201   4.0950027
## 6202   4.4441836
## 6203   4.0573097
## 6204   3.1202185
## 6205   2.8256630
## 6206   4.5257983
## 6207   3.5920430
## 6208   4.3017332
## 6209   3.9859541
## 6210   4.7297644
## 6211   4.1702118
## 6212   4.3348212
## 6213   3.5289491
## 6214   4.6790197
## 6215   5.1503755
## 6216   3.5492153
## 6217   2.1145943
## 6218   3.4232253
## 6219   4.3565313
## 6220   4.6381333
## 6221   4.3784286
## 6222   4.6568853
## 6223   4.2815970
## 6224   5.1194530
## 6225   5.4446948
## 6226   5.1427864
## 6227   4.3784017
## 6228   3.7062489
## 6229   3.5705786
## 6230   4.4241338
## 6231   3.1315304
## 6232   4.8369995
## 6233   3.9065168
## 6234   4.3395335
## 6235   3.4612370
## 6236   4.9440549
## 6237   3.4660017
## 6238   2.3390258
## 6239   6.6934305
## 6240   0.6041352
## 6241   5.5015227
## 6242   4.7135219
## 6243   2.3776029
## 6244   4.6691852
## 6245   5.0756098
## 6246   4.5152261
## 6247   4.6691730
## 6248   4.1335588
## 6249   5.3987393
## 6250   6.2832389
## 6251   3.4014055
## 6252   4.9585550
## 6253   5.1443645
## 6254   4.3963358
## 6255   2.9685264
## 6256   1.8946393
## 6257   2.1921497
## 6258   4.7978581
## 6259   2.7728822
## 6260   4.0822771
## 6261   4.5873868
## 6262   4.6796848
## 6263   2.6989395
## 6264   2.4381167
## 6265   2.1951871
## 6266   5.9066830
## 6267   3.1147592
## 6268   4.4948876
## 6269   4.2477580
## 6270   3.4915147
## 6271   5.5480818
## 6272   4.8219656
## 6273   3.1791122
## 6274   4.8778120
## 6275   3.6184822
## 6276   5.8390849
## 6277   2.5199098
## 6278   2.6557108
## 6279   4.4351425
## 6280   4.5546963
## 6281   4.0690110
## 6282   4.1578449
## 6283   4.3747109
## 6284   6.0642654
## 6285   4.2166624
## 6286   2.9119555
## 6287   3.2097053
## 6288   4.8950572
## 6289   5.4834604
## 6290   4.2173047
## 6291   5.3444738
## 6292   5.4921702
## 6293   5.9430782
## 6294   5.3312819
## 6295   4.2322730
## 6296   4.9448816
## 6297   3.2659040
## 6298   5.0521874
## 6299   4.5823989
## 6300   4.5197936
## 6301   3.8141135
## 6302   4.7424389
## 6303   3.6806132
## 6304   4.7723108
## 6305   4.7268882
## 6306   3.5627754
## 6307   4.1941531
## 6308   4.0690929
## 6309   3.4775340
## 6310   3.8160202
## 6311   2.4363652
## 6312   4.1939569
## 6313   2.2370220
## 6314   2.6889896
## 6315   2.8617308
## 6316   3.1102539
## 6317   2.8256688
## 6318   5.8335195
## 6319   6.3164228
## 6320   6.4696794
## 6321   3.1114507
## 6322   3.7156005
## 6323   4.8211665
## 6324   5.4885114
## 6325   5.7740896
## 6326   5.2759283
## 6327   3.7614458
## 6328   4.2949641
## 6329   3.9649018
## 6330   4.2249214
## 6331   3.9214010
## 6332   3.9003037
## 6333   3.3009355
## 6334   4.1662418
## 6335   3.3356995
## 6336   5.0928793
## 6337   4.9875813
## 6338   5.1800346
## 6339   4.3926756
## 6340   5.1820528
## 6341   4.6881077
## 6342   5.7317918
## 6343   4.7464370
## 6344   4.1785885
## 6345   4.8258000
## 6346   5.2176272
## 6347   5.1236806
## 6348   3.8909034
## 6349   2.7225450
## 6350   7.0043948
## 6351   5.0968520
## 6352   3.4897714
## 6353   6.8476982
## 6354   6.2795720
## 6355   4.3328468
## 6356   3.4867137
## 6357   5.1175137
## 6358   4.4531618
## 6359   3.9214867
## 6360   5.2720796
## 6361   5.1496627
## 6362   6.7172296
## 6363   6.5400138
## 6364   5.7156052
## 6365   5.6746787
## 6366   4.9378998
## 6367   4.0658000
## 6368   6.0138897
## 6369   2.5703972
## 6370   2.8867669
## 6371   2.7369329
## 6372   2.8739387
## 6373   3.6657479
## 6374   3.7683925
## 6375   4.0379373
## 6376   4.2560022
## 6377   4.4392945
## 6378   2.1470762
## 6379   6.4400214
## 6380   5.2788987
## 6381   3.7972466
## 6382   4.4361683
## 6383   4.7521896
## 6384   3.4763145
## 6385   3.7093496
## 6386   3.1997375
## 6387   4.8602703
## 6388   4.4559659
## 6389   4.2332017
## 6390   5.7954275
## 6391   4.5089015
## 6392   4.6513618
## 6393   3.6676912
## 6394   4.4065013
## 6395   3.7360968
## 6396   4.3976634
## 6397   5.1884101
## 6398   5.2127240
## 6399   3.4044763
## 6400   2.9122319
## 6401   2.2655772
## 6402   1.0934766
## 6403   2.8910336
## 6404   2.2008107
## 6405   3.0235068
## 6406   2.6141293
## 6407   5.1201478
## 6408   3.7577473
## 6409   4.5253745
## 6410   4.3442875
## 6411   4.7933930
## 6412   2.3930988
## 6413   3.3183296
## 6414   2.4419177
## 6415   3.6253878
## 6416   3.8017720
## 6417   3.5478310
## 6418   2.1032599
## 6419   4.6885892
## 6420   2.1058643
## 6421   1.8938784
## 6422   3.9334171
## 6423   4.7536585
## 6424   3.5767689
## 6425   3.5929186
## 6426   5.3204054
## 6427   5.1314317
## 6428   4.2470419
## 6429   3.6354025
## 6430   6.2757904
## 6431   5.2741265
## 6432   3.7493832
## 6433   3.4708421
## 6434   6.0862812
## 6435   5.7630657
## 6436   4.5479203
## 6437   6.1022851
## 6438   4.2254649
## 6439   4.7382601
## 6440   4.2786235
## 6441   4.0894388
## 6442   3.0943330
## 6443   3.9411262
## 6444   3.4452823
## 6445   4.4997191
## 6446   3.2944724
## 6447   3.7074759
## 6448   4.1132041
## 6449   4.2777746
## 6450   5.2755373
## 6451   3.7307367
## 6452   4.0834181
## 6453   2.9028075
## 6454   3.2061216
## 6455   4.4755134
## 6456   2.5370710
## 6457   6.8659861
## 6458   3.7521704
## 6459   2.1949895
## 6460   1.7685116
## 6461   4.8410471
## 6462   2.8845830
## 6463   3.8000415
## 6464   3.1985897
## 6465   2.7396951
## 6466   4.0479707
## 6467   4.1482776
## 6468   4.0261598
## 6469   4.3361762
## 6470   4.3998745
## 6471   4.1026943
## 6472   7.0277805
## 6473   5.7236013
## 6474   4.8576014
## 6475   3.9952793
## 6476   4.1418289
## 6477   4.5886416
## 6478   4.0380254
## 6479   4.3584288
## 6480   3.6897773
## 6481   3.6398043
## 6482   4.1157517
## 6483   4.3198816
## 6484   2.1521788
## 6485   5.4050706
## 6486   4.8021852
## 6487   4.4262862
## 6488   4.7296476
## 6489   3.8296901
## 6490   4.0306486
## 6491   5.1614040
## 6492   5.3406047
## 6493   3.1215359
## 6494   4.0388067
## 6495   5.8641268
## 6496   4.4043377
## 6497   5.1826077
## 6498   3.7964867
## 6499   4.8720600
## 6500   5.2079290
## 6501   5.0358215
## 6502   5.0655346
## 6503   2.1497696
## 6504   3.0841352
## 6505   5.6395629
## 6506   1.5023345
## 6507   7.5444330
## 6508   6.8352469
## 6509   2.3582039
## 6510   4.8374054
## 6511   5.3161020
## 6512   4.4256436
## 6513   6.0992122
## 6514   5.4480668
## 6515   5.5876156
## 6516   3.3412154
## 6517   3.1667746
## 6518   5.1796503
## 6519   5.2601282
## 6520   4.7484684
## 6521   4.5619040
## 6522   4.3025335
## 6523   3.0405297
## 6524   3.4150295
## 6525   3.3340904
## 6526   5.4828019
## 6527   5.1296088
## 6528   5.0187732
## 6529   3.2406267
## 6530   5.2515082
## 6531   5.3731452
## 6532   5.0003604
## 6533   4.5582901
## 6534   4.7001837
## 6535   4.3112968
## 6536   4.4655685
## 6537   3.7414144
## 6538   1.4236243
## 6539   2.6695959
## 6540   3.3041719
## 6541   4.1486989
## 6542   4.1663729
## 6543   3.8659520
## 6544   4.5798497
## 6545   5.0076688
## 6546   6.4533474
## 6547   4.7722169
## 6548   4.2155781
## 6549   4.9359109
## 6550   3.0452885
## 6551   3.0755669
## 6552   3.9022741
## 6553   5.0833052
## 6554   3.4236666
## 6555   3.1611158
## 6556   3.1620453
## 6557   3.4144604
## 6558   2.9137525
## 6559   2.7927843
## 6560   5.5351877
## 6561   4.3676081
## 6562   4.3901808
## 6563   5.8591790
## 6564   3.5126820
## 6565   4.0812939
## 6566   3.7670172
## 6567   3.6867922
## 6568   3.0765518
## 6569   2.9252546
## 6570   5.1350973
## 6571   4.8350292
## 6572   5.5982100
## 6573   5.4998720
## 6574   2.4935279
## 6575   5.4464337
## 6576   4.1245504
## 6577   2.8709614
## 6578   3.9556639
## 6579   1.4481156
## 6580   6.0947421
## 6581   6.5243883
## 6582   4.7199495
## 6583   3.4763263
## 6584   3.8904491
## 6585   4.6658849
## 6586   6.0694826
## 6587   6.1378400
## 6588   6.9440204
## 6589   3.6777927
## 6590   5.6997887
## 6591   4.8893519
## 6592   4.1467990
## 6593   1.9198478
## 6594   3.1316929
## 6595   3.3515003
## 6596   3.5888843
## 6597   3.7661522
## 6598   2.3608243
## 6599   5.0759100
## 6600   3.5021820
## 6601   5.8408229
## 6602   4.2904417
## 6603   4.3201104
## 6604   3.8459064
## 6605   4.0422786
## 6606   4.5210166
## 6607   5.4838708
## 6608   4.6520408
## 6609   3.4453838
## 6610   3.1807812
## 6611   4.6960194
## 6612   5.4124526
## 6613   5.2910530
## 6614   5.4529502
## 6615   2.8798639
## 6616   3.2639811
## 6617   3.1194063
## 6618   3.5110143
## 6619   6.0847188
## 6620   3.3006915
## 6621   3.6395684
## 6622   2.4423519
## 6623   2.1546955
## 6624   1.5464343
## 6625   2.3581332
## 6626   3.7582554
## 6627   4.3480411
## 6628   2.9188562
## 6629   4.0596036
## 6630   3.3797941
## 6631   4.5984994
## 6632   3.3796996
## 6633   5.4645509
## 6634   5.1497733
## 6635   3.6963645
## 6636   4.8619659
## 6637   5.1716251
## 6638   4.3844431
## 6639   3.0410808
## 6640   3.7048903
## 6641   4.5879532
## 6642   3.8346015
## 6643   3.5739798
## 6644   2.1582991
## 6645   3.1965893
## 6646   3.3430871
## 6647   5.0321445
## 6648   4.8939573
## 6649   5.1937861
## 6650   7.5830706
## 6651   4.2938284
## 6652   4.9928951
## 6653   5.1459536
## 6654   4.5917409
## 6655   3.2815164
## 6656   4.2253525
## 6657   3.1122662
## 6658   1.6379001
## 6659   1.4554862
## 6660   2.4106780
## 6661   4.2525002
## 6662   3.6027069
## 6663   4.0415074
## 6664   3.7458015
## 6665   3.6529021
## 6666   2.1392004
## 6667   5.6148021
## 6668   4.5537113
## 6669   7.4940013
## 6670   5.7512797
## 6671   6.0212175
## 6672   4.8733278
## 6673   4.8036623
## 6674   6.4546608
## 6675   6.1768080
## 6676   5.0928177
## 6677   4.8897655
## 6678   4.2887290
## 6679   3.6249850
## 6680   5.3264740
## 6681   5.3615216
## 6682   5.4493285
## 6683   6.0112060
## 6684   4.1033867
## 6685   4.4929046
## 6686   4.0809262
## 6687   5.7654903
## 6688   2.2365736
## 6689   3.6087560
## 6690   3.9165914
## 6691   3.4455882
## 6692   2.7973680
## 6693   5.7989366
## 6694   5.0598545
## 6695   5.3290265
## 6696   5.3271596
## 6697   4.4321086
## 6698   3.8355962
## 6699   4.7058324
## 6700   4.7725448
## 6701   5.4851268
## 6702   3.6344914
## 6703   5.3351945
## 6704   2.4110741
## 6705   3.8885510
## 6706   3.2599838
## 6707   5.3414558
## 6708   5.4296883
## 6709   4.4174149
## 6710   5.2356812
## 6711   5.0615073
## 6712   6.7025451
## 6713   5.4291194
## 6714   5.7924127
## 6715   3.8884661
## 6716   3.2052511
## 6717   4.1306410
## 6718   1.8806615
## 6719   3.6939392
## 6720   2.2838659
## 6721   1.9612628
## 6722   4.8054819
## 6723   5.0226889
## 6724   4.6078040
## 6725   4.0241659
## 6726   4.4397601
## 6727   4.2256020
## 6728   3.9026766
## 6729   3.8783049
## 6730   4.1106031
## 6731   4.4027057
## 6732   4.0813101
## 6733   3.6094093
## 6734   4.0682775
## 6735   4.1973840
## 6736   3.4665541
## 6737   3.6575745
## 6738   6.1576366
## 6739   4.4869639
## 6740   5.5325279
## 6741   4.6998325
## 6742   3.8096462
## 6743   4.9257527
## 6744   7.6320724
## 6745   7.2757605
## 6746   5.5178703
## 6747   4.1378309
## 6748   4.5578448
## 6749   6.7115613
## 6750   5.8736848
## 6751   7.3679304
## 6752   6.6115129
## 6753   6.1563399
## 6754   4.8449876
## 6755   5.5398610
## 6756   6.9541234
## 6757   5.3991150
## 6758   5.4608309
## 6759   5.9820668
## 6760   4.3830976
## 6761   4.0390610
## 6762   3.3714692
## 6763   3.5221712
## 6764   3.8870809
## 6765   3.9034062
## 6766   5.0622745
## 6767   5.7504219
## 6768   4.5549522
## 6769   4.0226759
## 6770   5.2604491
## 6771   5.4303752
## 6772   4.9434117
## 6773   3.2270169
## 6774   5.2221195
## 6775   2.6408476
## 6776   5.0176435
## 6777   5.4991669
## 6778   5.1190507
## 6779   4.4359152
## 6780   5.6846798
## 6781   3.9107756
## 6782   2.7521790
## 6783   4.5356817
## 6784   4.9167537
## 6785   3.6285001
## 6786   4.9862005
## 6787   4.9031563
## 6788   3.8096595
## 6789   3.5998658
## 6790   4.9025877
## 6791   2.9596191
## 6792   2.8072398
## 6793   3.2139949
## 6794   5.3762678
## 6795   3.7663236
## 6796   3.4294997
## 6797   3.7086795
## 6798   4.1802445
## 6799   4.2593590
## 6800   3.7881828
## 6801   3.5210690
## 6802   3.5980756
## 6803   4.1574576
## 6804   4.4868695
## 6805   3.1343431
## 6806   8.1946480
## 6807   4.7234288
## 6808   3.0281449
## 6809   3.9033266
## 6810   4.6149252
## 6811   7.4780738
## 6812   5.0022223
## 6813   4.8536096
## 6814   1.6804794
## 6815   4.0090574
## 6816   5.6421167
## 6817   3.0593487
## 6818   4.1844754
## 6819   3.5924844
## 6820   4.0965828
## 6821   5.7759919
## 6822   4.1565564
## 6823   3.7540317
## 6824   4.0561236
## 6825   4.5644049
## 6826   2.8093234
## 6827   2.6473075
## 6828   5.2558385
## 6829   3.3878407
## 6830   1.2644250
## 6831   1.2726908
## 6832   3.9524284
## 6833   4.0060636
## 6834   3.2083098
## 6835   4.0215396
## 6836   3.3495735
## 6837   3.3726311
## 6838   3.9894608
## 6839   3.8173617
## 6840   3.6629758
## 6841   4.5657024
## 6842   4.3327163
## 6843   2.5521141
## 6844   6.3901937
## 6845   3.1306028
## 6846   4.8161915
## 6847   5.1059813
## 6848   5.3239587
## 6849   4.8984293
## 6850   5.1896387
## 6851   5.3487545
## 6852   4.5262216
## 6853   4.3052030
## 6854   2.0624116
## 6855   2.9822684
## 6856   4.2203007
## 6857   4.3527341
## 6858   3.1845338
## 6859   6.6147599
## 6860   5.2876620
## 6861   3.5770328
## 6862   5.0400464
## 6863   4.9896964
## 6864   4.3789113
## 6865   4.7355573
## 6866   4.3254786
## 6867   4.9254680
## 6868   4.0868170
## 6869   4.2781751
## 6870   4.4471234
## 6871   4.1482310
## 6872   5.9133279
## 6873   4.6820968
## 6874   5.2216507
## 6875   2.9111720
## 6876   3.5061349
## 6877   4.1805136
## 6878   5.0831239
## 6879   4.4008205
## 6880   3.4305388
## 6881   5.2062404
## 6882   5.3544294
## 6883   5.1856965
## 6884   3.8262040
## 6885   6.4445022
## 6886   2.8186573
## 6887   2.2972634
## 6888   2.8940567
## 6889   4.5632212
## 6890   1.8079720
## 6891   3.0736854
## 6892   2.2983787
## 6893   4.5142463
## 6894   2.9411796
## 6895   4.2363633
## 6896   4.3689209
## 6897   3.9452621
## 6898   5.3541939
## 6899   6.9785172
## 6900   5.3767918
## 6901   3.4337215
## 6902   5.8746391
## 6903   6.4188421
## 6904   6.6013229
## 6905   5.2429365
## 6906   6.0417415
## 6907   7.5378505
## 6908   7.1340351
## 6909   6.7840772
## 6910   5.5271502
## 6911   5.1972145
## 6912   4.4808844
## 6913   4.3558122
## 6914   4.3468871
## 6915   4.6641536
## 6916   4.3266883
## 6917   4.3245368
## 6918   4.4321079
## 6919   4.8655896
## 6920   4.4330924
## 6921   4.8663823
## 6922   4.1314972
## 6923   2.8710648
## 6924   4.1733325
## 6925   4.2980682
## 6926   4.2026926
## 6927   3.7499609
## 6928   4.1982197
## 6929   3.1204146
## 6930   3.5800892
## 6931   4.2718412
## 6932   3.4662250
## 6933   2.6981127
## 6934   2.9831691
## 6935   4.6600406
## 6936   5.3330806
## 6937   2.9594509
## 6938   3.2073550
## 6939   3.5546923
## 6940   2.9283401
## 6941   5.8103271
## 6942   2.9427381
## 6943   4.4771291
## 6944   4.7258911
## 6945   5.1085833
## 6946   2.5394719
## 6947   2.9783599
## 6948   3.1488557
## 6949   3.9256241
## 6950   2.8860612
## 6951   6.1224372
## 6952   3.6498138
## 6953   4.9323933
## 6954   4.6871127
## 6955   3.0850877
## 6956   2.3328341
## 6957   4.2180131
## 6958   3.5425317
## 6959   4.2282764
## 6960   5.0338543
## 6961   4.4685021
## 6962   4.9906614
## 6963   3.0546869
## 6964   2.8665541
## 6965   5.4755191
## 6966   4.5680269
## 6967   5.7837896
## 6968   3.6159091
## 6969   3.3527575
## 6970   4.5283218
## 6971   3.9328384
## 6972   2.5394450
## 6973   3.5067777
## 6974   4.7358942
## 6975   7.2733253
## 6976   3.2196971
## 6977   4.9733551
## 6978   4.6013132
## 6979   4.4228401
## 6980   4.7227820
## 6981   3.0264965
## 6982   5.6440981
## 6983   4.7036574
## 6984   5.4154581
## 6985   5.9701450
## 6986   5.2482051
## 6987   5.4600655
## 6988   5.5184591
## 6989   5.6901794
## 6990   6.8602817
## 6991   5.3101062
## 6992   5.5520929
## 6993   6.3195955
## 6994   5.6157753
## 6995   5.2126181
## 6996   2.8335388
## 6997   5.8265770
## 6998   4.5581646
## 6999   4.3242154
## 7000   4.0395078
## 7001   1.8579353
## 7002   5.0415585
## 7003   5.0805117
## 7004   3.4351435
## 7005   4.1429297
## 7006   4.2847702
## 7007   3.3194300
## 7008   3.1036393
## 7009   2.9420507
## 7010   2.9428694
## 7011   7.3355527
## 7012   6.1884186
## 7013   4.5965349
## 7014   2.2595405
## 7015   2.4659101
## 7016   2.7734233
## 7017   3.7443995
## 7018   3.7711007
## 7019   4.3614772
## 7020   4.6928856
## 7021   5.6099088
## 7022   5.5140521
## 7023   3.4671709
## 7024   4.7160763
## 7025   6.9025756
## 7026   2.3799816
## 7027   5.0517818
## 7028   4.3328455
## 7029   6.1464538
## 7030   5.6717982
## 7031   5.6169903
## 7032   3.9365680
## 7033   5.2407722
## 7034   4.3811265
## 7035   5.6917457
## 7036   2.0129352
## 7037   3.7732422
## 7038   3.5880668
## 7039   3.9219034
## 7040   6.4926741
## 7041   6.5270387
## 7042   5.0391449
## 7043   4.2154496
## 7044   4.4937745
## 7045   3.6873471
## 7046   5.4564604
## 7047   6.4146001
## 7048   2.4107326
## 7049   5.2187173
## 7050   5.5949692
## 7051   4.3714256
## 7052   3.0491680
## 7053   3.8221959
## 7054   3.2203958
## 7055   4.8476240
## 7056   4.0197993
## 7057   4.4236171
## 7058   4.3039984
## 7059   3.6581677
## 7060   3.3418852
## 7061   3.2374540
## 7062   4.0473932
## 7063   4.6378625
## 7064   4.6513116
## 7065   1.4539615
## 7066   4.9040397
## 7067   3.3875561
## 7068   6.0397678
## 7069   5.5891401
## 7070   5.1975287
## 7071   7.0298046
## 7072   4.0048011
## 7073   5.0698352
## 7074   4.6256685
## 7075   4.6542379
## 7076   2.4646069
## 7077   6.1082595
## 7078   4.3484737
## 7079   3.8222994
## 7080   5.0884598
## 7081   6.2986926
## 7082   2.2745090
## 7083   3.9538796
## 7084   5.3485560
## 7085   4.8616128
## 7086   3.2479038
## 7087   2.7683839
## 7088   3.8515246
## 7089   3.6984161
## 7090   5.2265263
## 7091   5.6845217
## 7092   3.2616555
## 7093   4.7264750
## 7094   3.6910879
## 7095   4.8733462
## 7096   5.9635469
## 7097   3.6245450
## 7098   5.4511283
## 7099   3.1084669
## 7100   3.8034798
## 7101   4.4879014
## 7102   4.3205811
## 7103   4.3319351
## 7104   3.6846074
## 7105   4.9627388
## 7106   5.0625193
## 7107   4.2083522
## 7108   5.2768376
## 7109   4.1183996
## 7110   4.6290835
## 7111   4.8183673
## 7112   4.4268097
## 7113   4.6265168
## 7114   3.5955079
## 7115   3.8553550
## 7116   2.9271996
## 7117   3.9738233
## 7118   6.3310031
## 7119   4.1135153
## 7120   5.6359188
## 7121   2.0781338
## 7122   2.1124382
## 7123   4.3183756
## 7124   4.2461233
## 7125   4.8874279
## 7126   4.0130796
## 7127   3.5601617
## 7128   3.6979401
## 7129   3.5674553
## 7130   3.2503760
## 7131   3.8275367
## 7132   4.7410614
## 7133   3.9954890
## 7134   5.0918266
## 7135   4.0381013
## 7136   5.0945320
## 7137   4.5335687
## 7138   5.7484161
## 7139   5.5826262
## 7140   3.7222152
## 7141   4.3379522
## 7142   2.9457215
## 7143   1.7709135
## 7144   3.1137172
## 7145   4.5242295
## 7146   3.6064120
## 7147   2.2694874
## 7148   4.2703639
## 7149   4.5182834
## 7150   4.7048503
## 7151   4.8020290
## 7152   5.4781047
## 7153   3.2205422
## 7154   4.7190592
## 7155   4.6593499
## 7156   2.8936541
## 7157   2.2011318
## 7158   4.8617169
## 7159   5.1876945
## 7160   4.6160166
## 7161   3.7640612
## 7162   4.1667233
## 7163   4.6156849
## 7164   3.3776383
## 7165   3.5868547
## 7166   4.8701648
## 7167   2.9440129
## 7168   4.3042762
## 7169   2.3677851
## 7170   2.1264572
## 7171   2.5525150
## 7172   3.6887202
## 7173   3.6087681
## 7174   3.6439678
## 7175   3.5020676
## 7176   4.0062926
## 7177   4.1000117
## 7178   4.2144273
## 7179   5.4479769
## 7180   5.5522449
## 7181   5.7156981
## 7182   4.4257997
## 7183   4.1551845
## 7184   3.9795327
## 7185   3.6074630
## 7186   3.4035492
## 7187   4.9798983
## 7188   4.3769127
## 7189   5.2942541
## 7190   3.6080978
## 7191   5.2829661
## 7192   4.3239167
## 7193   3.5886723
## 7194   2.8461208
## 7195   3.2870516
## 7196   5.3773477
## 7197   2.9446274
## 7198   3.8096592
## 7199   4.5923912
## 7200   6.8505733
## 7201   4.6091840
## 7202   4.0213064
## 7203   2.8800054
## 7204   5.4470273
## 7205   4.5971892
## 7206   3.7607115
## 7207   3.5893825
## 7208   4.6299976
## 7209   4.8705759
## 7210   4.7630118
## 7211   4.9644814
## 7212   4.4356932
## 7213   5.1297624
## 7214   4.7551627
## 7215   4.6772434
## 7216   4.9165998
## 7217   5.4760952
## 7218   5.0969460
## 7219   4.0218447
## 7220   4.5899318
## 7221   4.3869688
## 7222   3.1491960
## 7223   6.0301117
## 7224   4.7520263
## 7225   4.6983209
## 7226   6.6403061
## 7227   6.5352822
## 7228   4.2482358
## 7229   3.9352477
## 7230   5.0163728
## 7231   6.3143503
## 7232   3.6808985
## 7233   3.7031869
## 7234   5.0567619
## 7235   5.5351738
## 7236   4.4932837
## 7237   3.9331848
## 7238   4.6007578
## 7239   4.7970209
## 7240   4.1364274
## 7241   3.6605418
## 7242   5.2849438
## 7243   4.1152367
## 7244   4.4699647
## 7245   4.1292105
## 7246   2.6655318
## 7247   5.8977135
## 7248   4.1451231
## 7249   5.3289446
## 7250   3.0885296
## 7251   3.4481298
## 7252   3.8752329
## 7253   5.0808740
## 7254   5.6868284
## 7255   4.2740782
## 7256   4.1415576
## 7257   7.2071178
## 7258   8.2992197
## 7259   3.5543806
## 7260   1.2296004
## 7261   4.8539293
## 7262   7.1378483
## 7263   2.7985510
## 7264   3.4730907
## 7265   4.5556179
## 7266   3.2704669
## 7267   5.7704504
## 7268   2.7109410
## 7269   5.1391666
## 7270   5.5836995
## 7271   5.4756337
## 7272   3.8123972
## 7273   4.8156388
## 7274   4.3097302
## 7275   4.3141686
## 7276   4.4363796
## 7277   3.2676637
## 7278   4.8009392
## 7279   5.4208806
## 7280   4.8513284
## 7281   2.9753337
## 7282   2.7499470
## 7283   4.6006382
## 7284   4.7940278
## 7285   3.7993043
## 7286   4.5687372
## 7287   4.9132441
## 7288   2.9521556
## 7289   2.1220579
## 7290   5.3664035
## 7291   3.4326681
## 7292   1.7941167
## 7293   5.2597843
## 7294   4.9907306
## 7295   4.6632772
## 7296   3.9485956
## 7297   5.1724978
## 7298   5.8513957
## 7299   4.4697199
## 7300   4.1339195
## 7301   4.0455981
## 7302   3.7737017
## 7303   6.6463531
## 7304   2.7219932
## 7305   3.2737836
## 7306   3.4473845
## 7307   4.1468983
## 7308   4.6758745
## 7309   4.3996582
## 7310   4.5749042
## 7311   3.1766518
## 7312   4.4884871
## 7313   2.8681455
## 7314   4.6692522
## 7315   4.2511349
## 7316   5.1431238
## 7317   3.9304888
## 7318   5.2965030
## 7319   5.9770157
## 7320   2.1504178
## 7321   6.1128998
## 7322   4.8658785
## 7323   4.1400654
## 7324   4.1009849
## 7325   5.4318377
## 7326   5.6542955
## 7327   3.7799204
## 7328   4.8744127
## 7329   4.6774001
## 7330   5.5577701
## 7331   5.5451634
## 7332   4.9902003
## 7333   1.5839868
## 7334   5.5473046
## 7335   5.8468924
## 7336   6.0292088
## 7337   5.9901556
## 7338   7.1990070
## 7339   7.3931815
## 7340   2.2889131
## 7341   3.9690236
## 7342   4.0349720
## 7343   3.9817897
## 7344   2.8041501
## 7345   4.8433712
## 7346   4.0843277
## 7347   5.7709289
## 7348   2.6760553
## 7349   4.8653718
## 7350   3.9052119
## 7351   5.0584434
## 7352   4.0414876
## 7353   5.6418278
## 7354   5.0454701
## 7355   5.6068460
## 7356   5.5779121
## 7357   6.8581714
## 7358   2.9872606
## 7359   2.8808211
## 7360   3.4461948
## 7361   3.8089181
## 7362   3.2167233
## 7363   4.3560860
## 7364   4.0445891
## 7365   4.7864747
## 7366   3.3022461
## 7367   2.1036519
## 7368   4.3276697
## 7369   5.1992486
## 7370   5.5966045
## 7371   4.9769447
## 7372   5.6427488
## 7373   3.7861720
## 7374   3.5717655
## 7375   4.0020894
## 7376   1.9831997
## 7377   5.6704991
## 7378   2.9568799
## 7379   2.8319557
## 7380   2.7715121
## 7381   5.3419631
## 7382   4.5366651
## 7383   5.3539634
## 7384   5.2486613
## 7385   1.3058834
## 7386   5.9977387
## 7387   5.5988661
## 7388   6.6896768
## 7389   3.6722802
## 7390   3.9302418
## 7391   3.1554087
## 7392   3.4649087
## 7393   2.7889444
## 7394   3.9417326
## 7395   4.0356615
## 7396   3.7552056
## 7397   2.7748984
## 7398   4.3810892
## 7399   4.6024478
## 7400   3.4141044
## 7401   2.7369567
## 7402   3.7433385
## 7403   5.9562674
## 7404   5.9801513
## 7405   5.2267456
## 7406   2.4102703
## 7407   2.2114779
## 7408   2.2204656
## 7409   3.0080657
## 7410   2.4919721
## 7411   4.6658179
## 7412   4.8303106
## 7413   4.5441070
## 7414   3.9800089
## 7415   3.8317315
## 7416   3.6156133
## 7417   4.7768414
## 7418   2.7895160
## 7419   4.1654350
## 7420   4.8746595
## 7421   4.4370657
## 7422   3.2032468
## 7423   5.9889242
## 7424   4.7956099
## 7425   5.3721709
## 7426   3.6385196
## 7427   6.0843223
## 7428   3.6929700
## 7429   4.2394411
## 7430   3.6254982
## 7431   3.5620421
## 7432   3.2439153
## 7433   5.6769857
## 7434   4.0219721
## 7435   3.5282826
## 7436   3.7659165
## 7437   4.0582641
## 7438   4.0062737
## 7439   3.9751299
## 7440   2.7719563
## 7441   4.2700598
## 7442   4.4621628
## 7443   2.9453766
## 7444   4.7251133
## 7445   2.7187488
## 7446   5.9152090
## 7447   3.0507873
## 7448   2.6665082
## 7449   7.2054677
## 7450   5.6588115
## 7451   3.2621105
## 7452   4.6953041
## 7453   6.0188286
## 7454   2.1013880
## 7455   1.0545112
## 7456   5.1024206
## 7457   4.0303802
## 7458   4.6624145
## 7459   3.4659712
## 7460   3.6818882
## 7461   4.5592290
## 7462   5.0997448
## 7463   5.4146297
## 7464   2.6585940
## 7465   5.5781090
## 7466   4.4035799
## 7467   4.3643887
## 7468   4.2519540
## 7469   5.0727296
## 7470   3.1520469
## 7471   4.9104990
## 7472   6.5130518
## 7473   4.6162385
## 7474   5.3508828
## 7475   5.5579398
## 7476   3.8148507
## 7477   3.4765437
## 7478   4.1398912
## 7479   3.7676114
## 7480   3.8186263
## 7481   2.7841126
## 7482   4.8448751
## 7483   3.4556373
## 7484   3.9124891
## 7485   4.2002861
## 7486   4.4244547
## 7487   4.2046790
## 7488   3.8339119
## 7489   4.4190125
## 7490   3.3869879
## 7491   3.0077686
## 7492   0.8651236
## 7493   6.3178145
## 7494   5.9212212
## 7495   5.1288842
## 7496   4.7171395
## 7497   3.7689606
## 7498   4.5035837
## 7499   3.6808587
## 7500   4.3567657
## 7501   3.6475884
## 7502   2.9263929
## 7503   3.8869549
## 7504   5.1028909
## 7505   2.4954378
## 7506   5.0864119
## 7507   5.3639364
## 7508   6.1590861
## 7509   5.0138908
## 7510   4.7516812
## 7511   4.6244723
## 7512   4.2050221
## 7513   1.8911202
## 7514   3.0283394
## 7515   3.6859729
## 7516   5.9966749
## 7517   6.5285152
## 7518   7.6869275
## 7519   8.5269369
## 7520   7.3363551
## 7521   4.7423935
## 7522   4.7924181
## 7523   4.6088621
## 7524   4.4015461
## 7525   3.5255415
## 7526   5.4272924
## 7527   5.4225883
## 7528   5.6883309
## 7529   5.8689293
## 7530   6.2678988
## 7531   6.4467675
## 7532   4.9141581
## 7533   4.5569517
## 7534   3.4718491
## 7535   4.2658751
## 7536   6.9853515
## 7537   6.6852397
## 7538   6.6746385
## 7539   5.8340214
## 7540   5.9112305
## 7541   4.4364687
## 7542   4.4389324
## 7543   4.1029429
## 7544   4.3581339
## 7545   4.6729482
## 7546   4.3556345
## 7547   4.8623696
## 7548   4.0997539
## 7549   4.3670702
## 7550   4.7340203
## 7551   5.3067551
## 7552   5.1214592
## 7553   5.1242505
## 7554   3.9760945
## 7555   5.7746873
## 7556   2.7834014
## 7557   4.2383364
## 7558   4.9845939
## 7559   5.8898921
## 7560   4.5795008
## 7561   4.6603830
## 7562   3.3151549
## 7563   2.6075511
## 7564   3.2964446
## 7565   3.8286975
## 7566   5.0779358
## 7567   2.4797042
## 7568   4.3727748
## 7569   4.3980403
## 7570   5.5568954
## 7571   5.0669271
## 7572   4.9321684
## 7573   5.4764009
## 7574   6.3935318
## 7575   5.8552638
## 7576   3.8012787
## 7577   3.5887650
## 7578   3.9915290
## 7579   4.3846050
## 7580   5.6880280
## 7581   4.5025334
## 7582   3.9163495
## 7583   4.0823429
## 7584   3.5281879
## 7585   5.0328802
## 7586   3.4753498
## 7587   4.7004879
## 7588   3.9930144
## 7589   5.2695867
## 7590   5.8714033
## 7591   3.5092167
## 7592   4.2338370
## 7593   4.9842708
## 7594   4.0053107
## 7595   4.7522247
## 7596   5.5213037
## 7597   4.9787415
## 7598   3.9656404
## 7599   2.6836627
## 7600   3.4687443
## 7601   5.8939303
## 7602   5.5091423
## 7603   4.7104246
## 7604   3.6688278
## 7605   4.2302003
## 7606   3.9703521
## 7607   4.1281664
## 7608   3.3056507
## 7609   5.1199982
## 7610   6.2751778
## 7611   3.2236712
## 7612   3.8751196
## 7613   4.2117524
## 7614   5.6414258
## 7615   4.5376244
## 7616   5.1435240
## 7617   4.6517667
## 7618   5.7355981
## 7619   3.3133178
## 7620   2.7997503
## 7621   3.1936981
## 7622   4.4872343
## 7623   2.4147142
## 7624   2.7633296
## 7625   4.7434603
## 7626   2.9694104
## 7627   5.2761165
## 7628   3.1815378
## 7629   5.1939385
## 7630   2.9907254
## 7631   4.5978821
## 7632   4.1212793
## 7633   4.6492176
## 7634   4.3219070
## 7635   3.5518441
## 7636   2.6450466
## 7637   3.3926954
## 7638   2.7240339
## 7639   5.0036855
## 7640   4.7119735
## 7641   3.4040116
## 7642   4.4115185
## 7643   4.5263111
## 7644   6.0188578
## 7645   3.9220787
## 7646   3.9868477
## 7647   4.2835142
## 7648   2.7438069
## 7649   3.3791529
## 7650   2.9622405
## 7651   3.4845042
## 7652   3.5762770
## 7653   4.3050317
## 7654   3.8980296
## 7655   3.6469903
## 7656   5.0946412
## 7657   4.4515907
## 7658   3.8189268
## 7659   4.9117167
## 7660   4.1759894
## 7661   4.0305381
## 7662   2.2610627
## 7663   3.7835024
## 7664   2.9723324
## 7665   5.3600678
## 7666   4.6621465
## 7667   4.2370718
## 7668   2.3415239
## 7669   1.7496062
## 7670   1.6391822
## 7671   4.9972238
## 7672   6.0920235
## 7673   3.3043952
## 7674   6.0695739
## 7675   3.9046858
## 7676   5.9668088
## 7677   4.0976314
## 7678   3.9778593
## 7679   5.4478121
## 7680   3.9793901
## 7681   4.8789758
## 7682   3.3585359
## 7683   2.8690581
## 7684   4.5638299
## 7685   4.1753609
## 7686   4.9644349
## 7687   3.5004784
## 7688   3.7968972
## 7689   4.9263189
## 7690   4.1546663
## 7691   3.3910910
## 7692   2.3976525
## 7693   4.6866472
## 7694   4.7870448
## 7695   3.6537608
## 7696   5.0013633
## 7697   4.7401430
## 7698   4.7875911
## 7699   5.6010278
## 7700   5.3292613
## 7701   5.5906219
## 7702   5.8265622
## 7703   4.2861275
## 7704   3.9707602
## 7705   3.9942425
## 7706   4.0678019
## 7707   4.8407661
## 7708   5.0809565
## 7709   4.6629812
## 7710   5.8866070
## 7711   3.1376270
## 7712   3.6500965
## 7713   2.7495999
## 7714   4.0627246
## 7715   5.1360329
## 7716   4.6771516
## 7717   6.5326989
## 7718   4.8547509
## 7719   4.0054701
## 7720   4.3807892
## 7721   2.8013794
## 7722   5.4488452
## 7723   5.7165903
## 7724   5.0278951
## 7725   4.4913961
## 7726   4.7672101
## 7727   3.9421161
## 7728   3.3930870
## 7729   3.0575976
## 7730   4.5151932
## 7731   4.3725185
## 7732   5.3528271
## 7733   4.0595794
## 7734   3.1709866
## 7735   2.8083493
## 7736   3.5052592
## 7737   2.8204651
## 7738   5.2880658
## 7739   5.8519441
## 7740   6.6630622
## 7741   5.4976876
## 7742   5.9467860
## 7743   6.2989265
## 7744   4.8931111
## 7745   3.5533621
## 7746   3.6264825
## 7747   3.5253718
## 7748   3.2293616
## 7749   4.0187287
## 7750   3.6856993
## 7751   5.1951743
## 7752   5.0098188
## 7753   6.0308392
## 7754   4.8962473
## 7755   5.1244730
## 7756   4.7733782
## 7757   5.1082790
## 7758   4.4671195
## 7759   4.8552280
## 7760   4.5670826
## 7761   4.1831112
## 7762   4.6091231
## 7763   4.5405125
## 7764   5.1087888
## 7765   4.1632606
## 7766   4.5600098
## 7767   4.3357554
## 7768   4.6997716
## 7769   2.7828168
## 7770   4.0970867
## 7771   3.0742613
## 7772   3.9388519
## 7773   5.9944633
## 7774   3.3957109
## 7775   5.2320387
## 7776   4.7739787
## 7777   4.6599534
## 7778   2.6611112
## 7779   6.3231302
## 7780   4.2750337
## 7781   4.8609847
## 7782   5.7257383
## 7783   6.0921183
## 7784   3.9473792
## 7785   3.5011061
## 7786   4.4810892
## 7787   5.6559702
## 7788   3.4705933
## 7789   3.0385240
## 7790   2.8984807
## 7791   3.4571408
## 7792   3.5071702
## 7793   4.0598152
## 7794   2.6408562
## 7795   2.8890329
## 7796   3.1264002
## 7797   3.5395202
## 7798   2.7346557
## 7799   5.5349899
## 7800   2.4636114
## 7801   4.6936500
## 7802   4.1147691
## 7803   3.6420211
## 7804   4.2520116
## 7805   3.8330396
## 7806   6.4171551
## 7807   4.7921613
## 7808   6.4166091
## 7809   6.8838587
## 7810   5.1643304
## 7811   4.9705574
## 7812   2.1486679
## 7813   4.0772782
## 7814   2.5539354
## 7815   4.1891349
## 7816   6.3576637
## 7817   4.4638016
## 7818   4.0147987
## 7819   4.1417684
## 7820   3.7672620
## 7821   4.3869466
## 7822   5.7141399
## 7823   3.4215450
## 7824   2.6132824
## 7825   3.5874282
## 7826   1.8830595
## 7827   7.4750363
## 7828   3.1556459
## 7829   3.5784180
## 7830   2.4644234
## 7831   2.1314966
## 7832   3.1641201
## 7833   3.4012460
## 7834   3.7401751
## 7835   3.4813606
## 7836   3.5329579
## 7837   3.6604730
## 7838   4.2756023
## 7839   4.4587016
## 7840   4.9546298
## 7841   4.1283178
## 7842   4.8314201
## 7843   4.3972245
## 7844   5.1152192
## 7845   2.9685303
## 7846   3.9018955
## 7847   4.8819715
## 7848   3.9811234
## 7849   4.3539982
## 7850   4.4977100
## 7851   6.0619037
## 7852   2.7620026
## 7853   2.8393400
## 7854   4.2659333
## 7855   4.2299306
## 7856   5.1119189
## 7857   4.4897989
## 7858   3.0305651
## 7859   4.3633892
## 7860   3.7527699
## 7861   5.3064779
## 7862   4.6077918
## 7863   4.5159445
## 7864   4.6199159
## 7865   4.5016528
## 7866   4.6077474
## 7867   2.8234434
## 7868   5.2371196
## 7869   4.4307103
## 7870   5.4451322
## 7871   4.7588293
## 7872   5.6886074
## 7873   5.5357979
## 7874   5.5128197
## 7875   2.8075858
## 7876   7.1752654
## 7877   7.7046919
## 7878   4.1092829
## 7879   3.8763533
## 7880   4.1305321
## 7881   3.8996914
## 7882   5.2896255
## 7883   5.3358000
## 7884   5.3946015
## 7885   4.3097002
## 7886   4.5681074
## 7887   2.9326228
## 7888   6.8744564
## 7889   5.9681921
## 7890   5.2907669
## 7891   4.8473911
## 7892   2.4498329
## 7893   3.9399904
## 7894   3.3381327
## 7895   3.3012214
## 7896   4.2656180
## 7897   2.2058005
## 7898   2.9335436
## 7899   3.1021579
## 7900   3.6800677
## 7901   3.3979186
## 7902   3.7904042
## 7903   5.2514019
## 7904   5.3243551
## 7905   3.6743102
## 7906   4.3149050
## 7907   3.6373919
## 7908   5.5777360
## 7909   4.1433082
## 7910   6.9702212
## 7911   7.2435407
## 7912   6.5861646
## 7913   4.9854870
## 7914   3.3176491
## 7915   3.4843188
## 7916   3.2616840
## 7917   4.5201974
## 7918   3.7823326
## 7919   4.0233647
## 7920   2.2849368
## 7921   2.8706912
## 7922   5.4440832
## 7923   5.1208266
## 7924   4.8754498
## 7925   5.2974345
## 7926   5.6336667
## 7927   4.0558138
## 7928   1.3841034
## 7929   2.4430300
## 7930   4.8012721
## 7931   6.0062224
## 7932   4.6553188
## 7933   3.3901357
## 7934   5.9014840
## 7935   4.1109186
## 7936   4.9166905
## 7937   4.6079758
## 7938   5.2001161
## 7939   5.6564542
## 7940   4.4672708
## 7941   3.6002221
## 7942   6.8575811
## 7943   6.1215913
## 7944   5.3552579
## 7945   4.3233642
## 7946   3.9282570
## 7947   2.9079926
## 7948   3.1248002
## 7949   4.9315437
## 7950   3.4561284
## 7951   6.0189576
## 7952   5.0082882
## 7953   4.4594065
## 7954   5.9048943
## 7955   6.3014354
## 7956   6.0417084
## 7957   5.1273905
## 7958   4.4676768
## 7959   5.3811956
## 7960   3.9545525
## 7961   7.6312176
## 7962   3.8559941
## 7963   4.5059020
## 7964   3.9096250
## 7965   2.6419391
## 7966   2.9525940
## 7967   4.1142135
## 7968   3.8717567
## 7969   4.8630618
## 7970   4.8160775
## 7971   5.7489229
## 7972   3.8475362
## 7973   5.7720749
## 7974   4.5564752
## 7975   6.4329792
## 7976   6.1510970
## 7977   3.2466183
## 7978   5.8357680
## 7979   6.0429360
## 7980   2.4007774
## 7981   6.1991048
## 7982   6.4230488
## 7983   2.4604337
## 7984   3.4226644
## 7985   3.5370545
## 7986   3.4598531
## 7987   4.4221181
## 7988   3.6551063
## 7989   5.9611752
## 7990   2.8806764
## 7991   4.1510738
## 7992   4.6501529
## 7993   5.4727352
## 7994   3.6334903
## 7995   4.9296941
## 7996   4.6625166
## 7997   4.2783548
## 7998   5.3060251
## 7999   3.1925434
## 8000   5.4403564
## 8001   5.7925875
## 8002   6.0266499
## 8003   4.4843870
## 8004   4.7552550
## 8005   5.3076420
## 8006   5.0713699
## 8007   6.6218681
## 8008   5.1478578
## 8009   3.4186625
## 8010   3.8367511
## 8011   4.1361220
## 8012   4.7034590
## 8013   4.2655222
## 8014   5.6457219
## 8015   7.6209998
## 8016   3.4516868
## 8017   3.2415328
## 8018   5.5422176
## 8019   4.6890053
## 8020   4.5146370
## 8021   4.0780287
## 8022   4.5281106
## 8023   3.1188802
## 8024   3.6334290
## 8025   3.6311996
## 8026   4.0683032
## 8027   5.0685660
## 8028   3.9498172
## 8029   4.6213489
## 8030   3.6406202
## 8031   5.2244403
## 8032   5.5107775
## 8033   5.3989073
## 8034   4.3576523
## 8035   6.0385646
## 8036   5.0996726
## 8037   6.2365250
## 8038   4.4355651
## 8039   3.9918761
## 8040   5.8951859
## 8041   6.2243646
## 8042   6.0367011
## 8043   4.0175635
## 8044   3.6858151
## 8045   4.7664817
## 8046   4.2656713
## 8047   6.4347443
## 8048   5.8712810
## 8049   6.6625216
## 8050   4.7164124
## 8051   2.9441019
## 8052   5.4217128
## 8053   6.4326505
## 8054   7.0576254
## 8055   7.0385837
## 8056   4.2908782
## 8057   4.3089300
## 8058   4.5336918
## 8059   4.3713983
## 8060   3.5324842
## 8061   3.9094921
## 8062   5.3671601
## 8063   4.5169845
## 8064   3.1326415
## 8065   2.4927755
## 8066   2.7132453
## 8067   4.4979474
## 8068   4.9282546
## 8069   7.7638930
## 8070   5.4812829
## 8071   5.4741881
## 8072   5.7711822
## 8073   3.1387981
## 8074   2.9254650
## 8075   3.5516283
## 8076   2.5654977
## 8077   4.4304636
## 8078   3.5773209
## 8079   3.8595218
## 8080   3.1946209
## 8081   3.2295028
## 8082   3.2294068
## 8083   3.8178805
## 8084   4.6547139
## 8085   5.6373092
## 8086   5.8411710
## 8087   4.5894145
## 8088   3.5252987
## 8089   3.6162111
## 8090   3.7178021
## 8091   2.2272275
## 8092   3.7276748
## 8093   4.1216284
## 8094   5.2321210
## 8095   5.4574034
## 8096   3.4575312
## 8097   5.2674249
## 8098   4.0840385
## 8099   2.8301992
## 8100   5.0466543
## 8101   3.8973468
## 8102   3.9027389
## 8103   4.0092307
## 8104   3.8021670
## 8105   3.8099332
## 8106   3.5019085
## 8107   4.0737289
## 8108   4.7974031
## 8109   4.4739179
## 8110   3.1750473
## 8111   4.3860955
## 8112   1.7430049
## 8113   5.7602726
## 8114   4.4053914
## 8115   4.8568618
## 8116   4.2276998
## 8117   4.6862578
## 8118   3.4793385
## 8119   4.8888040
## 8120   1.8612068
## 8121   2.4740863
## 8122   5.4696538
## 8123   6.2334576
## 8124   3.1918878
## 8125   3.9645949
## 8126   5.1286909
## 8127   4.5936970
## 8128   2.8925554
## 8129   4.7817026
## 8130   5.3233567
## 8131   2.4083793
## 8132   4.0818778
## 8133   5.4985883
## 8134   4.3545976
## 8135   3.4522736
## 8136   4.6663884
## 8137   4.8257699
## 8138   5.2873274
## 8139   4.9681652
## 8140   4.6015757
## 8141   5.1081775
## 8142   5.0440453
## 8143   4.5387680
## 8144   4.4618910
## 8145   5.2624796
## 8146   5.4488338
## 8147   4.1035471
## 8148   4.5619267
## 8149   3.2674947
## 8150   4.5988560
## 8151   5.8394341
## 8152   5.5117403
## 8153   6.4038651
## 8154   7.2408779
## 8155   3.4537381
## 8156   6.3547851
## 8157   4.6231089
## 8158   4.2411609
## 8159   3.6991607
## 8160   3.7517967
## 8161   3.0955146
## 8162   3.2532047
## 8163   3.5037340
## 8164   3.2846851
## 8165   3.4058178
## 8166   2.6351694
## 8167   4.2811710
## 8168   4.6934515
## 8169   6.9240957
## 8170   5.6885740
## 8171   5.7471505
## 8172   5.8475164
## 8173   4.1556033
## 8174   5.3148453
## 8175   3.6328043
## 8176   3.7147082
## 8177   3.3303948
## 8178   4.4331799
## 8179   3.9355741
## 8180   3.8434510
## 8181   3.8464013
## 8182   4.8975500
## 8183   4.9971138
## 8184   4.9198481
## 8185   4.7121070
## 8186   4.1397212
## 8187   3.3861476
## 8188   4.2768078
## 8189   4.5633490
## 8190   6.1649675
## 8191   3.5403719
## 8192   4.5479805
## 8193   5.0427866
## 8194   3.9460906
## 8195   4.1185950
## 8196   3.8422569
## 8197   4.7137558
## 8198   4.0800136
## 8199   4.0049818
## 8200   3.5724958
## 8201   4.6668326
## 8202   4.8056532
## 8203   4.2298052
## 8204   4.1847222
## 8205   3.6163971
## 8206   6.1233326
## 8207   5.1425652
## 8208   3.8192077
## 8209   4.0187640
## 8210   7.4181263
## 8211   7.0168057
## 8212   6.3998884
## 8213   4.7724598
## 8214   4.3423261
## 8215   4.0866533
## 8216   2.7994809
## 8217   5.0616398
## 8218   3.7583294
## 8219   2.0415884
## 8220   4.0080105
## 8221   3.4711915
## 8222   5.5480929
## 8223   5.7037443
## 8224   4.2326782
## 8225   4.2419610
## 8226   4.7365699
## 8227   5.2241974
## 8228   6.8634467
## 8229   6.7130168
## 8230   4.4177963
## 8231   4.6381220
## 8232   3.3389141
## 8233   5.5758735
## 8234   3.5269930
## 8235   2.2954347
## 8236   1.9003384
## 8237   3.2367515
## 8238   4.6596890
## 8239   3.3337888
## 8240   3.0299604
## 8241   5.2083603
## 8242   3.9669367
## 8243   3.2650998
## 8244   3.8496698
## 8245   3.5454992
## 8246   3.5289556
## 8247   3.8862592
## 8248   3.4023714
## 8249   3.3710304
## 8250   3.3218028
## 8251   2.6848281
## 8252   6.2279621
## 8253   4.9669477
## 8254   5.1918670
## 8255   6.5267291
## 8256   7.0124876
## 8257   4.3491073
## 8258   2.3640938
## 8259   3.9125357
## 8260   4.6589928
## 8261   4.9022692
## 8262   4.8645739
## 8263   2.3134113
## 8264   3.7706577
## 8265   4.6437291
## 8266   3.8834596
## 8267   4.0097098
## 8268   3.3830391
## 8269   3.6607883
## 8270   4.0271437
## 8271   4.3020553
## 8272   4.9814984
## 8273   4.5646685
## 8274   6.1804836
## 8275   6.8324213
## 8276   4.9877958
## 8277   4.1226880
## 8278   4.4429277
## 8279   4.8020550
## 8280   6.1141893
## 8281   2.3822135
## 8282   4.5536174
## 8283   3.9255118
## 8284   2.1911364
## 8285   4.6142109
## 8286   3.9849618
## 8287   3.6233890
## 8288   4.7139196
## 8289   4.7605529
## 8290   4.4026103
## 8291   5.3759625
## 8292   4.2029940
## 8293   4.4107624
## 8294   5.0369322
## 8295   3.4314673
## 8296   3.5887155
## 8297   3.9346822
## 8298   5.9573289
## 8299   6.2892426
## 8300   5.1299078
## 8301   5.7598834
## 8302   3.5300431
## 8303   2.3281626
## 8304   6.7525377
## 8305   6.6753947
## 8306   6.8895012
## 8307   6.0201918
## 8308   3.2234649
## 8309   3.9722388
## 8310   4.7584896
## 8311   3.8399447
## 8312   3.6581484
## 8313   3.1926749
## 8314   3.3301259
## 8315   1.9099302
## 8316   6.5622022
## 8317   4.0450418
## 8318   2.8411367
## 8319   4.7574174
## 8320   4.3296777
## 8321   3.8995241
## 8322   4.2266189
## 8323   5.5964043
## 8324   5.7524636
## 8325   4.3655191
## 8326   5.1268753
## 8327   1.2300419
## 8328   1.8566027
## 8329   1.6129786
## 8330   5.1361060
## 8331   4.0319418
## 8332   4.0663709
## 8333   5.5114659
## 8334   5.1483398
## 8335   4.8593831
## 8336   4.3800231
## 8337   2.6345381
## 8338   6.0157576
## 8339   4.0305312
## 8340   4.0436678
## 8341   3.0257674
## 8342   4.3584337
## 8343   4.3787585
## 8344   3.2538170
## 8345   4.8788701
## 8346   4.8203023
## 8347   4.0550845
## 8348   3.9802922
## 8349   4.2940359
## 8350   4.9325372
## 8351   3.3603425
## 8352   5.5405912
## 8353   6.0161759
## 8354   4.6863692
## 8355   5.5834102
## 8356   5.0227440
## 8357   2.7601568
## 8358   3.7995034
## 8359   3.7462470
## 8360   4.2377919
## 8361   4.3563697
## 8362   5.4050350
## 8363   3.0187484
## 8364   3.4310369
## 8365   3.0963202
## 8366   3.3687677
## 8367   4.0066982
## 8368   3.5338303
## 8369   3.9950929
## 8370   5.4497744
## 8371   6.5797594
## 8372   4.6081120
## 8373   3.2901181
## 8374   3.2066054
## 8375   4.3498252
## 8376   2.9226816
## 8377   3.1221634
## 8378   2.5587848
## 8379   4.3331160
## 8380   4.4817244
## 8381   4.3935179
## 8382   4.4083163
## 8383   5.0302397
## 8384   5.0747730
## 8385   4.7300003
## 8386   3.9155085
## 8387   3.8979178
## 8388   4.7352240
## 8389   4.8510063
## 8390   5.4696745
## 8391   5.4980046
## 8392   5.5424367
## 8393   6.7970222
## 8394   6.6087300
## 8395   4.0114763
## 8396   4.9486747
## 8397   5.9762598
## 8398   3.3059708
## 8399   3.4860156
## 8400   3.9821519
## 8401   4.2300000
## 8402   5.0961758
## 8403   4.6442977
## 8404   4.5483005
## 8405   5.4413564
## 8406   7.1096785
## 8407   6.0169574
## 8408   2.3836388
## 8409   4.9681631
## 8410   7.2645459
## 8411   5.8602480
## 8412   4.9710095
## 8413   2.8462147
## 8414   5.1757061
## 8415   7.0550566
## 8416   6.2158348
## 8417   3.0437184
## 8418   3.2280708
## 8419   4.4958101
## 8420   4.4537882
## 8421   4.5023196
## 8422   0.7460817
## 8423   4.4554417
## 8424   4.4455370
## 8425   5.1955078
## 8426   4.3787595
## 8427   4.0290820
## 8428   5.8015275
## 8429   3.0784686
## 8430   4.9913585
## 8431   3.6349932
## 8432   4.2726376
## 8433   4.5400320
## 8434   3.9443930
## 8435   4.7939032
## 8436   4.3920112
## 8437   3.1220792
## 8438   2.8715419
## 8439   2.5376642
## 8440   3.4156303
## 8441   1.4978267
## 8442   2.0540142
## 8443   5.5200783
## 8444   2.9712668
## 8445   5.1308645
## 8446   4.5032191
## 8447   4.0540151
## 8448   4.1115505
## 8449   4.3723336
## 8450   3.6525081
## 8451   2.9059388
## 8452   3.6137138
## 8453   3.8956392
## 8454   5.1511445
## 8455   2.4142879
## 8456   3.9042313
## 8457   4.7457789
## 8458   4.7810897
## 8459   3.7634192
## 8460   3.0774337
## 8461   3.7744932
## 8462   5.4438090
## 8463   3.3071526
## 8464   4.1292258
## 8465   5.5614683
## 8466   3.3894271
## 8467   6.8381857
## 8468   4.5650356
## 8469   4.2767921
## 8470   4.4662284
## 8471   2.9855298
## 8472   3.0029612
## 8473   2.9247777
## 8474   3.5638478
## 8475   5.4501377
## 8476   6.9292756
## 8477   5.9064320
## 8478   4.8507811
## 8479   2.6673182
## 8480   4.1170909
## 8481   4.8190844
## 8482   3.9757295
## 8483   4.5913157
## 8484   5.6351892
## 8485   5.7549959
## 8486   5.4447975
## 8487   3.1971345
## 8488   3.0582029
## 8489   3.5509214
## 8490   3.7910245
## 8491   6.1233245
## 8492   5.2947617
## 8493   4.0504776
## 8494   3.2420564
## 8495   3.1392116
## 8496   4.8680769
## 8497   5.6886070
## 8498   5.4284339
## 8499   3.8841214
## 8500   3.9607806
## 8501   3.1812653
## 8502   4.2700267
## 8503   4.4193453
## 8504   3.7336782
## 8505   5.7859162
## 8506   6.0694655
## 8507   4.4655413
## 8508   4.4057796
## 8509   2.9793996
## 8510   1.8535492
## 8511   4.4571894
## 8512   4.9858613
## 8513   5.6370466
## 8514   5.0987673
## 8515   3.8972335
## 8516   4.7869089
## 8517   4.2753689
## 8518   4.7801466
## 8519   4.1247671
## 8520   6.0379937
## 8521   2.8768947
## 8522   4.1211614
## 8523   2.9962740
## 8524   6.3481048
## 8525   2.6990312
## 8526   5.0456433
## 8527   4.4375171
## 8528   3.9985821
## 8529   3.9447004
## 8530   3.5500755
## 8531   4.6042029
## 8532   4.3305917
## 8533   4.4123647
## 8534   5.0251028
## 8535   6.3745678
## 8536   6.5339150
## 8537   6.7511305
## 8538   1.9466140
## 8539   3.4330529
## 8540   5.0976732
## 8541   3.0083210
## 8542   5.9537543
## 8543   5.7353404
## 8544   6.2716397
## 8545   2.8441849
## 8546   4.7216981
## 8547   5.8978594
## 8548   4.5596155
## 8549   2.7567674
## 8550   3.7782704
## 8551   4.5983031
## 8552   2.2562314
## 8553   5.5355428
## 8554   5.1939893
## 8555   4.5190338
## 8556   4.5119760
## 8557   5.4320786
## 8558   4.9771249
## 8559   3.3122608
## 8560   4.0645801
## 8561   4.1301217
## 8562   2.5884092
## 8563   2.5840723
## 8564   7.1580995
## 8565   4.0656667
## 8566   3.1985630
## 8567   4.3180527
## 8568   5.6949067
## 8569   5.9828020
## 8570   2.8063857
## 8571   2.2332333
## 8572   2.3023693
## 8573   4.7812298
## 8574   3.7575615
## 8575   6.1926722
## 8576   6.1927082
## 8577   5.9755508
## 8578   6.9528030
## 8579   4.1720075
## 8580   5.8638261
## 8581   4.7809786
## 8582   5.4152301
## 8583   3.3337118
## 8584   3.4905521
## 8585   5.9711977
## 8586   3.4547341
## 8587   5.2842707
## 8588   6.0011351
## 8589   6.8062600
## 8590   6.5142371
## 8591   6.5466870
## 8592   6.7512133
## 8593   5.8963822
## 8594   3.9132358
## 8595   5.6143626
## 8596   5.2708255
## 8597   5.0527446
## 8598   4.7999030
## 8599   6.7419160
## 8600   4.1813134
## 8601   3.1028265
## 8602   3.7248112
## 8603   6.5015864
## 8604   6.7519108
## 8605   5.1368191
## 8606   4.5880767
## 8607   4.8002136
## 8608   4.8307581
## 8609   4.0871180
## 8610   4.3920224
## 8611   4.4189267
## 8612   4.3323345
## 8613   5.6310108
## 8614   4.2939467
## 8615   4.2851539
## 8616   4.2870084
## 8617   3.2144075
## 8618   3.9063252
## 8619   2.9262084
## 8620   5.1202480
## 8621   4.3444432
## 8622   4.1201594
## 8623   4.3273898
## 8624   4.2418062
## 8625   3.0326010
## 8626   3.8540160
## 8627   4.9765186
## 8628   4.2307542
## 8629   4.7606903
## 8630   6.2009724
## 8631   5.0700262
## 8632   5.4922930
## 8633   4.2018889
## 8634   4.0649994
## 8635   3.0922633
## 8636   6.4286233
## 8637   4.0943709
## 8638   5.2958085
## 8639   5.3675426
## 8640   3.1619276
## 8641   7.0123007
## 8642   5.9573208
## 8643   3.1619601
## 8644   4.3017151
## 8645   4.3500721
## 8646   6.5381618
## 8647   6.8287415
## 8648   7.7158051
## 8649   6.6156700
## 8650   7.0248611
## 8651   1.7765850
## 8652   4.2950012
## 8653   2.8460620
## 8654   4.0799370
## 8655   5.3767409
## 8656   3.0967544
## 8657   4.4728264
## 8658   2.4840073
## 8659   4.1769693
## 8660   3.5098424
## 8661   3.8560385
## 8662   3.7777463
## 8663   3.7542400
## 8664   4.7678746
## 8665   5.7404800
## 8666   2.6514858
## 8667   3.6229363
## 8668   5.3147294
## 8669   6.3932658
## 8670   4.5795634
## 8671   4.2952152
## 8672   4.0924942
## 8673   1.9609314
## 8674   1.4127076
## 8675   7.4402362
## 8676   4.6979637
## 8677   4.7262063
## 8678   3.9656341
## 8679   2.6239463
## 8680   2.3625764
## 8681   4.0435525
## 8682   4.2795260
## 8683   5.3755996
## 8684   2.8069600
## 8685   3.8068631
## 8686   3.4828910
## 8687   3.5900911
## 8688   3.9978372
## 8689   3.1034402
## 8690   2.8798286
## 8691   7.2191927
## 8692   6.4726721
## 8693   3.0788162
## 8694   3.1832987
## 8695   4.0742894
## 8696   3.2589829
## 8697   5.2455212
## 8698   4.1296694
## 8699   3.0905103
## 8700   2.9832569
## 8701   5.0413825
## 8702   5.2077235
## 8703   3.4832266
## 8704   4.0522938
## 8705   5.5500790
## 8706   5.4667166
## 8707   5.3635672
## 8708   4.2787055
## 8709   4.5462560
## 8710   4.0060279
## 8711   3.4166118
## 8712   3.4252837
## 8713   2.6802732
## 8714   5.9749280
## 8715   6.1607597
## 8716   5.0313745
## 8717   3.7329266
## 8718   3.3673276
## 8719   5.6795162
## 8720   4.4402956
## 8721   4.5167752
## 8722   3.4508122
## 8723   4.4388327
## 8724   3.7771804
## 8725   2.0668220
## 8726   2.5241493
## 8727   4.0384946
## 8728   4.8080641
## 8729   4.6909615
## 8730   5.8770731
## 8731   5.1939492
## 8732   4.4707577
## 8733   3.8823807
## 8734   4.4328589
## 8735   7.0708831
## 8736   4.8520549
## 8737   4.1782272
## 8738   3.6302580
## 8739   4.2535145
## 8740   3.2957497
## 8741   3.1441573
## 8742   2.6738975
## 8743   8.3346176
## 8744   7.0557281
## 8745   5.7762044
## 8746   5.7765969
## 8747   4.7017548
## 8748   6.7437236
## 8749   6.1962533
## 8750   5.1291661
## 8751   2.2893466
## 8752   2.9560931
## 8753   5.3023369
## 8754   4.1584811
## 8755   6.2803578
## 8756   5.3828285
## 8757   3.6328231
## 8758   3.9278805
## 8759   3.3203991
## 8760   4.0056270
## 8761   4.3583839
## 8762   4.7929178
## 8763   4.1950585
## 8764   4.1373842
## 8765   4.0633023
## 8766   3.8309696
## 8767   4.2575708
## 8768   3.9708961
## 8769   4.6148560
## 8770   3.6853063
## 8771   4.1385446
## 8772   2.5469147
## 8773   4.3046050
## 8774   4.5878383
## 8775   4.0917038
## 8776   4.3995174
## 8777   5.4394179
## 8778   5.5292839
## 8779   5.5544004
## 8780   4.7750716
## 8781   5.8193997
## 8782   4.5134226
## 8783   4.8235449
## 8784   3.3793304
## 8785   3.4421316
## 8786   4.8215070
## 8787   4.8162568
## 8788   4.2837632
## 8789   3.4796363
## 8790   4.7858100
## 8791   3.9455901
## 8792   4.1564257
## 8793   5.5056904
## 8794   4.9150610
## 8795   3.1065323
## 8796   2.9260403
## 8797   5.0032281
## 8798   1.3062247
## 8799   2.9132891
## 8800   4.7565373
## 8801   3.8836711
## 8802   3.8002077
## 8803   3.3754415
## 8804   4.2783468
## 8805   4.2861073
## 8806   4.7498900
## 8807   3.8830077
## 8808   4.1185719
## 8809   4.8701864
## 8810   3.4494167
## 8811   3.3528901
## 8812   4.1525183
## 8813   6.4294434
## 8814   4.5881244
## 8815   3.1033484
## 8816   2.3004275
## 8817   6.6284856
## 8818   4.7102711
## 8819   4.4023680
## 8820   2.6928674
## 8821   4.3244726
## 8822   5.0820550
## 8823   4.3763093
## 8824   2.7921155
## 8825   5.0943977
## 8826   3.4959928
## 8827   4.8542501
## 8828   3.7324245
## 8829   4.3491506
## 8830   4.2599905
## 8831   4.5367915
## 8832   6.3697273
## 8833   6.4397760
## 8834   5.9200761
## 8835   4.6823089
## 8836   3.7389731
## 8837   4.2393396
## 8838   4.4527772
## 8839   4.7777708
## 8840   5.6712699
## 8841   5.6346320
## 8842   2.2333498
## 8843   4.3938916
## 8844   3.1120035
## 8845   1.7384844
## 8846   5.0505078
## 8847   4.7518624
## 8848   5.9985019
## 8849   4.6750287
## 8850   5.7977188
## 8851   3.6729836
## 8852   4.5038259
## 8853   3.7413776
## 8854   4.4757044
## 8855   3.7609340
## 8856   3.7842428
## 8857   4.2442023
## 8858   5.1516998
## 8859   2.8889731
## 8860   3.8343910
## 8861   6.0225610
## 8862   6.2905301
## 8863   2.9130653
## 8864   6.1317071
## 8865   3.1981054
## 8866   3.8327365
## 8867   3.7827187
## 8868   4.6379120
## 8869   6.3749793
## 8870   3.9229446
## 8871   3.9877239
## 8872   3.2103837
## 8873   6.0692920
## 8874   6.5141716
## 8875   3.9274954
## 8876   4.5375761
## 8877   5.9266353
## 8878   3.9153655
## 8879   3.9782711
## 8880   5.6517205
## 8881   4.7220461
## 8882   3.7456723
## 8883   3.8090780
## 8884   6.1664597
## 8885   3.4987083
## 8886   5.2500524
## 8887   3.9471436
## 8888   3.8522857
## 8889   5.2810220
## 8890   4.3101752
## 8891   3.1144219
## 8892   3.6220543
## 8893   6.9615489
## 8894   6.6639042
## 8895   6.4611323
## 8896   3.6021123
## 8897   2.7632282
## 8898   2.8081322
## 8899   2.1444671
## 8900   6.1996319
## 8901   6.4794687
## 8902   5.5127791
## 8903   4.5344988
## 8904   4.5399371
## 8905   3.4205705
## 8906   3.9513359
## 8907   5.6655314
## 8908   5.6662384
## 8909   4.6190185
## 8910   6.2275022
## 8911   5.9240440
## 8912   2.5584297
## 8913   5.0429123
## 8914   3.8158522
## 8915   4.2850965
## 8916   5.5065822
## 8917   4.8034757
## 8918   4.9594329
## 8919   4.8771394
## 8920   3.3003092
## 8921   2.6107923
## 8922   3.8677781
## 8923   4.4334367
## 8924   4.0075390
## 8925   4.8234258
## 8926   4.1793804
## 8927   4.0808103
## 8928   4.5214907
## 8929   3.5701494
## 8930   3.1204536
## 8931   3.7245891
## 8932   2.8130641
## 8933   3.5517342
## 8934   3.9415629
## 8935   3.3745504
## 8936   4.7083695
## 8937   3.8172611
## 8938   6.0555935
## 8939   5.9158622
## 8940   1.6020070
## 8941   2.0508427
## 8942   2.5211241
## 8943   4.3716474
## 8944   5.0520366
## 8945   3.9568774
## 8946   3.2846702
## 8947   5.0368524
## 8948   5.3861099
## 8949   6.2052586
## 8950   5.2913688
## 8951   4.3146260
## 8952   5.7797932
## 8953   5.7809641
## 8954   5.5261875
## 8955   5.7399041
## 8956   4.9877341
## 8957   2.8049267
## 8958   2.3504845
## 8959   2.5128365
## 8960   1.6634757
## 8961   2.3093387
## 8962   2.9741082
## 8963   2.7908985
## 8964   3.0381486
## 8965   4.9486049
## 8966   6.0821288
## 8967   3.4233904
## 8968   2.9736538
## 8969   2.6405501
## 8970   3.5909205
## 8971   4.4992843
## 8972   2.6078676
## 8973   2.3009215
## 8974   3.3112538
## 8975   7.5472745
## 8976   5.4118942
## 8977   4.0380661
## 8978   3.8750776
## 8979   3.7643566
## 8980   5.1463831
## 8981   5.4262581
## 8982   2.7835752
## 8983   3.1713236
## 8984   3.1672116
## 8985   4.9781561
## 8986   4.7932817
## 8987   5.3935422
## 8988   3.0719257
## 8989   4.2305449
## 8990   3.5176386
## 8991   3.7271184
## 8992   1.9057168
## 8993   3.1717903
## 8994   3.9703852
## 8995   2.8846474
## 8996   3.7345480
## 8997   3.7630966
## 8998   3.5290688
## 8999   4.5994537
## 9000   4.1171712
## 9001   3.9429126
## 9002   5.1393727
## 9003   2.0693229
## 9004   6.1254430
## 9005   5.0179899
## 9006   3.9572759
## 9007   4.1943694
## 9008   3.2341988
## 9009   4.7139730
## 9010   2.9630778
## 9011   3.0206463
## 9012   4.4035791
## 9013   6.0054314
## 9014   4.7890411
## 9015   7.2912029
## 9016   5.8267109
## 9017   5.4685469
## 9018   4.9160728
## 9019   4.4368489
## 9020   4.1512257
## 9021   4.9312466
## 9022   5.3637833
## 9023   4.6507925
## 9024   3.2782410
## 9025   3.4226281
## 9026   5.6549089
## 9027   3.7483766
## 9028   4.6821388
## 9029   7.7826756
## 9030   6.7509426
## 9031   3.6815257
## 9032   5.4015162
## 9033   3.3239944
## 9034   6.5974019
## 9035   5.9513370
## 9036   6.0815678
## 9037   5.4763313
## 9038   2.6664071
## 9039   5.9992415
## 9040   3.6295759
## 9041   4.2794694
## 9042   5.4021467
## 9043   4.1294759
## 9044   3.9487351
## 9045   4.1445730
## 9046   5.1928116
## 9047   4.8161884
## 9048   4.8150518
## 9049   4.3671175
## 9050   3.1921480
## 9051   3.5700996
## 9052   4.6321668
## 9053   3.4785236
## 9054   5.5987711
## 9055   4.4900796
## 9056   4.7425591
## 9057   2.6072933
## 9058   3.6562444
## 9059   2.8553924
## 9060   3.2716784
## 9061   4.7079172
## 9062   5.5474796
## 9063   3.0413536
## 9064   7.2086476
## 9065   6.8171642
## 9066   3.6347980
## 9067   3.1844585
## 9068   7.8388538
## 9069   3.1499878
## 9070   3.5071578
## 9071   3.0898963
## 9072   5.5052133
## 9073   5.1962061
## 9074   4.1314052
## 9075   3.7875222
## 9076   4.2981502
## 9077   3.8037003
## 9078   4.2538234
## 9079   4.6316656
## 9080   5.2431948
## 9081   4.2593474
## 9082   6.5794208
## 9083   6.4781615
## 9084   4.8460390
## 9085   2.7495581
## 9086   4.5260107
## 9087   3.0849595
## 9088   3.7657114
## 9089   3.8922710
## 9090   4.5983786
## 9091   5.0828093
## 9092   5.4584866
## 9093   4.9479241
## 9094   5.6609034
## 9095   6.1013565
## 9096   3.0536324
## 9097   3.8394938
## 9098   4.5571941
## 9099   5.1996076
## 9100   4.7041871
## 9101   5.3470995
## 9102   2.7937232
## 9103   5.3569835
## 9104   5.7668640
## 9105   3.2485283
## 9106   4.5882692
## 9107   2.2776452
## 9108   2.8205649
## 9109   2.2233491
## 9110   3.0491515
## 9111   2.7937950
## 9112   3.8529797
## 9113   1.8932610
## 9114   1.6469759
## 9115   1.7961667
## 9116   4.4936511
## 9117   3.7605303
## 9118   1.8096245
## 9119   3.2364486
## 9120   2.7414702
## 9121   4.4976150
## 9122   3.8114185
## 9123   4.5657758
## 9124   6.7333372
## 9125   4.8122989
## 9126   5.2803623
## 9127   5.2533145
## 9128   3.8384180
## 9129   5.3847679
## 9130   3.0497262
## 9131   5.0655571
## 9132   4.2462464
## 9133   4.2331482
## 9134   4.4764181
## 9135   7.4774314
## 9136   4.3582222
## 9137   4.5998778
## 9138   3.6865719
## 9139   4.8805038
## 9140   4.4341644
## 9141   3.9905612
## 9142   4.7753087
## 9143   5.2241959
## 9144   4.0393271
## 9145   3.9837015
## 9146   2.3253531
## 9147   3.4174697
## 9148   5.8945792
## 9149   3.3202040
## 9150   2.3563207
## 9151   4.0226790
## 9152   3.0553674
## 9153   2.4538235
## 9154   2.4857640
## 9155   5.9900973
## 9156   5.0760267
## 9157   5.2400764
## 9158   4.8295811
## 9159   4.7843813
## 9160   3.3661240
## 9161   6.1312729
## 9162   3.7989270
## 9163   4.1307457
## 9164   4.9370477
## 9165   4.9715524
## 9166   4.2649775
## 9167   3.5576688
## 9168   3.5060328
## 9169   8.0054519
## 9170   5.9947959
## 9171   4.9374675
## 9172   1.9238779
## 9173   3.2913982
## 9174   4.9703885
## 9175   1.8019030
## 9176   4.6488408
## 9177   4.6539427
## 9178   3.8804153
## 9179   3.7543666
## 9180   6.8645557
## 9181   4.6267653
## 9182   3.7643376
## 9183   5.1814008
## 9184   5.0970013
## 9185   5.1194286
## 9186   4.2814197
## 9187   3.5022651
## 9188   5.5348421
## 9189   4.0977968
## 9190   2.5171293
## 9191   1.6910326
## 9192   2.0945250
## 9193   4.0873535
## 9194   1.9770116
## 9195   4.0110357
## 9196   4.8975026
## 9197   5.2023231
## 9198   4.9093315
## 9199   5.0945667
## 9200   2.9470083
## 9201   4.5365047
## 9202   4.0883607
## 9203   3.0414135
## 9204   3.4582975
## 9205   4.9660066
## 9206   4.1075260
## 9207   4.0300992
## 9208   5.2609812
## 9209   4.7212697
## 9210   4.4415168
## 9211   4.1616239
## 9212   3.1645789
## 9213   2.4825018
## 9214   3.3606737
## 9215   2.2317009
## 9216   2.9413337
## 9217   4.6267741
## 9218   4.5615542
## 9219   5.2243554
## 9220   6.2137323
## 9221   5.4098152
## 9222   5.4294931
## 9223   3.8057765
## 9224   4.0871192
## 9225   2.8634720
## 9226   3.3384973
## 9227   3.9305037
## 9228   3.8525120
## 9229   4.9205117
## 9230   4.9375823
## 9231   3.4984181
## 9232   3.6308314
## 9233   3.1986292
## 9234   2.8666098
## 9235   3.1581283
## 9236   2.7712659
## 9237   2.7261127
## 9238   3.4608133
## 9239   4.3103191
## 9240   4.2431325
## 9241   4.4329686
## 9242   4.4390817
## 9243   3.2892858
## 9244   5.4919681
## 9245   5.2962236
## 9246   4.0257838
## 9247   5.8064022
## 9248   1.9591302
## 9249   4.0217188
## 9250   4.5677382
## 9251   3.6837034
## 9252   3.5822097
## 9253   5.0579940
## 9254   4.2906468
## 9255   5.1208425
## 9256   2.9582350
## 9257   3.5109273
## 9258   4.4926096
## 9259   3.8088001
## 9260   2.1732069
## 9261   3.4368575
## 9262   4.0337492
## 9263   2.9642895
## 9264   4.7091687
## 9265   5.7967663
## 9266   3.6136148
## 9267   2.5178460
## 9268   4.3574524
## 9269   5.2946969
## 9270   6.1690291
## 9271   6.7366446
## 9272   3.5452151
## 9273   5.4195479
## 9274   5.1936052
## 9275   4.3788920
## 9276   4.7082422
## 9277   2.7238702
## 9278   5.5453239
## 9279   4.2102891
## 9280   5.6948208
## 9281   5.0435692
## 9282   7.8915032
## 9283   1.8712472
## 9284   1.5878255
## 9285   5.4219127
## 9286   5.8326431
## 9287   5.9509807
## 9288   2.6701203
## 9289   3.3513909
## 9290   4.9953359
## 9291   3.4447958
## 9292   4.0706996
## 9293   3.6248651
## 9294   3.3660378
## 9295   3.9347659
## 9296   2.6199018
## 9297   3.3040060
## 9298   3.1893816
## 9299   4.1199610
## 9300   3.7002018
## 9301   5.8770384
## 9302   2.8485405
## 9303   4.2803697
## 9304   5.3545333
## 9305   4.6708765
## 9306   4.3642474
## 9307   5.0644544
## 9308   6.4311316
## 9309   3.5407685
## 9310   4.0955243
## 9311   5.5555412
## 9312   4.3862990
## 9313   4.0198001
## 9314   4.7034700
## 9315   3.5406055
## 9316   3.9081075
## 9317   4.5417974
## 9318   2.7198817
## 9319   3.4115834
## 9320   3.9197848
## 9321   5.6944062
## 9322   5.9956161
## 9323   4.9419813
## 9324   1.4136271
## 9325   2.9031069
## 9326   3.4814405
## 9327   4.1361271
## 9328   5.3195958
## 9329   4.4483725
## 9330   3.1671630
## 9331   2.4687342
## 9332   5.3722962
## 9333   5.5681107
## 9334   2.7174951
## 9335   4.7829752
## 9336   4.8591136
## 9337   5.8572073
## 9338   5.7130852
## 9339   4.2337820
## 9340   5.6437127
## 9341   5.4764492
## 9342   3.6015363
## 9343   3.9005911
## 9344   2.7357654
## 9345   5.8986572
## 9346   5.3804233
## 9347   4.4915627
## 9348   3.7484324
## 9349   2.3984310
## 9350   2.8421607
## 9351   2.9914147
## 9352   3.3978191
## 9353   4.2274362
## 9354   4.6738339
## 9355   3.5359274
## 9356   5.0487073
## 9357   3.7185040
## 9358   4.3640349
## 9359   4.3185428
## 9360   4.1676552
## 9361   4.3336246
## 9362   3.2379577
## 9363   2.8849792
## 9364   5.0080039
## 9365   2.0013518
## 9366   3.4382419
## 9367   4.6922564
## 9368   5.7785226
## 9369   5.1232346
## 9370   3.3244511
## 9371   3.7225011
## 9372   4.7543667
## 9373   4.1195547
## 9374   2.9968340
## 9375   2.4018068
## 9376   5.3443286
## 9377   3.4182080
## 9378   6.2721478
## 9379   5.3979582
## 9380   2.6392150
## 9381   2.5399847
## 9382   3.4554252
## 9383   5.1072344
## 9384   5.1195209
## 9385   1.4741832
## 9386   3.1824603
## 9387   5.3616125
## 9388   4.5169110
## 9389   3.7459367
## 9390   5.2539446
## 9391   3.9858324
## 9392   3.0912319
## 9393   3.5722822
## 9394   3.5995892
## 9395   4.6919089
## 9396   4.0464411
## 9397   4.3118124
## 9398   4.7299950
## 9399   3.5663676
## 9400   4.5734553
## 9401   5.5759411
## 9402   5.9370578
## 9403   6.6277181
## 9404   2.8744080
## 9405   2.9088695
## 9406   5.5516142
## 9407   2.0168842
## 9408   3.8430152
## 9409   3.4517152
## 9410   4.5045367
## 9411   4.6598504
## 9412   5.4042378
## 9413   3.9230415
## 9414   3.9224934
## 9415   4.2036813
## 9416   4.7496884
## 9417   5.9616367
## 9418   4.3806265
## 9419   3.3841693
## 9420   6.2333254
## 9421   3.7055385
## 9422   3.2959204
## 9423   2.0706816
## 9424   5.0160023
## 9425   3.9390369
## 9426   3.3720076
## 9427   3.2490469
## 9428   6.4108458
## 9429   3.5641399
## 9430   5.7681944
## 9431   2.8477648
## 9432   4.0123128
## 9433   3.3709321
## 9434   3.4570914
## 9435   4.9209537
## 9436   3.5025410
## 9437   3.1917958
## 9438   5.0887606
## 9439   4.8526233
## 9440   3.9249514
## 9441   4.6851433
## 9442   5.1953269
## 9443   5.6725966
## 9444   3.0585977
## 9445   4.3987177
## 9446   5.6619166
## 9447   3.5376889
## 9448   3.5819660
## 9449   4.2891258
## 9450   5.4502012
## 9451   6.6696026
## 9452   1.8921725
## 9453   4.4145604
## 9454   4.5877797
## 9455   3.1804629
## 9456   4.3186474
## 9457   5.4267519
## 9458   3.1325062
## 9459   3.3434403
## 9460   3.8297387
## 9461   4.0591049
## 9462   3.6980159
## 9463   4.0614712
## 9464   3.7564185
## 9465   4.5846242
## 9466   4.8848019
## 9467   4.0535588
## 9468   3.8613137
## 9469   5.0521587
## 9470   4.2116466
## 9471   4.1596233
## 9472   5.2991776
## 9473   3.2810706
## 9474   3.3704228
## 9475   2.7725979
## 9476   4.0565849
## 9477   2.6350889
## 9478   4.4200480
## 9479   2.3272649
## 9480   4.0105169
## 9481   5.3215987
## 9482   4.3551394
## 9483   5.0099531
## 9484   5.1060225
## 9485   4.0068700
## 9486   4.9028272
## 9487   3.3061737
## 9488   3.9642241
## 9489   5.1157063
## 9490   3.4240304
## 9491   3.1232715
## 9492   3.4091413
## 9493   4.6793061
## 9494   5.4955818
## 9495   2.1734092
## 9496   2.5357760
## 9497   5.6447597
## 9498   4.9876636
## 9499   3.9253831
## 9500   4.3968421
## 9501   5.3223827
## 9502   5.5441754
## 9503   5.2726163
## 9504   4.9338242
## 9505   6.3994339
## 9506   2.1061601
## 9507   4.0773833
## 9508   5.4035169
## 9509   4.7603444
## 9510   1.3582163
## 9511   1.7834673
## 9512   2.7420811
## 9513   5.0047908
## 9514   4.8672764
## 9515   4.3538885
## 9516   4.4637491
## 9517   4.1576598
## 9518   4.0422920
## 9519   4.6361864
## 9520   4.2357194
## 9521   4.5870179
## 9522   3.6193484
## 9523   1.2046190
## 9524   6.1563572
## 9525   3.0152903
## 9526   3.4799919
## 9527   2.9377867
## 9528   3.4568538
## 9529   4.3234626
## 9530   2.0692356
## 9531   4.7929922
## 9532   4.8130364
## 9533   5.1710178
## 9534   4.2861977
## 9535   4.3534323
## 9536   4.2960123
## 9537   4.0974085
## 9538   4.1559705
## 9539   4.7524606
## 9540   3.5917378
## 9541   3.9747697
## 9542   5.4885926
## 9543   3.4193070
## 9544   4.5110506
## 9545   2.8852602
## 9546   4.2146221
## 9547   2.5915976
## 9548   3.6438742
## 9549   4.9909894
## 9550   4.9616278
## 9551   4.0486242
## 9552   3.0087043
## 9553   3.3901188
## 9554   3.6188803
## 9555   6.3225528
## 9556   4.4711108
## 9557   4.3436642
## 9558   2.9835806
## 9559   3.1858881
## 9560   6.3996567
## 9561   3.6833079
## 9562   3.3793892
## 9563   4.0887615
## 9564   5.0018906
## 9565   6.5200934
## 9566   3.6807273
## 9567   2.9279387
## 9568   5.2679634
## 9569   4.0298798
## 9570   2.8138475
## 9571   3.8236625
## 9572   6.3654311
## 9573   5.9141395
## 9574   4.7142226
## 9575   4.5384505
## 9576   4.1837079
## 9577   6.3718861
## 9578   3.8846950
## 9579   4.4511302
## 9580   3.8179302
## 9581   4.8904898
## 9582   5.8840536
## 9583   4.9257831
## 9584   3.2077362
## 9585   5.2462929
## 9586   4.8005276
## 9587   4.6663436
## 9588   2.7847239
## 9589   4.7313465
## 9590   5.1444123
## 9591   4.1333678
## 9592   5.5541044
## 9593   4.3986939
## 9594   5.0610857
## 9595   2.5206353
## 9596   2.6773908
## 9597   3.5876581
## 9598   3.3710741
## 9599   3.7624744
## 9600   1.7180200
## 9601   2.7032369
## 9602   2.9429758
## 9603   3.0928126
## 9604   1.4932380
## 9605   1.9538994
## 9606   2.7855742
## 9607   3.2361799
## 9608   4.5995910
## 9609   3.9818884
## 9610   3.1595720
## 9611   3.9189791
## 9612   3.8123972
## 9613   3.4648070
## 9614   6.1489035
## 9615   6.2136349
## 9616   2.3526848
## 9617   3.7784348
## 9618   3.8751414
## 9619   1.9257111
## 9620   3.5397425
## 9621   5.9108276
## 9622   3.4544278
## 9623   3.9008861
## 9624   3.6081382
## 9625   5.3017803
## 9626   3.4088291
## 9627   2.4885864
## 9628   6.3089014
## 9629   6.8662871
## 9630   4.0175182
## 9631   2.5947066
## 9632   4.8397485
## 9633   3.2243895
## 9634   3.9659367
## 9635   3.3292636
## 9636   2.6858435
## 9637   5.0036871
## 9638   4.6257949
## 9639   4.5222742
## 9640   5.2532782
## 9641   4.9515323
## 9642   2.5867036
## 9643   3.3265368
## 9644   4.0375324
## 9645   6.8231116
## 9646   5.6162705
## 9647   3.0659350
## 9648   3.2820277
## 9649   3.5003994
## 9650   5.6175178
## 9651   3.6690209
## 9652   3.2217100
## 9653   2.5278837
## 9654   3.1752130
## 9655   3.4909996
## 9656   3.0058499
## 9657   4.8224505
## 9658   4.9345093
## 9659   5.4832511
## 9660   6.3663826
## 9661   6.2313212
## 9662   4.4838423
## 9663   3.0496385
## 9664   5.5417794
## 9665   3.8220387
## 9666   4.3986155
## 9667   3.8697610
## 9668   3.2956968
## 9669   4.3830145
## 9670   5.0043944
## 9671   5.1689514
## 9672   7.2744893
## 9673   2.5044824
## 9674   5.1784471
## 9675   4.6622639
## 9676   4.5238535
## 9677   3.2793350
## 9678   3.2135378
## 9679   3.8916695
## 9680   3.0523643
## 9681   4.5078395
## 9682   6.2685293
## 9683   3.3398476
## 9684   4.5647912
## 9685   6.8571573
## 9686   6.5718868
## 9687   5.1250877
## 9688   4.1379869
## 9689   3.2713223
## 9690   4.5080344
## 9691   2.5330494
## 9692   2.9526738
## 9693   2.6939239
## 9694   2.3639975
## 9695   3.1589544
## 9696   5.5105125
## 9697   6.6450512
## 9698   3.9970661
## 9699   4.2905647
## 9700   2.7481578
## 9701   5.0593118
## 9702   5.2617741
## 9703   4.9685409
## 9704   5.5890163
## 9705   3.7320372
## 9706   5.6985592
## 9707   3.7350403
## 9708   4.5651702
## 9709   4.6801476
## 9710   4.9521204
## 9711   4.7150344
## 9712   4.9416801
## 9713   5.2686504
## 9714   6.2099255
## 9715   4.1519552
## 9716   4.1646234
## 9717   3.9017064
## 9718   4.6720739
## 9719   2.8154102
## 9720   5.5253594
## 9721   5.4129023
## 9722   5.2845119
## 9723   2.1913058
## 9724   3.3824926
## 9725   4.9679512
## 9726   4.5050408
## 9727   4.8158331
## 9728   4.8863195
## 9729   4.3732477
## 9730   4.4805738
## 9731   5.3349098
## 9732   4.6119565
## 9733   5.8786397
## 9734   5.0428342
## 9735   4.6746749
## 9736   4.9072706
## 9737   5.0156486
## 9738   4.0570425
## 9739   6.0375389
## 9740   5.9094498
## 9741   5.4114949
## 9742   5.4862925
## 9743   5.3257273
## 9744   4.9960270
## 9745   4.5049862
## 9746   4.2826505
## 9747   4.6720991
## 9748   4.3095147
## 9749   4.1153664
## 9750   4.9894836
## 9751   3.9727951
## 9752   3.3006510
## 9753   7.9146902
## 9754   6.3667728
## 9755   4.9509647
## 9756   3.1134033
## 9757   3.2895418
## 9758   3.4437925
## 9759   3.8657143
## 9760   4.0467594
## 9761   4.1465841
## 9762   3.7877456
## 9763   3.1038041
## 9764   4.9144244
## 9765   4.6229547
## 9766   5.2600985
## 9767   6.5293348
## 9768   4.7250274
## 9769   3.3936082
## 9770   4.5744315
## 9771   4.8258022
## 9772   5.7983293
## 9773   4.7240975
## 9774   4.3168751
## 9775   5.4257020
## 9776   4.1221621
## 9777   5.8608272
## 9778   6.1925276
## 9779   4.1310802
## 9780   4.4834616
## 9781   4.6289515
## 9782   3.7831781
## 9783   4.1988262
## 9784   3.9692313
## 9785   3.8518265
## 9786   2.8450726
## 9787   4.3146370
## 9788   4.9514954
## 9789   4.7514202
## 9790   3.7434897
## 9791   4.0144644
## 9792   4.3794892
## 9793   4.8034611
## 9794   4.1454937
## 9795   2.1192401
## 9796   3.8313715
## 9797   3.1940628
## 9798   5.3193423
## 9799   5.5966671
## 9800   4.7157334
## 9801   4.8324886
## 9802   1.6649926
## 9803   3.3483706
## 9804   3.6337534
## 9805   4.6082721
## 9806   4.6300939
## 9807   6.0402179
## 9808   4.8308754
## 9809   3.6006776
## 9810   4.1622173
## 9811   3.9363977
## 9812   3.7193628
## 9813   3.6172843
## 9814   3.1930954
## 9815   4.5696064
## 9816   3.2795486
## 9817   3.8777688
## 9818   4.0102517
## 9819   4.7380863
## 9820   5.9552597
## 9821   4.1760918
## 9822   4.1834661
## 9823   6.3376211
## 9824   3.9389252
## 9825   3.4037033
## 9826   4.1418866
## 9827   3.6155968
## 9828   4.0190368
## 9829   4.1217233
## 9830   3.8550858
## 9831   4.2988522
## 9832   4.4901118
## 9833   6.5485110
## 9834   3.1541779
## 9835   4.9622264
## 9836   2.4947252
## 9837   4.0473718
## 9838   4.8317685
## 9839   4.8389179
## 9840   2.5164651
## 9841   3.2339861
## 9842   2.6954185
## 9843   5.0124250
## 9844   3.0261916
## 9845   3.2876531
## 9846   3.5678815
## 9847   4.2821278
## 9848   4.0616543
## 9849   3.3809325
## 9850   4.7071517
## 9851   4.4872102
## 9852   3.7305590
## 9853   4.8977209
## 9854   4.6096583
## 9855   1.4525817
## 9856   0.9319578
## 9857   1.4957003
## 9858   3.2237532
## 9859   3.5164138
## 9860   3.6957899
## 9861   3.2683909
## 9862   4.0283223
## 9863   5.2873984
## 9864   5.2878184
## 9865   4.2365980
## 9866   3.8263508
## 9867   3.8754161
## 9868   2.2752727
## 9869   4.6508032
## 9870   4.4246179
## 9871   4.4898740
## 9872   5.9623032
## 9873   5.6626621
## 9874   5.5555883
## 9875   3.7789865
## 9876   3.5212971
## 9877   4.8910328
## 9878   5.2460885
## 9879   3.9423827
## 9880   4.2386455
## 9881   7.2044557
## 9882   6.1302560
## 9883   2.7533775
## 9884   2.8547100
## 9885   4.2306920
## 9886   4.8575463
## 9887   6.1905595
## 9888   4.0720139
## 9889   4.2750174
## 9890   4.7198667
## 9891   5.9299636
## 9892   5.3787648
## 9893   2.3405528
## 9894   5.1890792
## 9895   5.6155461
## 9896   2.2728908
## 9897   3.9634842
## 9898   3.7965550
## 9899   4.9628419
## 9900   5.1096578
## 9901   5.1134248
## 9902   4.6246674
## 9903   4.7425120
## 9904   3.9809363
## 9905   4.1373718
## 9906   4.6056328
## 9907   4.5604973
## 9908   4.2385634
## 9909   5.2476324
## 9910   4.2836511
## 9911   5.4189875
## 9912   3.4540313
## 9913   4.6551055
## 9914   3.0931112
## 9915   5.9446513
## 9916   6.2066740
## 9917   4.7866950
## 9918   4.3723359
## 9919   4.3678845
## 9920   6.0740774
## 9921   3.3527187
## 9922   3.4036783
## 9923   5.1470468
## 9924   3.0174425
## 9925   3.0753061
## 9926   5.2216321
## 9927   4.3645946
## 9928   3.2215853
## 9929   5.7621102
## 9930   4.6009100
## 9931   3.8718840
## 9932   3.2552105
## 9933   4.5523256
## 9934   4.7316468
## 9935   4.8398919
## 9936   3.9240405
## 9937   3.8778024
## 9938   3.8848458
## 9939   4.5687714
## 9940   5.0754470
## 9941   5.6506627
## 9942   4.8470522
## 9943   5.3502934
## 9944   6.6608787
## 9945   6.4674097
## 9946   1.4129981
## 9947   3.5780755
## 9948   3.9828622
## 9949   3.8455935
## 9950   2.8124334
## 9951   2.8683946
## 9952   3.1567783
## 9953   3.3601679
## 9954   2.9177489
## 9955   3.8953291
## 9956   2.8774683
## 9957   5.9107288
## 9958   3.1244413
## 9959   4.5863895
## 9960   4.5146468
## 9961   4.8750217
## 9962   5.9975868
## 9963   5.1251504
## 9964   4.3887009
## 9965   3.2268234
## 9966   5.5951877
## 9967   5.7396593
## 9968   5.8350616
## 9969   4.9911793
## 9970   4.6377594
## 9971   4.5766926
## 9972   3.4551658
## 9973   5.0705451
## 9974   4.6205784
## 9975   4.9280537
## 9976   4.0202767
## 9977   4.9261221
## 9978   4.3180474
## 9979   6.3722202
## 9980   5.1262734
## 9981   3.5565408
## 9982   3.4835555
## 9983   2.8322143
## 9984   2.5191655
## 9985   4.3213179
## 9986   4.5833673
## 9987   3.5337940
## 9988   4.3918198
## 9989   4.7908295
## 9990   4.5833625
## 9991   3.4914576
## 9992   4.4558272
## 9993   2.0445168
## 9994   1.9365025
## 9995   2.2867937
## 9996   4.3965916
## 9997   2.8125499
## 9998   4.1914991
## 9999   2.8647385
## 10000  4.0285916
## 10001  5.2794105
## 10002  5.5239610
## 10003  4.0400204
## 10004  3.5223196
## 10005  6.5517969
## 10006  3.5102375
## 10007  2.9087496
## 10008  4.0018547
## 10009  3.8168837
## 10010  4.9219827
## 10011  6.1712344
## 10012  2.6310984
## 10013  4.8013914
## 10014  4.7965110
## 10015  3.8972509
## 10016  4.5044836
## 10017  4.1030431
## 10018  3.6827168
## 10019  3.9285352
## 10020  2.1923098
## 10021  4.4723869
## 10022  3.0540631
## 10023  3.6011924
## 10024  4.1404556
## 10025  5.9823593
## 10026  5.3084948
## 10027  4.9269517
## 10028  4.7592268
## 10029  4.2375436
## 10030  4.1717302
## 10031  4.6020190
## 10032  4.8291349
## 10033  4.8653899
## 10034  6.3853577
## 10035  5.7327184
## 10036  4.3298291
## 10037  4.8399756
## 10038  4.4534912
## 10039  3.2926570
## 10040  3.8005212
## 10041  3.3572964
## 10042  6.6616604
## 10043  7.0886087
## 10044  2.9666057
## 10045  2.5507017
## 10046  1.4509824
## 10047  2.6921028
## 10048  7.8393067
## 10049  5.2117197
## 10050  6.5896093
## 10051  3.9525035
## 10052  1.8582097
## 10053  2.2771240
## 10054  2.0322451
## 10055  2.0027266
## 10056  4.0467238
## 10057  3.3452109
## 10058  4.8150122
## 10059  6.0327390
## 10060  4.2980369
## 10061  4.2956014
## 10062  4.8861409
## 10063  4.6841818
## 10064  4.7927573
## 10065  3.2214307
## 10066  3.6454158
## 10067  3.8775825
## 10068  6.2515126
## 10069  4.0495968
## 10070  5.5825063
## 10071  5.2455917
## 10072  5.4964524
## 10073  5.5345933
## 10074  6.1996485
## 10075  8.2604744
## 10076  1.5527128
## 10077  6.5053978
## 10078  3.5744556
## 10079  3.0052414
## 10080  4.0751359
## 10081  5.9611156
## 10082  1.8508137
## 10083  3.2417552
## 10084  5.0193529
## 10085  1.9311954
## 10086  4.2424642
## 10087  2.8954024
## 10088  6.2589934
## 10089  4.6119007
## 10090  4.4212521
## 10091  3.5227961
## 10092  4.5176055
## 10093  4.1343038
## 10094  5.0332580
## 10095  3.9207041
## 10096  4.8405906
## 10097  3.1204047
## 10098  5.7679408
## 10099  5.1407380
## 10100  4.8217090
## 10101  3.3441010
## 10102  5.2177185
## 10103  2.6569944
## 10104  3.7939616
## 10105  3.7195431
## 10106  6.2831555
## 10107  4.4205394
## 10108  3.9276027
## 10109  3.0650966
## 10110  4.5563122
## 10111  4.4962769
## 10112  5.5146488
## 10113  4.4462670
## 10114  5.0666340
## 10115  5.7617728
## 10116  5.5080522
## 10117  3.9902622
## 10118  6.4297537
## 10119  3.6686990
## 10120  4.7100641
## 10121  5.2126519
## 10122  5.5248031
## 10123  2.6387744
## 10124  4.2513213
## 10125  4.5262016
## 10126  5.5551798
## 10127  3.2432590
## 10128  3.2383084
## 10129  2.9573191
## 10130  3.2505063
## 10131  5.3915088
## 10132  5.1881006
## 10133  2.9035902
## 10134  3.3811832
## 10135  3.2289573
## 10136  3.2881034
## 10137  3.9643383
## 10138  3.1943520
## 10139  2.8177888
## 10140  6.5698499
## 10141  3.4031685
## 10142  3.4027639
## 10143  5.3835397
## 10144  4.6875169
## 10145  4.9767141
## 10146  4.6604771
## 10147  4.0608365
## 10148  4.9712724
## 10149  3.5169691
## 10150  2.9122535
## 10151  2.6601223
## 10152  3.0169357
## 10153  3.9750560
## 10154  3.7998509
## 10155  3.9012337
## 10156  4.3186509
## 10157  4.7682525
## 10158  3.4668563
## 10159  3.6037776
## 10160  5.5627634
## 10161  5.7236242
## 10162  3.6319785
## 10163  2.6271841
## 10164  4.5430359
## 10165  3.9493012
## 10166  4.9358042
## 10167  4.2895669
## 10168  4.2757913
## 10169  4.4402047
## 10170  4.2745008
## 10171  5.2097258
## 10172  3.4761218
## 10173  3.6750188
## 10174  3.5423033
## 10175  3.2360749
## 10176  5.2736880
## 10177  4.4660674
## 10178  3.4459412
## 10179  2.6419791
## 10180  3.2845126
## 10181  7.2101194
## 10182  5.4607039
## 10183  5.1662412
## 10184  4.6347405
## 10185  3.3119137
## 10186  2.9083697
## 10187  3.8959988
## 10188  4.3072069
## 10189  2.3098657
## 10190  2.0403244
## 10191  3.4579920
## 10192  5.8757919
## 10193  2.9071178
## 10194  1.8179115
## 10195  2.1044152
## 10196  2.4135405
## 10197  5.7329374
## 10198  4.2581978
## 10199  3.7772377
## 10200  4.3228970
## 10201  3.7211620
## 10202  5.9432934
## 10203  6.1680491
## 10204  3.7922144
## 10205  3.8173060
## 10206  3.3992837
## 10207  5.0222677
## 10208  5.8015518
## 10209  5.8893403
## 10210  5.7821030
## 10211  4.8658750
## 10212  3.7805242
## 10213  3.3092003
## 10214  3.5946634
## 10215  4.8123155
## 10216  7.1002716
## 10217  5.3384204
## 10218  2.6733983
## 10219  2.7260680
## 10220  4.5401989
## 10221  4.1330873
## 10222  5.5815940
## 10223  4.2963787
## 10224  2.3752854
## 10225  3.6381048
## 10226  5.7347219
## 10227  4.7847493
## 10228  6.5735014
## 10229  5.8136636
## 10230  2.8172418
## 10231  5.0606555
## 10232  3.1111785
## 10233  5.3597721
## 10234  4.2929001
## 10235  3.2166648
## 10236  4.0674109
## 10237  5.2315256
## 10238  4.1682691
## 10239  3.1131305
## 10240  4.9683793
## 10241  4.4118093
## 10242  4.5129205
## 10243  5.1649614
## 10244  4.2005015
## 10245  2.6620022
## 10246  2.7072163
## 10247  3.9207918
## 10248  3.7879028
## 10249  5.2475959
## 10250  5.3369531
## 10251  4.1112967
## 10252  4.6111149
## 10253  4.4815968
## 10254  3.5857645
## 10255  3.6007944
## 10256  4.8770466
## 10257  5.1008748
## 10258  3.2264059
## 10259  4.5996084
## 10260  2.8441214
## 10261  3.8004806
## 10262  4.2502940
## 10263  3.7455796
## 10264  3.6863085
## 10265  3.7343499
## 10266  3.9371803
## 10267  3.9196217
## 10268  4.3144525
## 10269  4.8607287
## 10270  2.7937822
## 10271  3.6019656
## 10272  4.2878777
## 10273  4.5202859
## 10274  5.4246192
## 10275  5.2347541
## 10276  3.8706874
## 10277  6.2454944
## 10278  4.4718106
## 10279  2.6333727
## 10280  2.9210797
## 10281  5.6022447
## 10282  4.4624076
## 10283  4.6440839
## 10284  4.0219139
## 10285  3.4263738
## 10286  3.7126439
## 10287  5.5489790
## 10288  2.6591875
## 10289  4.1809802
## 10290  5.8635427
## 10291  4.4633771
## 10292  4.5709481
## 10293  4.6259232
## 10294  4.3734515
## 10295  4.5350452
## 10296  3.6961190
## 10297  4.5274452
## 10298  3.9083814
## 10299  4.3834087
## 10300  5.0397631
## 10301  3.4981262
## 10302  4.0490346
## 10303  5.2437558
## 10304  3.8036922
## 10305  4.2102210
## 10306  4.7997877
## 10307  3.8885931
## 10308  2.9168532
## 10309  4.6684755
## 10310  3.3428216
## 10311  3.5033671
## 10312  4.2078278
## 10313  4.1830849
## 10314  5.5687158
## 10315  4.0257481
## 10316  3.8656586
## 10317  4.7169679
## 10318  4.4320220
## 10319  2.1413163
## 10320  5.4238775
## 10321  4.2952803
## 10322  3.6659302
## 10323  3.8402692
## 10324  2.5169963
## 10325  3.1648922
## 10326  5.8345979
## 10327  5.0121572
## 10328  5.3625877
## 10329  3.8496994
## 10330  4.0579577
## 10331  4.4287339
## 10332  2.9953335
## 10333  3.5237833
## 10334  4.3216971
## 10335  3.7487849
## 10336  4.0443651
## 10337  5.7018863
## 10338  5.7985148
## 10339  5.5020556
## 10340  4.8427748
## 10341  4.2072378
## 10342  3.1261986
## 10343  4.9644567
## 10344  6.8328894
## 10345  6.1029917
## 10346  4.6788593
## 10347  5.5865108
## 10348  4.3567796
## 10349  4.2255478
## 10350  4.8419852
## 10351  3.3717595
## 10352  3.2371281
## 10353  3.2346603
## 10354  3.0278468
## 10355  3.8670096
## 10356  3.2731182
## 10357  5.8052558
## 10358  4.1014336
## 10359  5.5750091
## 10360  7.1189591
## 10361  4.1530132
## 10362  2.6933989
## 10363  2.4585479
## 10364  4.6420510
## 10365  5.0087538
## 10366  6.4154329
## 10367  6.0871034
## 10368  5.1467637
## 10369  4.2876705
## 10370  3.6776645
## 10371  2.4493615
## 10372  3.0566277
## 10373  3.2922663
## 10374  1.9881979
## 10375  3.9465123
## 10376  5.5098676
## 10377  5.7226595
## 10378  4.1424502
## 10379  3.9493384
## 10380  3.3866564
## 10381  3.6728780
## 10382  5.4721963
## 10383  4.3741883
## 10384  3.3399910
## 10385  2.5119870
## 10386  4.3503990
## 10387  4.5513850
## 10388  4.3342066
## 10389  3.9520546
## 10390  4.8856917
## 10391  5.1624607
## 10392  4.2653893
## 10393  3.6898127
## 10394  5.8041250
## 10395  3.1013901
## 10396  5.0072113
## 10397  3.1648277
## 10398  3.4474420
## 10399  4.3620015
## 10400  3.2986589
## 10401  1.1804166
## 10402  1.8532425
## 10403  3.8056964
## 10404  6.1111839
## 10405  4.5313688
## 10406  4.9002468
## 10407  6.1581866
## 10408  4.6924472
## 10409  3.5098095
## 10410  3.3618610
## 10411  2.3837459
## 10412  3.1909702
## 10413  5.0681202
## 10414  3.5754499
## 10415  4.6330657
## 10416  3.2508457
## 10417  5.1607278
## 10418  3.0705802
## 10419  4.5173237
## 10420  4.0122540
## 10421  3.1550470
## 10422  3.4732671
## 10423  5.8140299
## 10424  5.8550968
## 10425  3.1667610
## 10426  3.7749386
## 10427  2.9737899
## 10428  5.5424513
## 10429  6.7743506
## 10430  6.9019850
## 10431  4.1766281
## 10432  3.4732445
## 10433  3.1691396
## 10434  4.0725003
## 10435  3.3467505
## 10436  3.4286598
## 10437  4.2664042
## 10438  5.8048250
## 10439  3.0150136
## 10440  4.2015564
## 10441  3.5772454
## 10442  3.1757429
## 10443  3.0359425
## 10444  3.4742192
## 10445  3.6233619
## 10446  5.3286052
## 10447  5.3330490
## 10448  4.6133835
## 10449  5.0613918
## 10450  4.7807675
## 10451  5.7585116
## 10452  3.3179139
## 10453  4.5752520
## 10454  5.4046759
## 10455  5.2815054
## 10456  4.3490519
## 10457  4.1184267
## 10458  3.4773342
## 10459  4.8063876
## 10460  3.5526330
## 10461  4.6258325
## 10462  6.0145195
## 10463  5.7643679
## 10464  3.9662527
## 10465  3.1297691
## 10466  3.1650980
## 10467  3.9813994
## 10468  2.2191511
## 10469  2.3064995
## 10470  3.9347272
## 10471  4.3039972
## 10472  4.7969710
## 10473  4.4744908
## 10474  4.0698916
## 10475  4.3065424
## 10476  4.9792994
## 10477  4.0767003
## 10478  4.1812457
## 10479  4.2961897
## 10480  5.2731132
## 10481  3.5694848
## 10482  2.6410394
## 10483  2.7843141
## 10484  4.6226484
## 10485  7.2893355
## 10486  2.8964576
## 10487  3.1634404
## 10488  6.2332408
## 10489  5.9917702
## 10490  6.2845607
## 10491  3.3509547
## 10492  3.8510483
## 10493  2.7321686
## 10494  1.5263961
## 10495  6.1581437
## 10496  4.1392224
## 10497  3.3534092
## 10498  4.3544717
## 10499  4.6649043
## 10500  5.2490619
## 10501  4.8221812
## 10502  3.1572354
## 10503  3.8263648
## 10504  3.1197117
## 10505  4.1739311
## 10506  4.5086963
## 10507  3.9591647
## 10508  4.7823255
## 10509  4.0135274
## 10510  2.1045660
## 10511  3.8395257
## 10512  4.5326836
## 10513  2.7489274
## 10514  2.4376154
## 10515  3.7356956
## 10516  3.6692532
## 10517  3.8905592
## 10518  5.6815557
## 10519  5.2738342
## 10520  4.1012533
## 10521  5.8983903
## 10522  4.2890652
## 10523  7.0196226
## 10524  7.0745558
## 10525  4.9931447
## 10526  5.5470726
## 10527  5.8944042
## 10528  6.7466685
## 10529  5.5589789
## 10530  4.6154225
## 10531  4.3551035
## 10532  4.7024141
## 10533  5.0111120
## 10534  4.9602937
## 10535  4.2670554
## 10536  5.3584758
## 10537  4.3317461
## 10538  4.3189513
## 10539  3.6836124
## 10540  5.1372977
## 10541  5.7178866
## 10542  6.9551984
## 10543  6.3521907
## 10544  2.1009674
## 10545  5.6216360
## 10546  5.1970985
## 10547  6.0238614
## 10548  3.5851241
## 10549  5.0850910
## 10550  3.2860502
## 10551  3.9781829
## 10552  3.2781213
## 10553  5.2550116
## 10554  3.7595354
## 10555  4.9632503
## 10556  3.2892690
## 10557  3.8706360
## 10558  3.5648815
## 10559  3.6350387
## 10560  4.4391163
## 10561  3.4040859
## 10562  5.0555412
## 10563  5.9480673
## 10564  3.4566355
## 10565  4.4812524
## 10566  3.4078600
## 10567  3.9129921
## 10568  3.2980020
## 10569  6.3882140
## 10570  5.0184162
## 10571  3.5638703
## 10572  2.8168490
## 10573  3.9600790
## 10574  3.2729714
## 10575  4.3597286
## 10576  4.2423909
## 10577  5.0781743
## 10578  4.3094514
## 10579  4.3873318
## 10580  6.6808018
## 10581  5.5399698
## 10582  5.3110271
## 10583  5.7683219
## 10584  6.4826272
## 10585  6.8121504
## 10586  6.4051052
## 10587  6.8291214
## 10588  6.5543394
## 10589  6.4168727
## 10590  6.3364531
## 10591  6.9028806
## 10592  4.3906219
## 10593  4.8932542
## 10594  5.3938772
## 10595  5.3267918
## 10596  6.6527804
## 10597  5.7008358
## 10598  3.3087940
## 10599  5.2747212
## 10600  3.0994954
## 10601  4.1770074
## 10602  4.6400312
## 10603  4.0992161
## 10604  3.7315131
## 10605  3.6800295
## 10606  4.7285917
## 10607  4.2504610
## 10608  4.0123398
## 10609  4.0824166
## 10610  4.7184937
## 10611  3.9224696
## 10612  4.7614774
## 10613  4.1396331
## 10614  5.3987990
## 10615  4.0428523
## 10616  3.6864752
## 10617  5.8686798
## 10618  3.5827975
## 10619  4.3553785
## 10620  4.1121765
## 10621  2.5529480
## 10622  4.8972306
## 10623  5.5804318
## 10624  4.1619262
## 10625  3.0508042
## 10626  4.4205394
## 10627  3.8711613
## 10628  4.1543920
## 10629  5.2338691
## 10630  3.4517942
## 10631  4.8688731
## 10632  4.5766028
## 10633  4.4006785
## 10634  6.2981079
## 10635  5.8939045
## 10636  2.9099291
## 10637  7.2371247
## 10638  5.4612334
## 10639  2.0404936
## 10640  5.3250749
## 10641  7.9138399
## 10642  4.5441628
## 10643  5.9791363
## 10644  7.2536940
## 10645  3.9780142
## 10646  4.0701655
## 10647  4.3127800
## 10648  3.7682799
## 10649  3.8812275
## 10650  3.8898723
## 10651  3.6277646
## 10652  4.1839995
## 10653  3.5984343
## 10654  4.9716932
## 10655  4.9108385
## 10656  6.5156788
## 10657  4.4881278
## 10658  5.4739608
## 10659  4.7269712
## 10660  6.0168823
## 10661  2.8335243
## 10662  5.1311095
## 10663  3.0499963
## 10664  4.3413207
## 10665  4.5105944
## 10666  3.6546775
## 10667  3.6672521
## 10668  2.7702650
## 10669  3.5989546
## 10670  3.0991146
## 10671  2.0005001
## 10672  5.2224329
## 10673  4.5990473
## 10674  3.2986226
## 10675  4.2454816
## 10676  2.9981039
## 10677  3.5847164
## 10678  3.5457638
## 10679  5.2834163
## 10680  4.5234469
## 10681  4.7305950
## 10682  2.3342970
## 10683  5.1637077
## 10684  3.9490519
## 10685  3.7276275
## 10686  2.3534748
## 10687  3.9857196
## 10688  6.4830704
## 10689  4.9109912
## 10690  3.5102842
## 10691  4.7162617
## 10692  4.9110869
## 10693  3.7495647
## 10694  3.0734423
## 10695  4.2817457
## 10696  7.3633582
## 10697  3.8340001
## 10698  4.2071921
## 10699  5.6820125
## 10700  5.3519869
## 10701  5.8896005
## 10702  5.1643365
## 10703  4.5509995
## 10704  4.4531534
## 10705  5.7470951
## 10706  3.1995063
## 10707  5.2537743
## 10708  2.8783625
## 10709  5.2704810
## 10710  3.7449542
## 10711  4.6227110
## 10712  4.4476862
## 10713  3.4630512
## 10714  1.1586871
## 10715  5.6593578
## 10716  5.8506349
## 10717  5.1674590
## 10718  4.3882191
## 10719  5.3560210
## 10720  4.8066193
## 10721  5.8871799
## 10722  3.9971296
## 10723  3.0032183
## 10724  6.1398076
## 10725  6.6948616
## 10726  3.7379679
## 10727  3.7621511
## 10728  2.5800882
## 10729  3.2487437
## 10730  3.0608330
## 10731  2.5132459
## 10732  5.6057952
## 10733  3.2220790
## 10734  4.5847095
## 10735  4.4030724
## 10736  4.7657078
## 10737  2.5344714
## 10738  3.2871445
## 10739  2.9854540
## 10740  5.0116124
## 10741  5.4028246
## 10742  5.5913495
## 10743  3.0207818
## 10744  3.4477947
## 10745  4.8699313
## 10746  3.7992530
## 10747  3.4638820
## 10748  5.3839478
## 10749  6.1667658
## 10750  4.0415305
## 10751  3.3472961
## 10752  3.8721718
## 10753  3.7189243
## 10754  3.9653017
## 10755  3.8883833
## 10756  5.5498740
## 10757  4.6356982
## 10758  3.5674391
## 10759  3.2749715
## 10760  5.1522156
## 10761  4.9426921
## 10762  4.4765642
## 10763  3.4263670
## 10764  3.8380215
## 10765  6.1430301
## 10766  3.7879265
## 10767  3.0380334
## 10768  2.1139954
## 10769  6.6547616
## 10770  5.9633286
## 10771  4.3492782
## 10772  3.9069628
## 10773  5.7954426
## 10774  6.5727101
## 10775  6.3104623
## 10776  2.7538995
## 10777  5.7538375
## 10778  3.7537824
## 10779  5.7846672
## 10780  4.7753345
## 10781  2.9526244
## 10782  5.0990897
## 10783  2.4040197
## 10784  6.5330894
## 10785  5.1696106
## 10786  6.0381437
## 10787  3.5544192
## 10788  4.9509179
## 10789  4.5191395
## 10790  5.5819796
## 10791  4.8123886
## 10792  3.7814164
## 10793  4.1311225
## 10794  4.9470111
## 10795  6.1318215
## 10796  3.5556333
## 10797  3.6977998
## 10798  3.0191202
## 10799  3.9951890
## 10800  3.8369726
## 10801  2.8880128
## 10802  5.0761949
## 10803  3.6016801
## 10804  5.0773266
## 10805  3.5488556
## 10806  5.1247245
## 10807  6.3446356
## 10808  5.5280858
## 10809  5.5322287
## 10810  4.8040133
## 10811  4.1303307
## 10812  2.2611658
## 10813  2.8029068
## 10814  3.0933000
## 10815  4.1193696
## 10816  4.7828353
## 10817  3.2395510
## 10818  3.5070714
## 10819  5.2542221
## 10820  6.4108949
## 10821  5.7170023
## 10822  3.9360568
## 10823  5.3291622
## 10824  5.2861288
## 10825  3.0763273
## 10826  3.5566084
## 10827  3.6640248
## 10828  7.3414481
## 10829  5.0398407
## 10830  2.6603200
## 10831  5.7554930
## 10832  5.1807620
## 10833  4.3930388
## 10834  2.3356323
## 10835  3.9762695
## 10836  4.8313529
## 10837  5.3101305
## 10838  4.3101154
## 10839  3.3739731
## 10840  3.6642406
## 10841  4.3434742
## 10842  4.5660475
## 10843  2.9762939
## 10844  5.0955611
## 10845  3.6273400
## 10846  2.1432030
## 10847  2.5768802
## 10848  2.4009772
## 10849  4.0946080
## 10850  5.2243523
## 10851  5.0918016
## 10852  5.0832503
## 10853  5.1485752
## 10854  5.1135166
## 10855  6.9622572
## 10856  6.1251345
## 10857  4.9725064
## 10858  5.2185394
## 10859  3.4311635
## 10860  3.0351878
## 10861  2.1709432
## 10862  6.2980916
## 10863  5.1940956
## 10864  5.2478086
## 10865  4.0523772
## 10866  3.7841477
## 10867  4.6187669
## 10868  2.2155364
## 10869  5.4138336
## 10870  4.0595180
## 10871  5.9535257
## 10872  3.6941730
## 10873  4.0378066
## 10874  5.2612713
## 10875  4.7566976
## 10876  3.6272330
## 10877  5.6054644
## 10878  4.8384353
## 10879  3.5655263
## 10880  4.0997652
## 10881  4.3126663
## 10882  4.0782165
## 10883  3.3591736
## 10884  5.1267888
## 10885  5.9624031
## 10886  4.2297682
## 10887  4.0062260
## 10888  4.2346331
## 10889  3.6904156
## 10890  6.2346456
## 10891  5.7932209
## 10892  7.0339107
## 10893  3.1016425
## 10894  3.2566987
## 10895  6.5565057
## 10896  4.7614824
## 10897  3.5900893
## 10898  5.4060139
## 10899  4.0501977
## 10900  5.3782233
## 10901  5.5258473
## 10902  4.4804113
## 10903  6.8357080
## 10904  6.9190855
## 10905  5.5701019
## 10906  5.9543246
## 10907  4.3127643
## 10908  5.8951575
## 10909  3.7186975
## 10910  5.3508951
## 10911  5.1092015
## 10912  2.6467894
## 10913  5.2951453
## 10914  5.4477750
## 10915  4.7676002
## 10916  4.6162961
## 10917  5.3260643
## 10918  4.3013864
## 10919  3.6592885
## 10920  0.4483933
## 10921  2.3760225
## 10922  2.5573288
## 10923  2.2329614
## 10924  6.1525160
## 10925  7.7482697
## 10926  6.5238481
## 10927  2.4156596
## 10928  2.6933239
## 10929  4.7976633
## 10930  5.5882445
## 10931  1.5394803
## 10932  3.0631440
## 10933  4.3003301
## 10934  3.3179035
## 10935  5.0123790
## 10936  4.9872742
## 10937  4.4281969
## 10938  5.7586995
## 10939  4.4728675
## 10940  5.1631028
## 10941  1.9863418
## 10942  5.8033601
## 10943  2.9024847
## 10944  2.6561518
## 10945  2.8809777
## 10946  3.2222766
## 10947  3.8696066
## 10948  2.5061386
## 10949  5.0060720
## 10950  3.3181205
## 10951  3.5711616
## 10952  5.1382035
## 10953  4.0101052
## 10954  5.9327470
## 10955  3.9659444
## 10956  5.4560695
## 10957  5.9889071
## 10958  5.1255057
## 10959  4.0843782
## 10960  4.4516088
## 10961  4.4159512
## 10962  4.1681363
## 10963  4.5228930
## 10964  4.5599902
## 10965  4.4136451
## 10966  5.1620660
## 10967  4.3228338
## 10968  5.3628383
## 10969  4.3398700
## 10970  3.8113420
## 10971  3.6460358
## 10972  3.7085182
## 10973  3.9541006
## 10974  5.5184213
## 10975  2.5794803
## 10976  3.8699411
## 10977  3.4934329
## 10978  4.7538437
## 10979  1.8512219
## 10980  3.6375130
## 10981  6.0283584
## 10982  5.3344338
## 10983  3.7551651
## 10984  2.0628068
## 10985  5.0623469
## 10986  4.9468433
## 10987  2.6564138
## 10988  6.6418788
## 10989  6.1591952
## 10990  6.5725286
## 10991  5.6701585
## 10992  5.2563713
## 10993  3.9169987
## 10994  5.3285440
## 10995  4.1906917
## 10996  4.2138181
## 10997  3.6274245
## 10998  3.7553376
## 10999  4.8764678
## 11000  1.6019232
## 11001  2.7860727
## 11002  3.2522094
## 11003  2.9996999
## 11004  4.4059673
## 11005  4.9296314
## 11006  4.5369071
## 11007  3.0715808
## 11008  4.8911417
## 11009  3.0838437
## 11010  3.2710897
## 11011  4.3077770
## 11012  4.2222060
## 11013  3.9152698
## 11014  4.0747723
## 11015  4.9105666
## 11016  4.3262570
## 11017  5.1449888
## 11018  4.5979730
## 11019  3.4666698
## 11020  5.3767921
## 11021  3.6785880
## 11022  3.8350251
## 11023  2.9357769
## 11024  5.2207403
## 11025  3.5788336
## 11026  4.7889694
## 11027  4.3872043
## 11028  4.0625496
## 11029  3.8843302
## 11030  5.4906341
## 11031  4.0443799
## 11032  4.2069277
## 11033  4.9679711
## 11034  5.0372183
## 11035  2.7512423
## 11036  3.9393290
## 11037  6.1628791
## 11038  5.6713844
## 11039  2.7011193
## 11040  4.6442483
## 11041  5.4841498
## 11042  3.2257491
## 11043  2.8397774
## 11044  3.4819194
## 11045  2.9892388
## 11046  6.2232161
## 11047  2.0937174
## 11048  3.0014922
## 11049  5.6351454
## 11050  4.8896761
## 11051  3.4925808
## 11052  4.3838617
## 11053  5.5534740
## 11054  5.0497068
## 11055  3.1714447
## 11056  3.5482521
## 11057  2.9764974
## 11058  5.1799024
## 11059  5.4130034
## 11060  6.5329713
## 11061  4.9447944
## 11062  2.9399572
## 11063  3.1105207
## 11064  3.9040303
## 11065  5.0559926
## 11066  4.0015552
## 11067  2.7292001
## 11068  5.7687063
## 11069  4.3149175
## 11070  3.7772909
## 11071  4.3951305
## 11072  3.5805186
## 11073  4.9345303
## 11074  4.7405238
## 11075  3.7987086
## 11076  3.7893804
## 11077  3.7191724
## 11078  5.1417314
## 11079  5.2134266
## 11080  5.0769979
## 11081  5.0716362
## 11082  4.5559497
## 11083  3.8767084
## 11084  6.0580244
## 11085  6.8552389
## 11086  6.5176741
## 11087  2.6479700
## 11088  6.4272837
## 11089  4.4952603
## 11090  3.5791546
## 11091  4.1602321
## 11092  3.7397265
## 11093  4.9667623
## 11094  2.6816657
## 11095  2.3619279
## 11096  6.0020227
## 11097  6.2624048
## 11098  4.5856511
## 11099  6.6213886
## 11100  2.5796288
## 11101  6.4336937
## 11102  5.9296363
## 11103  5.6680227
## 11104  5.0733909
## 11105  4.1054602
## 11106  4.2869481
## 11107  6.5124239
## 11108  5.2028841
## 11109  3.6278379
## 11110  2.9723025
## 11111  3.3461204
## 11112  2.8896552
## 11113  6.2644106
## 11114  6.2062935
## 11115  3.0302969
## 11116  3.6807217
## 11117  4.0461612
## 11118  4.5150502
## 11119  5.0954583
## 11120  2.8669651
## 11121  5.8692492
## 11122  4.9844826
## 11123  5.1261541
## 11124  4.6967826
## 11125  4.5068441
## 11126  4.3883023
## 11127  6.6273337
## 11128  2.4536867
## 11129  4.5962749
## 11130  2.8316536
## 11131  3.2898377
## 11132  3.9521741
## 11133  4.9314665
## 11134  5.7855882
## 11135  2.6777450
## 11136  4.4031198
## 11137  2.5990765
## 11138  5.1801164
## 11139  3.9495500
## 11140  6.1410342
## 11141  5.1334503
## 11142  3.1544833
## 11143  3.5256458
## 11144  4.7341232
## 11145  4.7657818
## 11146  3.5819123
## 11147  3.5402744
## 11148  3.2881798
## 11149  4.4108092
## 11150  6.5031292
## 11151  5.4881805
## 11152  6.5920967
## 11153  5.1954889
## 11154  3.9151148
## 11155  9.0719835
## 11156  7.8320922
## 11157  7.1124655
## 11158  6.2265951
## 11159  5.0258867
## 11160  5.2717641
## 11161  5.3143619
## 11162  5.3894030
## 11163  5.0797686
## 11164  3.4213324
## 11165  4.2464655
## 11166  3.6916604
## 11167  4.4285263
## 11168  2.3003768
## 11169  3.3395788
## 11170  5.6254174
## 11171  4.5764998
## 11172  5.1823770
## 11173  4.0556897
## 11174  3.4042835
## 11175  2.8612339
## 11176  6.5146555
## 11177  3.6095617
## 11178  5.2340108
## 11179  5.4304736
## 11180  5.0290400
## 11181  2.9978817
## 11182  3.7839440
## 11183  3.7403263
## 11184  3.6399255
## 11185  2.3419395
## 11186  5.3893751
## 11187  4.2423316
## 11188  4.2638354
## 11189  4.1425763
## 11190  4.3776918
## 11191  2.9325313
## 11192  3.8567835
## 11193  2.8276913
## 11194  3.7977471
## 11195  4.8698943
## 11196  4.5173174
## 11197  6.1232724
## 11198  5.8677626
## 11199  3.9050306
## 11200  4.4767135
## 11201  4.5544371
## 11202  4.5127015
## 11203  3.9323233
## 11204  5.1935545
## 11205  5.7271468
## 11206  3.5028790
## 11207  3.2478896
## 11208  5.8787445
## 11209  3.5676003
## 11210  3.8344747
## 11211  6.1410830
## 11212  6.7107551
## 11213  5.6958551
## 11214  5.5203380
## 11215  5.7698065
## 11216  5.4538175
## 11217  3.4984000
## 11218  2.9825111
## 11219  2.3931983
## 11220  5.4822959
## 11221  2.3010489
## 11222  2.3467508
## 11223  4.4634431
## 11224  4.0712713
## 11225  4.1846501
## 11226  4.2671879
## 11227  4.3230457
## 11228  5.6825668
## 11229  7.2329184
## 11230  4.2623989
## 11231  4.0580492
## 11232  2.7877700
## 11233  4.1691541
## 11234  4.0175334
## 11235  3.8475628
## 11236  4.8460045
## 11237  5.9396451
## 11238  4.4875067
## 11239  4.3899811
## 11240  4.5362462
## 11241  3.1988861
## 11242  4.9035077
## 11243  5.6829409
## 11244  5.2659814
## 11245  3.6114517
## 11246  3.9834737
## 11247  3.3831385
## 11248  3.9930814
## 11249  5.8821232
## 11250  3.7930837
## 11251  2.6241595
## 11252  3.7407106
## 11253  4.2059175
## 11254  3.3821466
## 11255  4.3763777
## 11256  2.8911824
## 11257  5.6318322
## 11258  3.4752968
## 11259  2.3729611
## 11260  5.0224440
## 11261  5.0269197
## 11262  5.3013911
## 11263  2.9910501
## 11264  4.5746872
## 11265  3.9295911
## 11266  5.5470300
## 11267  6.2488258
## 11268  5.0462331
## 11269  2.9172086
## 11270  2.1348924
## 11271  5.0424824
## 11272  5.4688142
## 11273  4.7709212
## 11274  5.1327185
## 11275  6.1119195
## 11276  6.3673637
## 11277  6.4971417
## 11278  5.8777474
## 11279  6.5518741
## 11280  2.5102163
## 11281  7.0091221
## 11282  6.9769493
## 11283  6.4125707
## 11284  3.0897368
## 11285  4.8784903
## 11286  4.6966210
## 11287  4.8633679
## 11288  3.8730639
## 11289  3.2553219
## 11290  3.6938527
## 11291  4.2803885
## 11292  3.2429192
## 11293  4.3561800
## 11294  2.8460508
## 11295  3.7535664
## 11296  4.2218706
## 11297  6.3777872
## 11298  5.0715704
## 11299  2.5513327
## 11300  2.8680188
## 11301  3.0461855
## 11302  3.4605541
## 11303  4.2434409
## 11304  4.3592157
## 11305  4.4438076
## 11306  5.2775130
## 11307  6.3349154
## 11308  3.9486349
## 11309  4.1309020
## 11310  4.0764003
## 11311  5.4356792
## 11312  5.5213606
## 11313  2.8579360
## 11314  2.4818922
## 11315  4.2502037
## 11316  5.7584362
## 11317  5.4842245
## 11318  3.9299600
## 11319  3.1314562
## 11320  3.3147671
## 11321  3.3275540
## 11322  2.6878205
## 11323  2.9207136
## 11324  2.4141855
## 11325  3.9372469
## 11326  3.6705415
## 11327  3.0453351
## 11328  4.4041392
## 11329  5.3416613
## 11330  5.6679726
## 11331  3.5473921
## 11332  2.9207842
## 11333  5.4400297
## 11334  2.9969539
## 11335  2.6296019
## 11336  3.7178983
## 11337  2.7552544
## 11338  2.4789008
## 11339  3.1404974
## 11340  4.0314725
## 11341  4.6153558
## 11342  3.1973350
## 11343  5.3341855
## 11344  2.8136038
## 11345  2.5853683
## 11346  5.3855632
## 11347  5.5314585
## 11348  6.0442400
## 11349  4.6764510
## 11350  7.4483680
## 11351  4.4828898
## 11352  2.7768745
## 11353  4.6242081
## 11354  4.0676383
## 11355  3.7421677
## 11356  3.3671125
## 11357  2.5933046
## 11358  3.6270013
## 11359  2.8353455
## 11360  3.0602352
## 11361  5.6777211
## 11362  4.7386304
## 11363  5.0969356
## 11364  4.9102679
## 11365  2.8684479
## 11366  3.9642715
## 11367  4.9204874
## 11368  2.4275735
## 11369  4.9181122
## 11370  4.2227346
## 11371  5.1478513
## 11372  4.2511681
## 11373  4.0424398
## 11374  3.9289053
## 11375  6.1742362
## 11376  4.1329043
## 11377  3.9564851
## 11378  5.2880993
## 11379  4.0618425
## 11380  4.9419962
## 11381  3.4733647
## 11382  3.3863294
## 11383  2.8966886
## 11384  3.3230440
## 11385  2.5106339
## 11386  2.9981284
## 11387  5.6505497
## 11388  3.4881323
## 11389  4.2910907
## 11390  2.5992734
## 11391  6.0933699
## 11392  4.4459844
## 11393  3.8902744
## 11394  2.5458647
## 11395  4.6021160
## 11396  2.8122452
## 11397  6.3048145
## 11398  4.3342163
## 11399  4.2747535
## 11400  4.8506007
## 11401  3.8965009
## 11402  3.4657903
## 11403  5.3546204
## 11404  4.1015140
## 11405  6.6680328
## 11406  3.5817237
## 11407  4.3422719
## 11408  3.8484860
## 11409  3.9639590
## 11410  4.5523687
## 11411  4.9155502
## 11412  4.2210532
## 11413  4.5865955
## 11414  4.2744720
## 11415  1.8118180
## 11416  2.7468871
## 11417  5.8815166
## 11418  6.0949030
## 11419  5.0764908
## 11420  4.8421006
## 11421  3.5317010
## 11422  2.2384463
## 11423  2.3343308
## 11424  2.6016422
## 11425  2.4759399
## 11426  0.8179009
## 11427  4.5797615
## 11428  5.8997166
## 11429  4.8950475
## 11430  3.8582574
## 11431  3.6881399
## 11432  6.2361130
## 11433  8.1266258
## 11434  5.9955568
## 11435  4.9767683
## 11436  2.4459645
## 11437  2.4601565
## 11438  1.3602526
## 11439  1.9950864
## 11440  3.3664137
## 11441  3.5865822
## 11442  3.3256634
## 11443  6.1844032
## 11444  3.6760558
## 11445  7.3071138
## 11446  5.7932570
## 11447  5.9840124
## 11448  5.1203507
## 11449  6.4519310
## 11450  4.0044715
## 11451  1.7514257
## 11452  3.6500306
## 11453  7.1692543
## 11454  2.6250787
## 11455  1.7290703
## 11456  3.7812252
## 11457  7.1931256
## 11458  5.7738601
## 11459  4.7246239
## 11460  5.1645065
## 11461  4.6459366
## 11462  4.1722095
## 11463  4.4608492
## 11464  4.6759230
## 11465  4.1891968
## 11466  5.7309935
## 11467  5.2699813
## 11468  4.6568413
## 11469  5.9412604
## 11470  3.4628612
## 11471  6.1503085
## 11472  4.4955758
## 11473  4.4944083
## 11474  4.4756635
## 11475  3.8933375
## 11476  3.3999322
## 11477  3.0488902
## 11478  2.7738655
## 11479  4.5824729
## 11480  5.2430608
## 11481  4.7969932
## 11482  4.4023480
## 11483  2.9430485
## 11484  3.1720601
## 11485  4.2948762
## 11486  4.1953232
## 11487  4.9654905
## 11488  4.8790479
## 11489  5.2583483
## 11490  4.9352363
## 11491  4.7456875
## 11492  5.6187317
## 11493  4.8641504
## 11494  4.0803222
## 11495  4.0003755
## 11496  3.7818385
## 11497  3.0082656
## 11498  3.5161696
## 11499  2.9392304
## 11500  4.0942438
## 11501  3.3680066
## 11502  2.8039087
## 11503  3.5313558
## 11504  4.0920914
## 11505  4.5684592
## 11506  2.7921080
## 11507  2.5234726
## 11508  3.0989957
## 11509  5.2396891
## 11510  3.5353123
## 11511  5.1472281
## 11512  5.3762733
## 11513  3.6544125
## 11514  3.8357944
## 11515  4.8076263
## 11516  5.6713867
## 11517  2.3760790
## 11518  3.4098157
## 11519  3.2600578
## 11520  3.1197047
## 11521  2.3171744
## 11522  1.6517452
## 11523  2.5098203
## 11524  5.1363783
## 11525  4.0083080
## 11526  6.5301214
## 11527  5.3883326
## 11528  3.8122324
## 11529  5.3391270
## 11530  2.8689688
## 11531  4.1498710
## 11532  6.5594018
## 11533  6.5678653
## 11534  7.0344883
## 11535  5.0752738
## 11536  4.3638250
## 11537  4.4655090
## 11538  5.7750133
## 11539  4.4375704
## 11540  4.7084327
## 11541  2.2885382
## 11542  4.4869832
## 11543  1.8006680
## 11544  2.7499670
## 11545  3.5126129
## 11546  3.4063290
## 11547  4.9771492
## 11548  2.8357451
## 11549  6.3994401
## 11550  3.6804571
## 11551  5.2823547
## 11552  5.6647479
## 11553  4.5981803
## 11554  3.3098185
## 11555  1.7648489
## 11556  3.5661134
## 11557  4.6881574
## 11558  3.0483602
## 11559  3.0897387
## 11560  5.6416421
## 11561  1.8135256
## 11562  2.1406511
## 11563  4.4700265
## 11564  4.5461275
## 11565  5.8986890
## 11566  5.5464418
## 11567  6.8192867
## 11568  4.3039837
## 11569  4.7619655
## 11570  4.6666560
## 11571  5.1814719
## 11572  5.5760810
## 11573  4.8882401
## 11574  6.0704303
## 11575  5.6798224
## 11576  5.8720896
## 11577  4.9412520
## 11578  3.7301197
## 11579  5.8333306
## 11580  3.0600494
## 11581  3.3083269
## 11582  4.0814581
## 11583  4.4206228
## 11584  4.4268881
## 11585  4.1835826
## 11586  4.8925786
## 11587  4.8112719
## 11588  4.7322670
## 11589  4.0371697
## 11590  3.8273884
## 11591  3.4387444
## 11592  5.5894218
## 11593  4.1224328
## 11594  3.1655403
## 11595  3.9110668
## 11596  5.6390697
## 11597  5.9841915
## 11598  4.3773592
## 11599  4.6926632
## 11600  5.3063352
## 11601  3.9999708
## 11602  3.5549081
## 11603  1.7923325
## 11604  0.6441456
## 11605  0.9372081
## 11606  3.3665297
## 11607  3.4737703
## 11608  4.8018226
## 11609  5.1623840
## 11610  4.3824393
## 11611  4.0757869
## 11612  5.1374106
## 11613  4.4732644
## 11614  5.4491745
## 11615  7.3953968
## 11616  5.3018525
## 11617  5.6562372
## 11618  3.3806396
## 11619  1.7312846
## 11620  3.5257890
## 11621  6.1831684
## 11622  3.9527348
## 11623  4.1277166
## 11624  3.7481976
## 11625  4.7191225
## 11626  2.4539892
## 11627  1.8325334
## 11628  4.5737414
## 11629  3.8979740
## 11630  4.2792765
## 11631  3.4305578
## 11632  4.0675461
## 11633  3.5259523
## 11634  1.9393420
## 11635  3.1580700
## 11636  4.7237969
## 11637  7.0539696
## 11638  6.3565672
## 11639  5.6999790
## 11640  5.8431500
## 11641  4.1524043
## 11642  2.6383218
## 11643  3.2155654
## 11644  3.3827227
## 11645  4.8297305
## 11646  4.0883135
## 11647  4.6284559
## 11648  5.1437472
## 11649  3.6479993
## 11650  3.9981724
## 11651  5.3481393
## 11652  2.2190598
## 11653  3.4970638
## 11654  4.1130492
## 11655  5.0995683
## 11656  4.7564828
## 11657  5.4883126
## 11658  5.0486153
## 11659  3.5956715
## 11660  3.4304655
## 11661  4.6454275
## 11662  3.6998324
## 11663  5.6287814
## 11664  6.4898198
## 11665  4.7620979
## 11666  4.9121184
## 11667  2.8864939
## 11668  4.7579511
## 11669  5.1410954
## 11670  5.6094235
## 11671  3.5591479
## 11672  5.3838321
## 11673  3.2928863
## 11674  5.3154414
## 11675  3.9309473
## 11676  3.5419787
## 11677  3.3914225
## 11678  2.6518512
## 11679  3.3915651
## 11680  5.0626178
## 11681  6.0290345
## 11682  3.2520534
## 11683  3.4501348
## 11684  3.1048986
## 11685  4.7529533
## 11686  3.4034296
## 11687  3.0909655
## 11688  4.3887648
## 11689  4.1865263
## 11690  5.7982462
## 11691  4.2959460
## 11692  6.0563695
## 11693  5.6699467
## 11694  4.5017454
## 11695  4.0361005
## 11696  3.0444627
## 11697  5.1746407
## 11698  4.0328179
## 11699  4.2403768
## 11700  4.0359533
## 11701  3.5619236
## 11702  4.2822661
## 11703  4.6562718
## 11704  5.7101705
## 11705  4.9663752
## 11706  3.4409166
## 11707  5.5524909
## 11708  4.1639570
## 11709  4.9659696
## 11710  4.6556311
## 11711  4.8429538
## 11712  1.4084560
## 11713  1.6224904
## 11714  5.6776371
## 11715  5.3880493
## 11716  4.9668689
## 11717  1.2903349
## 11718  5.1083524
## 11719  3.3139784
## 11720  3.3435665
## 11721  3.6287783
## 11722  3.9994737
## 11723  3.8759532
## 11724  4.3008767
## 11725  4.8678992
## 11726  3.0028084
## 11727  4.7602292
## 11728  5.8618661
## 11729  6.4570396
## 11730  4.1388129
## 11731  7.2547071
## 11732  6.7101279
## 11733  3.2083408
## 11734  2.4655051
## 11735  2.8189388
## 11736  3.3763754
## 11737  5.3663061
## 11738  4.4381983
## 11739  5.3950277
## 11740  4.2656367
## 11741  7.3488703
## 11742  6.1157640
## 11743  3.8446206
## 11744  3.4904371
## 11745  6.6580745
## 11746  6.8691608
## 11747  5.3996438
## 11748  4.2615237
## 11749  3.3552715
## 11750  3.6971085
## 11751  5.3211479
## 11752  4.1771269
## 11753  4.0314517
## 11754  4.8036517
## 11755  6.1899102
## 11756  5.9437707
## 11757  4.7328349
## 11758  5.3598607
## 11759  5.6799841
## 11760  5.9448315
## 11761  6.6953115
## 11762  4.1075338
## 11763  4.9470384
## 11764  5.1404192
## 11765  5.7572517
## 11766  4.5800429
## 11767  3.5999801
## 11768  4.7340311
## 11769  4.6118820
## 11770  6.1241451
## 11771  6.1724682
## 11772  4.1341154
## 11773  4.1415436
## 11774  3.2648048
## 11775  2.5621151
## 11776  4.1021359
## 11777  4.6813067
## 11778  4.9441564
## 11779  4.7680494
## 11780  4.3628744
## 11781  3.0601182
## 11782  5.8385405
## 11783  6.4457578
## 11784  6.8491168
## 11785  5.9929523
## 11786  6.5885930
## 11787  5.2605726
## 11788  5.3762512
## 11789  6.1577576
## 11790  6.1707598
## 11791  4.0701548
## 11792  3.8434399
## 11793  5.3231530
## 11794  5.0448960
## 11795  3.4766142
## 11796  2.5357191
## 11797  1.7382526
## 11798  1.6631179
## 11799  1.8622986
## 11800  3.2435514
## 11801  3.7689804
## 11802  5.9532518
## 11803  5.5274784
## 11804  4.6672266
## 11805  3.6109828
## 11806  3.9487046
## 11807  2.2346703
## 11808  3.7965504
## 11809  5.5314812
## 11810  5.4994655
## 11811  4.6622023
## 11812  4.2869947
## 11813  5.2288778
## 11814  4.3412249
## 11815  3.0257804
## 11816  4.8455599
## 11817  5.2573741
## 11818  4.4292423
## 11819  4.5161743
## 11820  4.7415516
## 11821  2.9954330
## 11822  2.8367543
## 11823  4.1262429
## 11824  3.1516868
## 11825  4.7599047
## 11826  3.1868075
## 11827  4.0454276
## 11828  4.6705592
## 11829  5.1072117
## 11830  5.4390097
## 11831  5.2087886
## 11832  3.6356551
## 11833  2.3875015
## 11834  3.5843826
## 11835  4.9617036
## 11836  4.0522331
## 11837  2.9362638
## 11838  2.1509908
## 11839  4.0453255
## 11840  2.4538382
## 11841  4.2338126
## 11842  3.4215180
## 11843  4.2971300
## 11844  3.3406276
## 11845  4.5739964
## 11846  3.9819420
## 11847  5.6565816
## 11848  3.9964231
## 11849  5.0165807
## 11850  2.1407786
## 11851  5.3116644
## 11852  6.5872176
## 11853  3.6781465
## 11854  3.3732560
## 11855  4.0385699
## 11856  3.0723864
## 11857  3.4445587
## 11858  5.4234987
## 11859  2.6887692
## 11860  3.0612254
## 11861  4.7912819
## 11862  4.2299530
## 11863  5.5563576
## 11864  4.5199203
## 11865  5.1538565
## 11866  5.1738244
## 11867  4.8820359
## 11868  5.3976247
## 11869  3.0261708
## 11870  4.0081767
## 11871  3.6166486
## 11872  2.8674383
## 11873  4.6401468
## 11874  6.8647990
## 11875  4.7807186
## 11876  4.3358500
## 11877  3.8446463
## 11878  1.2749806
## 11879  4.4593837
## 11880  4.0915736
## 11881  2.9199049
## 11882  4.1370184
## 11883  5.7810250
## 11884  5.0294270
## 11885  3.2090682
## 11886  2.5541215
## 11887  2.0143019
## 11888  3.0744506
## 11889  4.1665479
## 11890  3.7936864
## 11891  3.9994826
## 11892  3.5416063
## 11893  3.6639400
## 11894  4.4802571
## 11895  4.5422734
## 11896  3.9029397
## 11897  5.8491424
## 11898  4.5313271
## 11899  5.4631452
## 11900  5.7331955
## 11901  2.7780453
## 11902  2.3862049
## 11903  5.1758726
## 11904  5.4969332
## 11905  3.0258082
## 11906  3.8220503
## 11907  5.0944065
## 11908  5.2691541
## 11909  3.2615832
## 11910  4.0173476
## 11911  3.3989879
## 11912  2.3821345
## 11913  2.9732573
## 11914  5.6614024
## 11915  4.7280704
## 11916  4.0588831
## 11917  4.9586333
## 11918  4.9134385
## 11919  3.2580195
## 11920  6.2023357
## 11921  6.7066628
## 11922  3.2609658
## 11923  3.1229273
## 11924  3.3673931
## 11925  4.5291886
## 11926  5.2026830
## 11927  4.8173712
## 11928  4.6280735
## 11929  3.4547118
## 11930  3.3072542
## 11931  4.3864295
## 11932  4.7725423
## 11933  3.8511235
## 11934  3.4286141
## 11935  2.8301457
## 11936  4.8945314
## 11937  5.2972929
## 11938  4.8639885
## 11939  2.4136272
## 11940  4.4561659
## 11941  4.9780742
## 11942  3.5232983
## 11943  3.3790020
## 11944  3.3790252
## 11945  3.5568637
## 11946  3.6584995
## 11947  4.6349180
## 11948  3.0386684
## 11949  3.8389705
## 11950  4.2412325
## 11951  4.6558113
## 11952  4.4564918
## 11953  2.5489835
## 11954  3.5300856
## 11955  4.3539125
## 11956  2.7865215
## 11957  3.8932154
## 11958  3.2662126
## 11959  3.5065864
## 11960  3.3169929
## 11961  3.9326581
## 11962  4.4114127
## 11963  3.2220996
## 11964  3.8794827
## 11965  5.0977466
## 11966  4.2479157
## 11967  4.4605399
## 11968  4.7788785
## 11969  4.0212022
## 11970  4.9627421
## 11971  5.1864684
## 11972  4.3418772
## 11973  5.5502336
## 11974  5.6806706
## 11975  3.5846936
## 11976  5.6089828
## 11977  3.4034325
## 11978  4.7561340
## 11979  3.6976439
## 11980  3.5080074
## 11981  3.9757280
## 11982  4.5317297
## 11983  4.2676382
## 11984  3.8843322
## 11985  5.3217192
## 11986  5.6846341
## 11987  4.6747547
## 11988  4.5646708
## 11989  3.4938921
## 11990  3.8153309
## 11991  4.9709017
## 11992  5.9448454
## 11993  4.4934258
## 11994  2.7317146
## 11995  2.9595003
## 11996  2.8766388
## 11997  3.8361102
## 11998  3.8199704
## 11999  4.9616269
## 12000  4.4607810</code></pre>
<div class="sourceCode" id="cb1670"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1670-1" data-line-number="1"><span class="kw">bind_cols</span>(<span class="kw">posterior_samples</span>(fit1) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(sigma),</a>
<a class="sourceLine" id="cb1670-2" data-line-number="2">          <span class="kw">posterior_samples</span>(fit4) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1670-3" data-line-number="3"><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">dif =</span> sigma <span class="op">-</span><span class="st"> </span>sigma1) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1670-4" data-line-number="4"><span class="st">  </span></a>
<a class="sourceLine" id="cb1670-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> dif, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1670-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">point_range =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">5</span>, <span class="fl">.95</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1670-7" data-line-number="7"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1670-8" data-line-number="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;This is a difference distribution&quot;</span>,</a>
<a class="sourceLine" id="cb1670-9" data-line-number="9">       <span class="dt">x     =</span> <span class="kw">expression</span>(sigma[y]))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-58-1.png" /><!-- --></p>
<p>If you want a quick and dirty plot of the relation between <code>thorax_c</code> and <code>Longevity</code>, you can use <code>brms::conditional_effects()</code>.</p>
<div class="sourceCode" id="cb1671"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1671-1" data-line-number="1"><span class="kw">conditional_effects</span>(fit4)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-59-1.png" /><!-- --></p>
<p>But to make plots like the ones at the top of Figure 19.5, we’ll have to work a little harder. First, we need some intermediary values marking off the three values along the <code>Thorax</code>-axis Kruschke singled out in his top panel plots. As far as I can tell, they were the <code>min()</code>, the <code>max()</code>, and their <code>mean()</code>.</p>
<div class="sourceCode" id="cb1672"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1672-1" data-line-number="1">(r &lt;-<span class="st"> </span><span class="kw">range</span>(my_data<span class="op">$</span>Thorax))</a></code></pre></div>
<pre><code>## [1] 0.64 0.94</code></pre>
<div class="sourceCode" id="cb1674"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1674-1" data-line-number="1"><span class="kw">mean</span>(r)</a></code></pre></div>
<pre><code>## [1] 0.79</code></pre>
<p>Next, we’ll make the data necessary for our side-tipped Gaussians. For kicks and giggles, we’ll choose 80 draws instead of 20. But do note how we used our <code>r</code> values, from above, to specify both <code>Thorax</code> and <code>thorax_c</code> values in addition to the <code>CompanionNumber</code> categories for the <code>newdata</code> argument. Otherwise, this workflow is very much the same as in previous plots.</p>
<div class="sourceCode" id="cb1676"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1676-1" data-line-number="1">n_draws &lt;-<span class="st"> </span><span class="dv">80</span></a>
<a class="sourceLine" id="cb1676-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1676-3" data-line-number="3">densities &lt;-</a>
<a class="sourceLine" id="cb1676-4" data-line-number="4"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-5" data-line-number="5"><span class="st">  </span><span class="kw">distinct</span>(CompanionNumber) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-6" data-line-number="6"><span class="st">  </span><span class="kw">expand</span>(CompanionNumber, <span class="dt">Thorax =</span> <span class="kw">c</span>(r[<span class="dv">1</span>], <span class="kw">mean</span>(r), r[<span class="dv">2</span>])) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">thorax_c  =</span> Thorax <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(my_data<span class="op">$</span>Thorax)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-8" data-line-number="8"><span class="st">  </span><span class="kw">add_fitted_draws</span>(fit4, <span class="dt">n =</span> n_draws, <span class="dt">seed =</span> <span class="dv">19</span>, <span class="dt">dpar =</span> <span class="kw">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-9" data-line-number="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ll        =</span> <span class="kw">qnorm</span>(.<span class="dv">025</span>, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma),</a>
<a class="sourceLine" id="cb1676-10" data-line-number="10">         <span class="dt">ul        =</span> <span class="kw">qnorm</span>(.<span class="dv">975</span>, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-11" data-line-number="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Longevity =</span> <span class="kw">map2</span>(ll, ul, seq, <span class="dt">length.out =</span> <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-12" data-line-number="12"><span class="st">  </span><span class="kw">unnest</span>(Longevity) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1676-13" data-line-number="13"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density   =</span> <span class="kw">dnorm</span>(Longevity, mu, sigma))</a>
<a class="sourceLine" id="cb1676-14" data-line-number="14"></a>
<a class="sourceLine" id="cb1676-15" data-line-number="15"><span class="kw">glimpse</span>(densities)</a></code></pre></div>
<pre><code>## Observations: 120,000
## Variables: 14
## Groups: CompanionNumber, Thorax, thorax_c, .row [15]
## $ CompanionNumber &lt;chr&gt; &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;…
## $ Thorax          &lt;dbl&gt; 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0…
## $ thorax_c        &lt;dbl&gt; -0.18096, -0.18096, -0.18096, -0.18096, -0.18096, -0.18096, -0.18096, -0.…
## $ .row            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ .chain          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .iteration      &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .draw           &lt;int&gt; 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3…
## $ .value          &lt;dbl&gt; 38.56409, 38.56409, 38.56409, 38.56409, 38.56409, 38.56409, 38.56409, 38.…
## $ mu              &lt;dbl&gt; 38.56409, 38.56409, 38.56409, 38.56409, 38.56409, 38.56409, 38.56409, 38.…
## $ sigma           &lt;dbl&gt; 12.08948, 12.08948, 12.08948, 12.08948, 12.08948, 12.08948, 12.08948, 12.…
## $ ll              &lt;dbl&gt; 14.86915, 14.86915, 14.86915, 14.86915, 14.86915, 14.86915, 14.86915, 14.…
## $ ul              &lt;dbl&gt; 62.25903, 62.25903, 62.25903, 62.25903, 62.25903, 62.25903, 62.25903, 62.…
## $ Longevity       &lt;dbl&gt; 14.86915, 15.34783, 15.82652, 16.30520, 16.78389, 17.26258, 17.74126, 18.…
## $ density         &lt;dbl&gt; 0.004834375, 0.005220395, 0.005628408, 0.006058804, 0.006511894, 0.006987…</code></pre>
<p>Here, we’ll use a simplified workflow to extract the <code>fitted()</code> values in order to make the regression lines. Since these are straight lines, all we need are two values for each draw, one at the extremes of the <code>Thorax</code> axis.</p>
<div class="sourceCode" id="cb1678"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1678-1" data-line-number="1">f &lt;-</a>
<a class="sourceLine" id="cb1678-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1678-3" data-line-number="3"><span class="st">  </span><span class="kw">distinct</span>(CompanionNumber) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1678-4" data-line-number="4"><span class="st">  </span><span class="kw">expand</span>(CompanionNumber, <span class="dt">Thorax =</span> <span class="kw">c</span>(r[<span class="dv">1</span>], <span class="kw">mean</span>(r), r[<span class="dv">2</span>])) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1678-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">thorax_c =</span> Thorax <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(my_data<span class="op">$</span>Thorax)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1678-6" data-line-number="6"><span class="st">  </span><span class="kw">add_fitted_draws</span>(fit4, <span class="dt">n =</span> n_draws, <span class="dt">seed =</span> <span class="dv">19</span>, <span class="dt">value =</span> <span class="st">&quot;Longevity&quot;</span>)</a>
<a class="sourceLine" id="cb1678-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1678-8" data-line-number="8"><span class="kw">glimpse</span>(f)</a></code></pre></div>
<pre><code>## Observations: 1,200
## Variables: 8
## Groups: CompanionNumber, Thorax, thorax_c, .row [15]
## $ CompanionNumber &lt;chr&gt; &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;None0&quot;, &quot;…
## $ Thorax          &lt;dbl&gt; 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0…
## $ thorax_c        &lt;dbl&gt; -0.18096, -0.18096, -0.18096, -0.18096, -0.18096, -0.18096, -0.18096, -0.…
## $ .row            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ .chain          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .iteration      &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ .draw           &lt;int&gt; 31, 208, 586, 800, 1099, 1115, 1353, 1800, 2120, 2133, 2195, 2220, 2492, …
## $ Longevity       &lt;dbl&gt; 38.56409, 30.73483, 41.54440, 39.10625, 36.16563, 31.61745, 39.23632, 36.…</code></pre>
<p>Now we’re ready to make our plots for the top row of Figure 19.3.</p>
<div class="sourceCode" id="cb1680"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1680-1" data-line-number="1">densities <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1680-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Longevity, <span class="dt">y =</span> Thorax)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1680-3" data-line-number="3"><span class="st">  </span><span class="co"># the Gaussians</span></a>
<a class="sourceLine" id="cb1680-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ridgeline</span>(<span class="kw">aes</span>(<span class="dt">height =</span> <span class="op">-</span>density, <span class="dt">group =</span> <span class="kw">interaction</span>(Thorax, .draw)),</a>
<a class="sourceLine" id="cb1680-5" data-line-number="5">                 <span class="dt">fill =</span> <span class="ot">NA</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>, <span class="dt">scale =</span> <span class="dv">5</span><span class="op">/</span><span class="dv">3</span>,</a>
<a class="sourceLine" id="cb1680-6" data-line-number="6">                 <span class="dt">color =</span> <span class="kw">adjustcolor</span>(<span class="st">&quot;grey50&quot;</span>, <span class="dt">alpha.f =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>),</a>
<a class="sourceLine" id="cb1680-7" data-line-number="7">                 <span class="dt">min_height =</span> <span class="ot">NA</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1680-8" data-line-number="8"><span class="st">  </span><span class="co"># the vertical lines below the Gaussians</span></a>
<a class="sourceLine" id="cb1680-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> <span class="kw">interaction</span>(Thorax, .draw)),</a>
<a class="sourceLine" id="cb1680-10" data-line-number="10">            <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1680-11" data-line-number="11"><span class="st">  </span><span class="co"># the regression lines</span></a>
<a class="sourceLine" id="cb1680-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> f,</a>
<a class="sourceLine" id="cb1680-13" data-line-number="13">            <span class="kw">aes</span>(<span class="dt">group =</span> .draw),</a>
<a class="sourceLine" id="cb1680-14" data-line-number="14">            <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1680-15" data-line-number="15"><span class="st">  </span><span class="co"># the data</span></a>
<a class="sourceLine" id="cb1680-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1680-17" data-line-number="17">             <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1680-18" data-line-number="18"><span class="st">  </span><span class="kw">coord_flip</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">110</span>,</a>
<a class="sourceLine" id="cb1680-19" data-line-number="19">             <span class="dt">ylim =</span> <span class="kw">c</span>(.<span class="dv">58</span>, <span class="dv">1</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1680-20" data-line-number="20"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>CompanionNumber, <span class="dt">ncol =</span> <span class="dv">5</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-63-1.png" /><!-- --></p>
<p>Now we have a covariate in the model, we have to decide on which of its values we want to base our group comparisons. Unless there’s a substantive reason for another value, the mean is a good standard choice. And since the covariate <code>thorax_c</code> is already mean centered, that means we can effectively leave it out of the equation. Here they are in the simple difference metric.</p>
<div class="sourceCode" id="cb1681"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1681-1" data-line-number="1">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit4)</a>
<a class="sourceLine" id="cb1681-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1681-3" data-line-number="3">differences &lt;-</a>
<a class="sourceLine" id="cb1681-4" data-line-number="4"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1681-5" data-line-number="5"><span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">Pregnant1.Pregnant8 vs None0</span><span class="st">`</span> =<span class="st"> </span>(<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>,</a>
<a class="sourceLine" id="cb1681-6" data-line-number="6">            </a>
<a class="sourceLine" id="cb1681-7" data-line-number="7">            <span class="st">`</span><span class="dt">Pregnant1.Pregnant8.None0 vs Virgin1</span><span class="st">`</span> =<span class="st"> </span>(<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">3</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin1,Intercept]</span><span class="st">`</span>,</a>
<a class="sourceLine" id="cb1681-8" data-line-number="8">            </a>
<a class="sourceLine" id="cb1681-9" data-line-number="9">            <span class="st">`</span><span class="dt">Virgin1 vs Virgin8</span><span class="st">`</span> =<span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin1,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin8,Intercept]</span><span class="st">`</span>,</a>
<a class="sourceLine" id="cb1681-10" data-line-number="10">            </a>
<a class="sourceLine" id="cb1681-11" data-line-number="11">            <span class="st">`</span><span class="dt">Pregnant1.Pregnant8.None0 vs Virgin1.Virgin8</span><span class="st">`</span> =<span class="st"> </span>(<span class="st">`</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Pregnant1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[None0,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">3</span> <span class="op">-</span><span class="st"> </span>(<span class="st">`</span><span class="dt">r_CompanionNumber[Virgin1,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> `</span><span class="dt">r_CompanionNumber[Virgin8,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1681-12" data-line-number="12"></a>
<a class="sourceLine" id="cb1681-13" data-line-number="13">differences <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1681-14" data-line-number="14"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st">   </span></a>
<a class="sourceLine" id="cb1681-15" data-line-number="15"><span class="st">  </span></a>
<a class="sourceLine" id="cb1681-16" data-line-number="16"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1681-17" data-line-number="17"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1681-18" data-line-number="18">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1681-19" data-line-number="19"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1681-20" data-line-number="20">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1681-21" data-line-number="21"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1681-22" data-line-number="22"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Difference&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1681-23" data-line-number="23"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">strip.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="fl">6.4</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1681-24" data-line-number="24"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-64-1.png" /><!-- --></p>
<p>Now we’ll look at the differences in the effect size metric. Since we saved our work above, it’s really easy to just convert the differences in bulk with <code>mutate_all()</code>.</p>
<div class="sourceCode" id="cb1682"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1682-1" data-line-number="1">differences <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1682-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate_all</span>(<span class="dt">.funs =</span> <span class="op">~</span>. <span class="op">/</span><span class="st"> </span>post<span class="op">$</span>sigma) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1682-3" data-line-number="3"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st">   </span></a>
<a class="sourceLine" id="cb1682-4" data-line-number="4"><span class="st">  </span></a>
<a class="sourceLine" id="cb1682-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1682-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1682-7" data-line-number="7">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1682-8" data-line-number="8"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1682-9" data-line-number="9">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1682-10" data-line-number="10"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1682-11" data-line-number="11"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Effect Size&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1682-12" data-line-number="12"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">strip.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="fl">6.4</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1682-13" data-line-number="13"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-65-1.png" /><!-- --></p>
<p>“The HDI widths of all the contrasts have gotten smaller by virtue of including the covariate in the analysis” (p. 571).</p>
</div>
<div id="analogous-to-traditional-ancova." class="section level3">
<h3><span class="header-section-number">19.4.2</span> Analogous to traditional ANCOVA.</h3>
<p>In contrast with ANCOVA,</p>
<blockquote>
<p>Bayesian methods do not partition the least-squares variance to make estimates, and therefore the Bayesian method is analogous to ANCOVA but is not ANCOVA. Frequentist practitioners are urged to test (with <span class="math inline">\(p\)</span> values) whether the assumptions of (a) equal slope in all groups, (b) equal standard deviation in all groups, and (c) normally distributed noise can be rejected. In a Bayesian approach, the descriptive model is generalized to address these concerns, as will be discussed in Section 19.5. (p. 572)</p>
</blockquote>
</div>
<div id="relation-to-hierarchical-linear-regression." class="section level3">
<h3><span class="header-section-number">19.4.3</span> Relation to hierarchical linear regression.</h3>
<p>Here Kruschke contrasts our last model with the one from way back in Chapter 17, section 3. As a refresher, here’s what that code looked like.</p>
<div class="sourceCode" id="cb1683"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1683-1" data-line-number="1">fit4 &lt;-</a>
<a class="sourceLine" id="cb1683-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1683-3" data-line-number="3">      <span class="dt">family =</span> student,</a>
<a class="sourceLine" id="cb1683-4" data-line-number="4">      y_z <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x_z <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x_z <span class="op">||</span><span class="st"> </span>Subj),</a>
<a class="sourceLine" id="cb1683-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1683-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1683-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>),  <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb1683-8" data-line-number="8">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>),  <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1683-9" data-line-number="9">                <span class="kw">prior</span>(<span class="kw">exponential</span>(one_over_twentynine) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">class =</span> nu)),</a>
<a class="sourceLine" id="cb1683-10" data-line-number="10">      <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1683-11" data-line-number="11">      <span class="dt">stanvars =</span> <span class="kw">stanvar</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">29</span>, <span class="dt">name =</span> <span class="st">&quot;one_over_twentynine&quot;</span>))</a></code></pre></div>
<p>And for convenience, here’s the code from the model we just fit.</p>
<div class="sourceCode" id="cb1684"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1684-1" data-line-number="1">fit5 &lt;-</a>
<a class="sourceLine" id="cb1684-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1684-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1684-4" data-line-number="4">      Longevity <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>thorax_c <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>CompanionNumber),</a>
<a class="sourceLine" id="cb1684-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>),          <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1684-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span>sd_Thorax_c), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1684-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">gamma</span>(alpha, beta),                <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1684-8" data-line-number="8">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, sd_y),                   <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1684-9" data-line-number="9">      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1684-10" data-line-number="10">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>),</a>
<a class="sourceLine" id="cb1684-11" data-line-number="11">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>It’s easy to get lost in the differences in the priors and the technical details with the model chains and such. The main thing to notice, here, is the differences in the model formulas (i.e., the likelihoods). Both models had intercepts and slopes. But whereas the model from 17.3 set both parameters to random, only the intercept in our last modes was random. The covariate <code>thorax_c</code> was fixed–it did not vary by group. Had we wanted it to, our <code>formula</code> syntax would have been something like <code>Longevity ~ 1 + thorax_c + (1 + thorax_c || CompanionNumber)</code>. And again, as noted in Chapter 17, the <code>||</code> portion of the syntax set the random intercepts and slopes to be orthogonal (i.e., correlate exactly at zero). As we’ll see, this will often not be the case. But let’s not get ahead of ourselves.</p>
<blockquote>
<p>Conceptually, the main difference between the models is merely the focus of attention. In the hierarchical linear regression model, the focus was on the slope coefficient. In that case, we were trying to estimate the magnitude of the slope, simultaneously for individuals and overall. The intercepts, which describe the levels of the nominal predictor, were of ancillary interest. In the present section, on the other hand, the focus of attention is reversed. We are most interested in the intercepts and their differences between groups, with the slopes on the covariate being of ancillary interest. (p. 573)</p>
</blockquote>
</div>
</div>
<div id="heterogeneous-variances-and-robustness-against-outliers" class="section level2">
<h2><span class="header-section-number">19.5</span> Heterogeneous variances and robustness against outliers</h2>
<p>On page 574, Kruschke laid out the schematic for a hierarchical Student’s-<span class="math inline">\(t\)</span> model in for which both the <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> parameters are random. Bürkner calls these <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html">distributional models</a> and they are indeed available within the <strong>brms</strong> framework. But there’s a catch. Though we can model <span class="math inline">\(\sigma\)</span> all day long and we can even make it hierarchical, <strong>brms</strong> limits us to modeling the hierarchical <span class="math inline">\(\sigma\)</span> parameters within the typical Gaussian framework. That is, we will depart from Kruschke’s schematic in that we will be</p>
<ul>
<li>modeling the log of <span class="math inline">\(\sigma\)</span>,</li>
<li>indicating its grand mean with the <code>sigma ~ 1</code> syntax,</li>
<li>modeling the group-level deflections as Gaussian with a mean of 0 and standard deviation <span class="math inline">\(\sigma_\sigma\)</span> estimated from the data,</li>
<li>and choosing a sensible prior for <span class="math inline">\(\sigma_\sigma\)</span> that is left-bound at 0 and gently slopes to the right (i.e., a folded <span class="math inline">\(t\)</span> or gamma distribution).</li>
</ul>
<p>Since we’re modeling <span class="math inline">\(\log(\sigma)\)</span>, we might use Gaussian prior centered on <code>sd(my_data$y) %&gt;% log()</code> and a reasonable spread like 1. We can simulate a little to get a sense of what those distributions look like.</p>
<div class="sourceCode" id="cb1685"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1685-1" data-line-number="1">n_draws &lt;-<span class="st"> </span><span class="fl">1e3</span></a>
<a class="sourceLine" id="cb1685-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1685-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">19</span>)</a>
<a class="sourceLine" id="cb1685-4" data-line-number="4"><span class="kw">tibble</span>(<span class="dt">prior =</span> <span class="kw">rnorm</span>(n_draws, <span class="dt">mean =</span> <span class="kw">log</span>(<span class="dv">1</span>), <span class="dt">sd =</span> <span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1685-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prior_exp =</span> <span class="kw">exp</span>(prior)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1685-6" data-line-number="6"><span class="st">  </span><span class="kw">gather</span>(key, value) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1685-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1685-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1685-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&quot;grey50&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1685-10" data-line-number="10"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-68-1.png" /><!-- --></p>
<p>Here’s what is looks like with <code>sd = 2</code>.</p>
<div class="sourceCode" id="cb1686"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1686-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">19</span>)</a>
<a class="sourceLine" id="cb1686-2" data-line-number="2"><span class="kw">tibble</span>(<span class="dt">prior =</span> <span class="kw">rnorm</span>(n_draws, <span class="dt">mean =</span> <span class="kw">log</span>(<span class="dv">1</span>), <span class="dt">sd =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1686-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prior_exp =</span> <span class="kw">exp</span>(prior)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1686-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1686-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prior_exp)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1686-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&quot;grey50&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1686-7" data-line-number="7"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">17</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-69-1.png" /><!-- --></p>
<p>Though we’re still peaking around 1, there’s more mass in the tail, making it easier for the likelihood to pull away from the prior mode.</p>
<p>But all this is the prior on the fixed effect, the grand mean of <span class="math inline">\(\log (\sigma)\)</span>. Keep in mind we’re also estimating group-level deflections using a hierarchical model. The good old folded <span class="math inline">\(t\)</span> on the unit scale is already pretty permissive for an estimate that is itself on the log scale. To make it more conservative, set <span class="math inline">\(\nu\)</span> to infinity and go with a folded Gaussian. Or keep your regularization loose and go with a low-<span class="math inline">\(\nu\)</span> folded <span class="math inline">\(t\)</span> or even a folded Cauchy. And, of course, one could even go with a gamma.</p>
<p>Consider we have data <code>my_data</code> for which our primary variable of interest is <code>y</code>. Starting from preparing our <code>stanvars</code> values, here’s what the model code might look like.</p>
<div class="sourceCode" id="cb1687"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1687-1" data-line-number="1"><span class="co"># get ready for `stanvars`</span></a>
<a class="sourceLine" id="cb1687-2" data-line-number="2">mean_y &lt;-<span class="st"> </span><span class="kw">mean</span>(my_data<span class="op">$</span>y)</a>
<a class="sourceLine" id="cb1687-3" data-line-number="3">sd_y   &lt;-<span class="st"> </span><span class="kw">sd</span>(my_data<span class="op">$</span>y)</a>
<a class="sourceLine" id="cb1687-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1687-5" data-line-number="5">omega  &lt;-<span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb1687-6" data-line-number="6">sigma  &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y</a>
<a class="sourceLine" id="cb1687-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1687-8" data-line-number="8">s_r    &lt;-<span class="st"> </span><span class="kw">gamma_a_b_from_omega_sigma</span>(<span class="dt">mode =</span> omega, <span class="dt">sd =</span> sigma)</a>
<a class="sourceLine" id="cb1687-9" data-line-number="9"></a>
<a class="sourceLine" id="cb1687-10" data-line-number="10"><span class="co"># define `stanvars`</span></a>
<a class="sourceLine" id="cb1687-11" data-line-number="11">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1687-12" data-line-number="12"><span class="st">  </span><span class="kw">stanvar</span>(mean_y,    <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1687-13" data-line-number="13"><span class="st">  </span><span class="kw">stanvar</span>(sd_y,      <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1687-14" data-line-number="14"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>shape, <span class="dt">name =</span> <span class="st">&quot;alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1687-15" data-line-number="15"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>rate,  <span class="dt">name =</span> <span class="st">&quot;beta&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1687-16" data-line-number="16"><span class="st">  </span><span class="kw">stanvar</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">29</span>,      <span class="dt">name =</span> <span class="st">&quot;one_over_twentynine&quot;</span>)</a>
<a class="sourceLine" id="cb1687-17" data-line-number="17"></a>
<a class="sourceLine" id="cb1687-18" data-line-number="18"><span class="co"># fit the model</span></a>
<a class="sourceLine" id="cb1687-19" data-line-number="19">fit &lt;-</a>
<a class="sourceLine" id="cb1687-20" data-line-number="20"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1687-21" data-line-number="21">      <span class="dt">family =</span> student,</a>
<a class="sourceLine" id="cb1687-22" data-line-number="22">      <span class="kw">bf</span>(Longevity <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>CompanionNumber), </a>
<a class="sourceLine" id="cb1687-23" data-line-number="23">         sigma     <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>CompanionNumber)),</a>
<a class="sourceLine" id="cb1687-24" data-line-number="24">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="co"># grand means</span></a>
<a class="sourceLine" id="cb1687-25" data-line-number="25">                <span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1687-26" data-line-number="26">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="kw">log</span>(sd_y), <span class="dv">1</span>), <span class="dt">class =</span> Intercept, <span class="dt">dpar =</span> sigma),</a>
<a class="sourceLine" id="cb1687-27" data-line-number="27">                </a>
<a class="sourceLine" id="cb1687-28" data-line-number="28">                <span class="co"># the priors controlling the spread for our hierarchical deflections</span></a>
<a class="sourceLine" id="cb1687-29" data-line-number="29">                <span class="kw">prior</span>(<span class="kw">gamma</span>(alpha, beta), <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1687-30" data-line-number="30">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd, <span class="dt">dpar =</span> sigma),</a>
<a class="sourceLine" id="cb1687-31" data-line-number="31">                </a>
<a class="sourceLine" id="cb1687-32" data-line-number="32">                <span class="co"># don&#39;t forget our student-t nu</span></a>
<a class="sourceLine" id="cb1687-33" data-line-number="33">                <span class="kw">prior</span>(<span class="kw">exponential</span>(one_over_twentynine), <span class="dt">class =</span> nu)),</a>
<a class="sourceLine" id="cb1687-34" data-line-number="34">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<div id="example-contrast-of-means-with-different-variances." class="section level3">
<h3><span class="header-section-number">19.5.1</span> Example: Contrast of means with different variances.</h3>
<p>Let’s load and take a look at Kruschke’s simulated group data.</p>
<div class="sourceCode" id="cb1688"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1688-1" data-line-number="1">my_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data.R/NonhomogVarData.csv&quot;</span>)</a>
<a class="sourceLine" id="cb1688-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1688-3" data-line-number="3"><span class="kw">head</span>(my_data)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   Group     Y
##   &lt;chr&gt; &lt;dbl&gt;
## 1 A      97.8
## 2 A      99.9
## 3 A      92.4
## 4 A      96.9
## 5 A     101. 
## 6 A      80.7</code></pre>
<p>Here are the means and <span class="math inline">\(SD\)</span>s for each <code>Group</code>.</p>
<div class="sourceCode" id="cb1690"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1690-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1690-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(Group) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1690-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(Y),</a>
<a class="sourceLine" id="cb1690-4" data-line-number="4">            <span class="dt">sd   =</span> <span class="kw">sd</span>(Y))</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   Group  mean    sd
##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 A      97.0  8.00
## 2 B      99.0  1.00
## 3 C     102.   1.  
## 4 D     104.   8.00</code></pre>
<p>First we’ll fit the model with homogeneous variances. To keep things simple, here we’ll fit a conventional model following the form of our original <code>fit1</code>. Here are our <code>stanvars</code>.</p>
<div class="sourceCode" id="cb1692"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1692-1" data-line-number="1">(mean_y &lt;-<span class="st"> </span><span class="kw">mean</span>(my_data<span class="op">$</span>Y))</a></code></pre></div>
<pre><code>## [1] 100.5</code></pre>
<div class="sourceCode" id="cb1694"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1694-1" data-line-number="1">(sd_y &lt;-<span class="st"> </span><span class="kw">sd</span>(my_data<span class="op">$</span>Y))</a></code></pre></div>
<pre><code>## [1] 6.228965</code></pre>
<div class="sourceCode" id="cb1696"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1696-1" data-line-number="1">omega &lt;-<span class="st"> </span>sd_y <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb1696-2" data-line-number="2">sigma &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_y</a>
<a class="sourceLine" id="cb1696-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1696-4" data-line-number="4">(s_r  &lt;-<span class="st"> </span><span class="kw">gamma_a_b_from_omega_sigma</span>(<span class="dt">mode =</span> omega, <span class="dt">sd =</span> sigma))</a></code></pre></div>
<pre><code>## $shape
## [1] 1.283196
## 
## $rate
## [1] 0.09092861</code></pre>
<div class="sourceCode" id="cb1698"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1698-1" data-line-number="1"><span class="co"># define `stanvars`</span></a>
<a class="sourceLine" id="cb1698-2" data-line-number="2">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1698-3" data-line-number="3"><span class="st">  </span><span class="kw">stanvar</span>(mean_y,    <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1698-4" data-line-number="4"><span class="st">  </span><span class="kw">stanvar</span>(sd_y,      <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1698-5" data-line-number="5"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>shape, <span class="dt">name =</span> <span class="st">&quot;alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1698-6" data-line-number="6"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>rate,  <span class="dt">name =</span> <span class="st">&quot;beta&quot;</span>)</a></code></pre></div>
<p>Now fit the ANOVA-like homogeneous-variances model.</p>
<div class="sourceCode" id="cb1699"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1699-1" data-line-number="1">fit5 &lt;-</a>
<a class="sourceLine" id="cb1699-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1699-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1699-4" data-line-number="4">      Y <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>Group),</a>
<a class="sourceLine" id="cb1699-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1699-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">gamma</span>(alpha, beta), <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1699-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, sd_y), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1699-8" data-line-number="8">      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1699-9" data-line-number="9">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1699-10" data-line-number="10">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.999</span>),</a>
<a class="sourceLine" id="cb1699-11" data-line-number="11">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>Here’s the model summary.</p>
<div class="sourceCode" id="cb1700"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1700-1" data-line-number="1"><span class="kw">print</span>(fit5)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Y ~ 1 + (1 | Group) 
##    Data: my_data (Number of observations: 96) 
## Samples: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Group-Level Effects: 
## ~Group (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     4.96      3.56     1.46    14.67 1.00     1814     2546
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   100.47      3.19    94.43   106.42 1.00     2255     1885
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     5.76      0.43     4.99     6.68 1.00     5581     5873
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Let’s get ready to make our version of the top of Figure 19.7. First we wrangle.</p>
<div class="sourceCode" id="cb1702"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1702-1" data-line-number="1"><span class="co"># how many model-implied Gaussians would you like?</span></a>
<a class="sourceLine" id="cb1702-2" data-line-number="2">n_draws &lt;-<span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb1702-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1702-4" data-line-number="4">densities &lt;-</a>
<a class="sourceLine" id="cb1702-5" data-line-number="5"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-6" data-line-number="6"><span class="st">  </span><span class="kw">distinct</span>(Group) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-7" data-line-number="7"><span class="st">  </span><span class="kw">add_fitted_draws</span>(fit5, <span class="dt">n =</span> n_draws, <span class="dt">seed =</span> <span class="dv">19</span>, <span class="dt">dpar =</span> <span class="kw">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-8" data-line-number="8"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ll      =</span> <span class="kw">qnorm</span>(.<span class="dv">025</span>, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma),</a>
<a class="sourceLine" id="cb1702-9" data-line-number="9">         <span class="dt">ul      =</span> <span class="kw">qnorm</span>(.<span class="dv">975</span>, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-10" data-line-number="10"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Y       =</span> <span class="kw">map2</span>(ll, ul, seq, <span class="dt">length.out =</span> <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-11" data-line-number="11"><span class="st">  </span><span class="kw">unnest</span>(Y) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-12" data-line-number="12"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dnorm</span>(Y, mu, sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-13" data-line-number="13"><span class="st">  </span><span class="kw">group_by</span>(.draw) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1702-14" data-line-number="14"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> density <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(density))</a>
<a class="sourceLine" id="cb1702-15" data-line-number="15"></a>
<a class="sourceLine" id="cb1702-16" data-line-number="16"><span class="kw">glimpse</span>(densities)</a></code></pre></div>
<pre><code>## Observations: 8,000
## Variables: 12
## Groups: .draw [20]
## $ Group      &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;…
## $ .row       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
## $ .chain     &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .draw      &lt;int&gt; 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, …
## $ .value     &lt;dbl&gt; 99.42235, 99.42235, 99.42235, 99.42235, 99.42235, 99.42235, 99.42235, 99.42235…
## $ mu         &lt;dbl&gt; 99.42235, 99.42235, 99.42235, 99.42235, 99.42235, 99.42235, 99.42235, 99.42235…
## $ sigma      &lt;dbl&gt; 6.640072, 6.640072, 6.640072, 6.640072, 6.640072, 6.640072, 6.640072, 6.640072…
## $ ll         &lt;dbl&gt; 86.40805, 86.40805, 86.40805, 86.40805, 86.40805, 86.40805, 86.40805, 86.40805…
## $ ul         &lt;dbl&gt; 112.4367, 112.4367, 112.4367, 112.4367, 112.4367, 112.4367, 112.4367, 112.4367…
## $ Y          &lt;dbl&gt; 86.40805, 86.67096, 86.93388, 87.19679, 87.45971, 87.72262, 87.98554, 88.24846…
## $ density    &lt;dbl&gt; 0.1465288, 0.1582290, 0.1705958, 0.1836410, 0.1973740, 0.2118018, 0.2269281, 0…</code></pre>
<p>In our wrangling code, the main thing to notice is those last two lines. If you look closely to Kruschke’s Gaussians, you’ll notice they all have the same maximum height. Up to this point, ours haven’t. This has to do with technicalities on how densities are scaled. In brief, the wider densities have been shorter. So those last two lines scaled all the densities within the same group to the same metric. Otherwise the code was business as usual.</p>
<p>Anyway, here’s our version of the top panel of Figure 19.7.</p>
<div class="sourceCode" id="cb1704"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1704-1" data-line-number="1">densities <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1704-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Y, <span class="dt">y =</span> Group)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1704-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_ridgeline</span>(<span class="kw">aes</span>(<span class="dt">height =</span> density, <span class="dt">group =</span> <span class="kw">interaction</span>(Group, .draw)),</a>
<a class="sourceLine" id="cb1704-4" data-line-number="4">                 <span class="dt">fill =</span> <span class="ot">NA</span>, <span class="dt">color =</span> <span class="kw">adjustcolor</span>(<span class="st">&quot;grey50&quot;</span>, <span class="dt">alpha.f =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>),</a>
<a class="sourceLine" id="cb1704-5" data-line-number="5">                 <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">scale =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1704-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1704-7" data-line-number="7">              <span class="dt">height =</span> <span class="fl">.04</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1704-8" data-line-number="8"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">80</span>, <span class="dt">to =</span> <span class="dv">120</span>, <span class="dt">by =</span> <span class="dv">10</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1704-9" data-line-number="9"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">75</span><span class="op">:</span><span class="dv">125</span>,</a>
<a class="sourceLine" id="cb1704-10" data-line-number="10">                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.25</span>, <span class="fl">4.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1704-11" data-line-number="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Data with Posterior Predictive Distrib.&quot;</span>, </a>
<a class="sourceLine" id="cb1704-12" data-line-number="12">       <span class="dt">y     =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1704-13" data-line-number="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1704-14" data-line-number="14">        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-76-1.png" /><!-- --></p>
<p>Here are the difference distributions in the middle of Figure 19.7.</p>
<div class="sourceCode" id="cb1705"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1705-1" data-line-number="1">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit5)</a>
<a class="sourceLine" id="cb1705-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1705-3" data-line-number="3">differences &lt;-</a>
<a class="sourceLine" id="cb1705-4" data-line-number="4"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1705-5" data-line-number="5"><span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">D vs A</span><span class="st">`</span> =<span class="st"> `</span><span class="dt">r_Group[D,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_Group[A,Intercept]</span><span class="st">`</span>,</a>
<a class="sourceLine" id="cb1705-6" data-line-number="6">            <span class="st">`</span><span class="dt">C vs B</span><span class="st">`</span> =<span class="st"> `</span><span class="dt">r_Group[C,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_Group[B,Intercept]</span><span class="st">`</span>)</a>
<a class="sourceLine" id="cb1705-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1705-8" data-line-number="8">differences <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1705-9" data-line-number="9"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1705-10" data-line-number="10"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;D vs A&quot;</span>, <span class="st">&quot;C vs B&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1705-11" data-line-number="11"><span class="st">  </span></a>
<a class="sourceLine" id="cb1705-12" data-line-number="12"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1705-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1705-14" data-line-number="14">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1705-15" data-line-number="15"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1705-16" data-line-number="16">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1705-17" data-line-number="17"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1705-18" data-line-number="18"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Difference&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1705-19" data-line-number="19"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-77-1.png" /><!-- --></p>
<p>Now here are the effect sizes at the bottom of the figure.</p>
<div class="sourceCode" id="cb1706"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1706-1" data-line-number="1">differences <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1706-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate_all</span>(<span class="dt">.funs =</span> <span class="op">~</span>. <span class="op">/</span><span class="st"> </span>post<span class="op">$</span>sigma) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1706-3" data-line-number="3"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1706-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;D vs A&quot;</span>, <span class="st">&quot;C vs B&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1706-5" data-line-number="5"><span class="st">  </span></a>
<a class="sourceLine" id="cb1706-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1706-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1706-8" data-line-number="8">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1706-9" data-line-number="9"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1706-10" data-line-number="10">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1706-11" data-line-number="11"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1706-12" data-line-number="12"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Effect Size&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1706-13" data-line-number="13"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-78-1.png" /><!-- --></p>
<p>Oh and remember, if you’d like to get all the possible contrasts in bulk, <strong>tidybayes</strong> has got your back.</p>
<div class="sourceCode" id="cb1707"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1707-1" data-line-number="1">fit5 <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1707-2" data-line-number="2"><span class="st">  </span><span class="kw">spread_draws</span>(r_Group[Group,]) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1707-3" data-line-number="3"><span class="st">  </span><span class="kw">compare_levels</span>(r_Group, <span class="dt">by =</span> Group) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1707-4" data-line-number="4"><span class="st">  </span><span class="co"># these next two lines allow us to reorder the contrasts along the y</span></a>
<a class="sourceLine" id="cb1707-5" data-line-number="5"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1707-6" data-line-number="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Group =</span> <span class="kw">reorder</span>(Group, r_Group)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1707-7" data-line-number="7"><span class="st">  </span></a>
<a class="sourceLine" id="cb1707-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> r_Group, <span class="dt">y =</span> Group)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1707-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1707-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1707-11" data-line-number="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Contrast&quot;</span>,</a>
<a class="sourceLine" id="cb1707-12" data-line-number="12">       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1707-13" data-line-number="13"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.33</span>, <span class="fl">6.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1707-14" data-line-number="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1707-15" data-line-number="15">        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-79-1.png" /><!-- --></p>
<p>But to get back on track, here are the <code>stanvars</code> for the robust hierarchical variances model.</p>
<div class="sourceCode" id="cb1708"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1708-1" data-line-number="1">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1708-2" data-line-number="2"><span class="st">  </span><span class="kw">stanvar</span>(mean_y,    <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1708-3" data-line-number="3"><span class="st">  </span><span class="kw">stanvar</span>(sd_y,      <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1708-4" data-line-number="4"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>shape, <span class="dt">name =</span> <span class="st">&quot;alpha&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1708-5" data-line-number="5"><span class="st">  </span><span class="kw">stanvar</span>(s_r<span class="op">$</span>rate,  <span class="dt">name =</span> <span class="st">&quot;beta&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1708-6" data-line-number="6"><span class="st">  </span><span class="kw">stanvar</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">29</span>,      <span class="dt">name =</span> <span class="st">&quot;one_over_twentynine&quot;</span>)</a></code></pre></div>
<p>Now fit that robust better-than-ANOVA model.</p>
<div class="sourceCode" id="cb1709"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1709-1" data-line-number="1">fit6 &lt;-</a>
<a class="sourceLine" id="cb1709-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1709-3" data-line-number="3">      <span class="dt">family =</span> student,</a>
<a class="sourceLine" id="cb1709-4" data-line-number="4">      <span class="kw">bf</span>(Y     <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>Group), </a>
<a class="sourceLine" id="cb1709-5" data-line-number="5">         sigma <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>Group)),</a>
<a class="sourceLine" id="cb1709-6" data-line-number="6">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="co"># grand means</span></a>
<a class="sourceLine" id="cb1709-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">10</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1709-8" data-line-number="8">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="kw">log</span>(sd_y), <span class="dv">1</span>), <span class="dt">class =</span> Intercept, <span class="dt">dpar =</span> sigma),</a>
<a class="sourceLine" id="cb1709-9" data-line-number="9">                </a>
<a class="sourceLine" id="cb1709-10" data-line-number="10">                <span class="co"># the priors controlling the spread for our hierarchical deflections</span></a>
<a class="sourceLine" id="cb1709-11" data-line-number="11">                <span class="kw">prior</span>(<span class="kw">gamma</span>(alpha, beta), <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb1709-12" data-line-number="12">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd, <span class="dt">dpar =</span> sigma),</a>
<a class="sourceLine" id="cb1709-13" data-line-number="13">                </a>
<a class="sourceLine" id="cb1709-14" data-line-number="14">                <span class="co"># don&#39;t forget our student-t nu</span></a>
<a class="sourceLine" id="cb1709-15" data-line-number="15">                <span class="kw">prior</span>(<span class="kw">exponential</span>(one_over_twentynine), <span class="dt">class =</span> nu)),</a>
<a class="sourceLine" id="cb1709-16" data-line-number="16">      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1709-17" data-line-number="17">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1709-18" data-line-number="18">      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>,</a>
<a class="sourceLine" id="cb1709-19" data-line-number="19">                     <span class="dt">max_treedepth =</span> <span class="dv">12</span>),</a>
<a class="sourceLine" id="cb1709-20" data-line-number="20">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>The chains look good.</p>
<div class="sourceCode" id="cb1710"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1710-1" data-line-number="1"><span class="kw">plot</span>(fit6)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-81-1.png" /><!-- --></p>
<p>Here’s the summary.</p>
<div class="sourceCode" id="cb1711"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1711-1" data-line-number="1"><span class="kw">print</span>(fit6)</a></code></pre></div>
<pre><code>##  Family: student 
##   Links: mu = identity; sigma = log; nu = identity 
## Formula: Y ~ 1 + (1 | Group) 
##          sigma ~ 1 + (1 | Group)
##    Data: my_data (Number of observations: 96) 
## Samples: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Group-Level Effects: 
## ~Group (Number of levels: 4) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           4.55      3.14     1.32    13.02 1.00     3148     4776
## sd(sigma_Intercept)     1.23      0.40     0.65     2.18 1.00     4350     5529
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept         100.48      2.73    94.73   105.97 1.00     4094     4128
## sigma_Intercept     1.23      0.54     0.21     2.37 1.00     4568     5951
## 
## Family Specific Parameters: 
##    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## nu    32.67     28.51     4.65   109.84 1.00    10110     8384
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Let’s get ready to make our version of the top of Figure 19.7. First we wrangle.</p>
<div class="sourceCode" id="cb1713"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1713-1" data-line-number="1">densities &lt;-</a>
<a class="sourceLine" id="cb1713-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-3" data-line-number="3"><span class="st">  </span><span class="kw">distinct</span>(Group) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-4" data-line-number="4"><span class="st">  </span><span class="kw">add_fitted_draws</span>(fit6, <span class="dt">n =</span> n_draws, <span class="dt">seed =</span> <span class="dv">19</span>, <span class="dt">dpar =</span> <span class="kw">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma&quot;</span>, <span class="st">&quot;nu&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ll      =</span> <span class="kw">qt</span>(.<span class="dv">025</span>, <span class="dt">df =</span> nu),</a>
<a class="sourceLine" id="cb1713-6" data-line-number="6">         <span class="dt">ul      =</span> <span class="kw">qt</span>(.<span class="dv">975</span>, <span class="dt">df =</span> nu)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Y       =</span> <span class="kw">map2</span>(ll, ul, seq, <span class="dt">length.out =</span> <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-8" data-line-number="8"><span class="st">  </span><span class="kw">unnest</span>(Y) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1713-9" data-line-number="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dt</span>(Y, nu)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-10" data-line-number="10"><span class="st">  </span><span class="co"># notice the conversion</span></a>
<a class="sourceLine" id="cb1713-11" data-line-number="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Y =</span> mu <span class="op">+</span><span class="st"> </span>Y <span class="op">*</span><span class="st"> </span>sigma) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-12" data-line-number="12"><span class="st">  </span><span class="kw">group_by</span>(.draw) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1713-13" data-line-number="13"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> density <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(density))</a>
<a class="sourceLine" id="cb1713-14" data-line-number="14"></a>
<a class="sourceLine" id="cb1713-15" data-line-number="15"><span class="kw">glimpse</span>(densities)</a></code></pre></div>
<pre><code>## Observations: 8,000
## Variables: 13
## Groups: .draw [20]
## $ Group      &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;…
## $ .row       &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …
## $ .chain     &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .iteration &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ .draw      &lt;int&gt; 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, 1115, …
## $ .value     &lt;dbl&gt; 97.33906, 97.33906, 97.33906, 97.33906, 97.33906, 97.33906, 97.33906, 97.33906…
## $ mu         &lt;dbl&gt; 97.33906, 97.33906, 97.33906, 97.33906, 97.33906, 97.33906, 97.33906, 97.33906…
## $ sigma      &lt;dbl&gt; 1.412658, 1.412658, 1.412658, 1.412658, 1.412658, 1.412658, 1.412658, 1.412658…
## $ nu         &lt;dbl&gt; 24.33915, 24.33915, 24.33915, 24.33915, 24.33915, 24.33915, 24.33915, 24.33915…
## $ ll         &lt;dbl&gt; -2.062378, -2.062378, -2.062378, -2.062378, -2.062378, -2.062378, -2.062378, -…
## $ ul         &lt;dbl&gt; 2.062378, 2.062378, 2.062378, 2.062378, 2.062378, 2.062378, 2.062378, 2.062378…
## $ Y          &lt;dbl&gt; 94.42563, 94.48449, 94.54334, 94.60220, 94.66106, 94.71991, 94.77877, 94.83763…
## $ density    &lt;dbl&gt; 0.1299849, 0.1401936, 0.1510374, 0.1625369, 0.1747115, 0.1875784, 0.2011531, 0…</code></pre>
<p>If you look closely at our code, above, you’ll note switching from the Gaussian to the Student <span class="math inline">\(t\)</span> required changes in our flow. Most obviously, we switched from <code>qnorm()</code> and <code>dnorm()</code> to <code>qt()</code> and <code>dt()</code>, respectively. The base <strong>R</strong> Student <span class="math inline">\(t\)</span> functions don’t take arguments for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. Rather, they’re presumed to be 0 and 1, respectively. That means that for our first three <code>mutate()</code> functions, the computations were all based on the standard Student <span class="math inline">\(t\)</span>, with only the <span class="math inline">\(\nu\)</span> parameter varying according to the posterior. The way we corrected for that was with the fourth <code>mutate()</code>.</p>
<p>Now we’re ready to make our version of the top panel of Figure 19.7.</p>
<div class="sourceCode" id="cb1715"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1715-1" data-line-number="1">densities <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1715-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Y, <span class="dt">y =</span> Group)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1715-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_ridgeline</span>(<span class="kw">aes</span>(<span class="dt">height =</span> density, <span class="dt">group =</span> <span class="kw">interaction</span>(Group, .draw)),</a>
<a class="sourceLine" id="cb1715-4" data-line-number="4">                 <span class="dt">fill =</span> <span class="ot">NA</span>, <span class="dt">color =</span> <span class="kw">adjustcolor</span>(<span class="st">&quot;grey50&quot;</span>, <span class="dt">alpha.f =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>),</a>
<a class="sourceLine" id="cb1715-5" data-line-number="5">                 <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">scale =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1715-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1715-7" data-line-number="7">              <span class="dt">height =</span> <span class="fl">.04</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1715-8" data-line-number="8"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">80</span>, <span class="dt">to =</span> <span class="dv">120</span>, <span class="dt">by =</span> <span class="dv">10</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1715-9" data-line-number="9"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">75</span><span class="op">:</span><span class="dv">125</span>,</a>
<a class="sourceLine" id="cb1715-10" data-line-number="10">                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.25</span>, <span class="fl">4.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1715-11" data-line-number="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Data with Posterior Predictive Distrib.&quot;</span>, </a>
<a class="sourceLine" id="cb1715-12" data-line-number="12">       <span class="dt">y     =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1715-13" data-line-number="13"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb1715-14" data-line-number="14">        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-84-1.png" /><!-- --></p>
<p>Here are the difference distributions in the middle of Figure 19.8.</p>
<div class="sourceCode" id="cb1716"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1716-1" data-line-number="1">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit6)</a>
<a class="sourceLine" id="cb1716-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1716-3" data-line-number="3">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1716-4" data-line-number="4"><span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">D vs A</span><span class="st">`</span> =<span class="st"> `</span><span class="dt">r_Group[D,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_Group[A,Intercept]</span><span class="st">`</span>,</a>
<a class="sourceLine" id="cb1716-5" data-line-number="5">            <span class="st">`</span><span class="dt">C vs B</span><span class="st">`</span> =<span class="st"> `</span><span class="dt">r_Group[C,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_Group[B,Intercept]</span><span class="st">`</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1716-6" data-line-number="6"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1716-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;D vs A&quot;</span>, <span class="st">&quot;C vs B&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1716-8" data-line-number="8"><span class="st">  </span></a>
<a class="sourceLine" id="cb1716-9" data-line-number="9"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1716-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1716-11" data-line-number="11">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1716-12" data-line-number="12"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1716-13" data-line-number="13">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1716-14" data-line-number="14"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1716-15" data-line-number="15"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Difference&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1716-16" data-line-number="16"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-85-1.png" /><!-- --></p>
<p>And here are the corresponding effect sizes at the bottom of the Figure 19.8.</p>
<div class="sourceCode" id="cb1717"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1717-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1717-2" data-line-number="2"><span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">D vs A</span><span class="st">`</span> =<span class="st"> </span>(<span class="st">`</span><span class="dt">r_Group[D,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_Group[A,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1717-3" data-line-number="3"><span class="st">              </span><span class="kw">exp</span>((b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[D,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> </span>b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[A,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>),</a>
<a class="sourceLine" id="cb1717-4" data-line-number="4">            <span class="st">`</span><span class="dt">C vs B</span><span class="st">`</span> =<span class="st"> </span>(<span class="st">`</span><span class="dt">r_Group[C,Intercept]</span><span class="st">`</span> <span class="op">-</span><span class="st"> `</span><span class="dt">r_Group[B,Intercept]</span><span class="st">`</span>) <span class="op">/</span></a>
<a class="sourceLine" id="cb1717-5" data-line-number="5"><span class="st">              </span><span class="kw">exp</span>((b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[C,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> </span>b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[B,Intercept]</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1717-6" data-line-number="6"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1717-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;D vs A&quot;</span>, <span class="st">&quot;C vs B&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1717-8" data-line-number="8"><span class="st">  </span></a>
<a class="sourceLine" id="cb1717-9" data-line-number="9"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1717-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1717-11" data-line-number="11">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1717-12" data-line-number="12"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1717-13" data-line-number="13">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1717-14" data-line-number="14"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1717-15" data-line-number="15"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Effect Size&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1717-16" data-line-number="16"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-86-1.png" /><!-- --></p>
<p>Notice that because (a) the sigma parameters were heterogeneous and (b) they were estimated on the log scale, we had to do quite a bit more data processing before they effect size estimates were ready.</p>
<p>“Finally, because each group has its own estimated scale (i.e., <span class="math inline">\(\sigma_j\)</span>), we can investigate differences in scales across groups” (p. 578). That’s not a bad idea. Even though Kruschke didn’t show this in the text, we may as well give it a go.</p>
<div class="sourceCode" id="cb1718"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1718-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1718-2" data-line-number="2"><span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">D vs A</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[D,Intercept]</span><span class="st">`</span>) <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[A,Intercept]</span><span class="st">`</span>),</a>
<a class="sourceLine" id="cb1718-3" data-line-number="3">            <span class="st">`</span><span class="dt">C vs B</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[C,Intercept]</span><span class="st">`</span>) <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[B,Intercept]</span><span class="st">`</span>),</a>
<a class="sourceLine" id="cb1718-4" data-line-number="4">            <span class="st">`</span><span class="dt">D vs C</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[D,Intercept]</span><span class="st">`</span>) <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[C,Intercept]</span><span class="st">`</span>),</a>
<a class="sourceLine" id="cb1718-5" data-line-number="5">            <span class="st">`</span><span class="dt">B vs A</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[B,Intercept]</span><span class="st">`</span>) <span class="op">-</span><span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> `</span><span class="dt">r_Group__sigma[A,Intercept]</span><span class="st">`</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1718-6" data-line-number="6"><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1718-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;D vs A&quot;</span>, <span class="st">&quot;C vs B&quot;</span>, <span class="st">&quot;D vs C&quot;</span>, <span class="st">&quot;B vs A&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1718-8" data-line-number="8"><span class="st">  </span></a>
<a class="sourceLine" id="cb1718-9" data-line-number="9"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1718-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1718-11" data-line-number="11">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1718-12" data-line-number="12"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1718-13" data-line-number="13">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1718-14" data-line-number="14"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1718-15" data-line-number="15"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Differences in &quot;</span>, sigma))) <span class="op">+</span></a>
<a class="sourceLine" id="cb1718-16" data-line-number="16"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-87-1.png" /><!-- --></p>
<p>For more on models including a hierarchical structure on both the mean and scale structures, check out <a href="https://twitter.com/wdonald_1985">Donald Williams</a> and colleagues’ work on what they call Mixed Effect Location and Scale Models (MELSM; e.g., <a href="https://psyarxiv.com/4kfjp/">here</a> or <a href="https://link.springer.com/article/10.3758/s13428-019-01255-9">here</a>). They’re quite handy and I’ve begun using them in my applied work (e.g., <a href="https://osf.io/vekpf/">here</a>).</p>
</div>
</div>
<div id="exercises-walk-out-an-effect-size" class="section level2">
<h2><span class="header-section-number">19.6</span> <del>Exercises</del> Walk out an effect size</h2>
<p>We computed a lot of effect sizes in this chapter. They were all standardized mean differences. Cohen (<a href="https://www.taylorfrancis.com/books/9780203771587">1988</a>) discussed these kinds of effect sizes in this way:</p>
<blockquote>
<p>We need a “pure” number, one free of our original measurement unit, with which to index what can be alternately called the degree of departure from the null hypothesis of the alternate hypothesis, or the ES (effect size) we wish to detect. This is accomplished by standardizing the raw effect size as expressed in the measurement unit of the dependent variable by dividing it by the (common) standard deviation of the measures in their respective populations, the latter also in the original measurement unit. (p. 20)</p>
</blockquote>
<p>Though Cohen framed his discussion in terms of null-hypothesis significance testing, we can just as easily apply it to our Bayesian modeling framework. The main thing is we can use his definitions form above to define a particular kind of effect size—the standardized mean difference between two groups. This is commonly referred to as a Cohen’s <span class="math inline">\(d\)</span>, which follows the formula</p>
<p><span class="math display">\[d = \frac{\bar y_A - \bar y_B}{s_y},\]</span></p>
<p>where the unstandardized means of the variable of interest <span class="math inline">\(y\)</span> are compared between two groups, A and B. From the raw data, we compute their two means, <span class="math inline">\(\bar y_A\)</span> and <span class="math inline">\(\bar y_B\)</span>, and divide their difference by the common (i.e. pooled) standard deviation <span class="math inline">\(s_y\)</span>. As is the typical case, the empirically-derived means and standard deviations are stand-ins (i.e., estimates) of the population parameters. If we’re willing to ignore uncertainty, we can do this all by hand.</p>
<p>Let’s walk this out with the fruit-fly data from section 19.3.2.</p>
<div class="sourceCode" id="cb1719"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1719-1" data-line-number="1">my_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data.R/FruitflyDataReduced.csv&quot;</span>)</a></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   Longevity = col_double(),
##   CompanionNumber = col_character(),
##   Thorax = col_double()
## )</code></pre>
<div class="sourceCode" id="cb1721"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1721-1" data-line-number="1"><span class="kw">glimpse</span>(my_data)</a></code></pre></div>
<pre><code>## Observations: 125
## Variables: 3
## $ Longevity       &lt;dbl&gt; 35, 37, 49, 46, 63, 39, 46, 56, 63, 65, 56, 65, 70, 63, 65, 70, 77, 81, 8…
## $ CompanionNumber &lt;chr&gt; &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnant8&quot;, &quot;Pregnan…
## $ Thorax          &lt;dbl&gt; 0.64, 0.68, 0.68, 0.72, 0.72, 0.76, 0.76, 0.76, 0.76, 0.76, 0.80, 0.80, 0…</code></pre>
<p>Recall we have five groups indexed by <code>CompanionNumber</code>, each with <span class="math inline">\(n = 25\)</span>.</p>
<div class="sourceCode" id="cb1723"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1723-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1723-2" data-line-number="2"><span class="st">  </span><span class="kw">count</span>(CompanionNumber)</a></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   CompanionNumber     n
##   &lt;chr&gt;           &lt;int&gt;
## 1 None0              25
## 2 Pregnant1          25
## 3 Pregnant8          25
## 4 Virgin1            25
## 5 Virgin8            25</code></pre>
<p>Let’s focus on just two groups, the male fruit flies for which individual males were supplied access to one or with virgin female fruit flies per day. In the data, these are <code>CompanionNumber == Virgin1</code> and <code>CompanionNumber == Virgin8</code>, respectively. Here’s a look at their mean <code>Longevity</code> values.</p>
<div class="sourceCode" id="cb1725"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1725-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1725-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(CompanionNumber, <span class="st">&quot;Virgin&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1725-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(CompanionNumber) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1725-4" data-line-number="4"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(Longevity))</a></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   CompanionNumber  mean
##   &lt;chr&gt;           &lt;dbl&gt;
## 1 Virgin1          56.8
## 2 Virgin8          38.7</code></pre>
<p>If we’re willing to treat the males in the <code>Virgin1</code> group as group “a” and those in the <code>Virgin8</code> group as group “b”, we can save those mean values like so.</p>
<div class="sourceCode" id="cb1727"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1727-1" data-line-number="1">y_bar_a &lt;-<span class="st"> </span><span class="fl">56.76</span></a>
<a class="sourceLine" id="cb1727-2" data-line-number="2">y_bar_b &lt;-<span class="st"> </span><span class="fl">38.72</span></a></code></pre></div>
<p>Now we’ll compute their pooled standard deviation.</p>
<div class="sourceCode" id="cb1728"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1728-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1728-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(CompanionNumber, <span class="st">&quot;Virgin&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1728-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">s =</span> <span class="kw">sd</span>(Longevity))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##       s
##   &lt;dbl&gt;
## 1  16.2</code></pre>
<p>Save that value.</p>
<div class="sourceCode" id="cb1730"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1730-1" data-line-number="1">s_y &lt;-<span class="st"> </span><span class="fl">16.24533</span></a></code></pre></div>
<p>Now computing Cohen’s <span class="math inline">\(d\)</span> is just simple arithmetic.</p>
<div class="sourceCode" id="cb1731"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1731-1" data-line-number="1">(y_bar_a <span class="op">-</span><span class="st"> </span>y_bar_b) <span class="op">/</span><span class="st"> </span>s_y</a></code></pre></div>
<pre><code>## [1] 1.110473</code></pre>
<p>Though I’m not up on contemporary standards in fruit fly research, a Cohen’s <span class="math inline">\(d\)</span> of that size would be considered [conspicuously] big in most areas of my field (psychology). If we’d like to compute the <span class="math inline">\(d\)</span> estimates for any other combination of experimental conditions, we’d just follow the corresponding arithmetic.</p>
<p>As I hinted at earlier, the problem with this approach is it ignores uncertainty. Frequentists use various formulas to express this in terms of 95% confidence intervals. Our approach will be to express it with the posterior distribution of a Bayesian model. We’ve already accomplished this with our <code>fit1</code> from above. Here we’ll use three other approaches.</p>
<p>Instead of the Bayesian hierarchical alternative to the frequentist ANOVA, we can use a single-level model where we predict a metric variable with separate intercepts for the two levels of <code>CompanionNumber</code>. First, we subset the data and define our <code>stanvars</code>.</p>
<div class="sourceCode" id="cb1733"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1733-1" data-line-number="1">my_data &lt;-</a>
<a class="sourceLine" id="cb1733-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1733-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(CompanionNumber, <span class="st">&quot;Virgin&quot;</span>))</a>
<a class="sourceLine" id="cb1733-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1733-5" data-line-number="5">mean_y &lt;-<span class="st"> </span>(y_bar_a <span class="op">+</span><span class="st"> </span>y_bar_b) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb1733-6" data-line-number="6"></a>
<a class="sourceLine" id="cb1733-7" data-line-number="7">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb1733-8" data-line-number="8"><span class="st">  </span><span class="kw">stanvar</span>(mean_y, <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1733-9" data-line-number="9"><span class="st">  </span><span class="kw">stanvar</span>(s_y,    <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>)</a></code></pre></div>
<p>Fit the model with <code>brm()</code>.</p>
<div class="sourceCode" id="cb1734"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1734-1" data-line-number="1">fit7 &lt;-</a>
<a class="sourceLine" id="cb1734-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1734-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1734-4" data-line-number="4">      Longevity <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>CompanionNumber,</a>
<a class="sourceLine" id="cb1734-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1734-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, sd_y), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1734-7" data-line-number="7">      <span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1734-8" data-line-number="8">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1734-9" data-line-number="9">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<p>Check the summary.</p>
<div class="sourceCode" id="cb1735"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1735-1" data-line-number="1"><span class="kw">print</span>(fit7)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Longevity ~ 0 + CompanionNumber 
##    Data: my_data (Number of observations: 50) 
## Samples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## CompanionNumberVirgin1    56.74      2.87    51.12    62.41 1.00     6734     5909
## CompanionNumberVirgin8    38.70      2.81    33.14    44.20 1.00     7202     5730
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    13.85      1.45    11.38    17.07 1.00     6368     5482
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Extract the posterior draws.</p>
<div class="sourceCode" id="cb1737"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1737-1" data-line-number="1">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit7)</a></code></pre></div>
<p>Here we’ll plot the three dimensions of the posterior, each with the corresponding value from the Cohen’s <span class="math inline">\(d\)</span> formula marked off as a vertical line in the foreground.</p>
<div class="sourceCode" id="cb1738"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1738-1" data-line-number="1">lines &lt;-</a>
<a class="sourceLine" id="cb1738-2" data-line-number="2"><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">name  =</span> <span class="kw">c</span>(<span class="st">&quot;b_CompanionNumberVirgin1&quot;</span>, <span class="st">&quot;b_CompanionNumberVirgin8&quot;</span>, <span class="st">&quot;sigma&quot;</span>),</a>
<a class="sourceLine" id="cb1738-3" data-line-number="3">         <span class="dt">value =</span> <span class="kw">c</span>(y_bar_a, y_bar_b, s_y))</a>
<a class="sourceLine" id="cb1738-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1738-5" data-line-number="5">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1738-6" data-line-number="6"><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>lp__) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1738-7" data-line-number="7"><span class="st">  </span></a>
<a class="sourceLine" id="cb1738-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1738-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1738-10" data-line-number="10">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1738-11" data-line-number="11"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1738-12" data-line-number="12">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1738-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">data =</span> lines,</a>
<a class="sourceLine" id="cb1738-14" data-line-number="14">             <span class="kw">aes</span>(<span class="dt">xintercept =</span> value),</a>
<a class="sourceLine" id="cb1738-15" data-line-number="15">             <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1738-16" data-line-number="16"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1738-17" data-line-number="17"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;posterior&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1738-18" data-line-number="18"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>name, <span class="dt">scales =</span> <span class="st">&quot;free_x&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-98-1.png" /><!-- --></p>
<p>The model did a great job capturing the group means. Notice how the posterior <code>sigma</code> is a bit lower than the value <span class="math inline">\(s_y\)</span>. This is because <span class="math inline">\(\sigma\)</span> in the model is conditioned on the mean. Because we have two means, one for each group, that has ‘explained some of the variation’ in the criterion variable <code>Longevity</code>. Thus, our posterior for <span class="math inline">\(\sigma\)</span> might be more fully expressed as <span class="math inline">\(\sigma | \text{CompanionNumber}\)</span>. If we would like to compute our Cohen’s <span class="math inline">\(d\)</span> using the posterior iterations from <code>fit7</code>, we’d execute something like this.</p>
<div class="sourceCode" id="cb1739"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1739-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1739-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d =</span> (b_CompanionNumberVirgin1 <span class="op">-</span><span class="st"> </span>b_CompanionNumberVirgin8) <span class="op">/</span><span class="st"> </span>s_y) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1739-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb1739-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> d)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1739-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1739-6" data-line-number="6">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1739-7" data-line-number="7"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1739-8" data-line-number="8">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1739-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> (y_bar_a <span class="op">-</span><span class="st"> </span>y_bar_b) <span class="op">/</span><span class="st"> </span>s_y,</a>
<a class="sourceLine" id="cb1739-10" data-line-number="10">             <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1739-11" data-line-number="11"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1739-12" data-line-number="12"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Cohen&#39;s &quot;</span>, <span class="kw">italic</span>(d), <span class="st">&quot; expressed as a posterior&quot;</span>)))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-99-1.png" /><!-- --></p>
<p>Similar to the previous plots, this time we superimposed the density with the estimate for <span class="math inline">\(d\)</span> we computed above, <code>(y_bar_a - y_bar_b) / s_y</code>. Happily, the hand-calculated estimate coheres nicely with the central tendency of our posterior distribution. But now we get a full measure of uncertainty. Notice how wide those 95% HDIs are. Hopefully this isn’t a surprise given our noncommittal priors and only <span class="math inline">\(n = 25\)</span> for both groups. There’s a lot of uncertainty in that posterior.</p>
<p>A second way we might use a single-level model to compute a Cohen’s <span class="math inline">\(d\)</span> effect size is using a dummy variable. We’ll convert our nominal variable <code>CompanionNumber</code> into a binary variable <code>Virgin1</code> for which 1 corresponds to <code>CompanionNumber == Virgin1</code> and 0 corresponds to <code>CompanionNumber == Virgin8</code>. Compute the dummy.</p>
<div class="sourceCode" id="cb1740"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1740-1" data-line-number="1">my_data &lt;-</a>
<a class="sourceLine" id="cb1740-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1740-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Virgin1 =</span> <span class="kw">if_else</span>(CompanionNumber <span class="op">==</span><span class="st"> &quot;Virgin1&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a></code></pre></div>
<p>Now fit the dummy-predictor model with <code>brm()</code>.</p>
<div class="sourceCode" id="cb1741"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1741-1" data-line-number="1">fit8 &lt;-</a>
<a class="sourceLine" id="cb1741-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1741-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1741-4" data-line-number="4">      Longevity <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Virgin1,</a>
<a class="sourceLine" id="cb1741-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1741-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1741-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, sd_y), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1741-8" data-line-number="8">      <span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1741-9" data-line-number="9">      <span class="dt">seed =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb1741-10" data-line-number="10">      <span class="dt">stanvars =</span> stanvars)</a></code></pre></div>
<div class="sourceCode" id="cb1742"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1742-1" data-line-number="1"><span class="kw">print</span>(fit8)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Longevity ~ 1 + Virgin1 
##    Data: my_data (Number of observations: 50) 
## Samples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    38.73      2.79    33.19    44.27 1.00     7735     5541
## Virgin1      17.97      3.94    10.19    25.59 1.00     7058     5512
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    13.85      1.47    11.32    17.08 1.00     6433     5111
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>With this parameterization, our posterior for <code>Intercept</code> is the same, within simulation variation, as <code>CompanionNumberVirgin8</code> from <code>fit7</code>. The posterior for <code>sigma</code> is about the same for both models, too. But focus on <code>Virgin1</code>. This is the unstandardized mean difference, what we called <span class="math inline">\(\bar y_A - \bar y_B\)</span> in our formula for Cohen’s <span class="math inline">\(d\)</span>. Here’s a look at its posterior distribution with its empirical estimate superimposed with a vertical line.</p>
<div class="sourceCode" id="cb1744"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1744-1" data-line-number="1">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit8)</a>
<a class="sourceLine" id="cb1744-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1744-3" data-line-number="3">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1744-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> b_Virgin1)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1744-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1744-6" data-line-number="6">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1744-7" data-line-number="7"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1744-8" data-line-number="8">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1744-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> y_bar_a <span class="op">-</span><span class="st"> </span>y_bar_b,</a>
<a class="sourceLine" id="cb1744-10" data-line-number="10">             <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1744-11" data-line-number="11"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1744-12" data-line-number="12"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Unstandardized mean difference&quot;</span>)</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-102-1.png" /><!-- --></p>
<p>Here’s how to standardize that unstandardized effect size into a Cohen’s-<span class="math inline">\(d\)</span> metric.</p>
<div class="sourceCode" id="cb1745"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1745-1" data-line-number="1">post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1745-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d =</span> b_Virgin1 <span class="op">/</span><span class="st"> </span>s_y) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1745-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb1745-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> d)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1745-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1745-6" data-line-number="6">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1745-7" data-line-number="7"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1745-8" data-line-number="8">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1745-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> (y_bar_a <span class="op">-</span><span class="st"> </span>y_bar_b) <span class="op">/</span><span class="st"> </span>s_y,</a>
<a class="sourceLine" id="cb1745-10" data-line-number="10">             <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1745-11" data-line-number="11"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1745-12" data-line-number="12"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Cohen&#39;s &quot;</span>, <span class="kw">italic</span>(d), <span class="st">&quot; expressed as a posterior&quot;</span>)))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-103-1.png" /><!-- --></p>
<p>Let’s work this one more way. By simple algebra, a standardized mean difference is the same as the difference between two standardized means. If we standardize the criterion <code>Longevity</code> before fitting the model and continue using the dummy variable approach, the <code>Virgin1</code> posterior will be the same as a Cohen’s <span class="math inline">\(d\)</span>.</p>
<p>Standardize the criterion.</p>
<div class="sourceCode" id="cb1746"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1746-1" data-line-number="1">my_data &lt;-</a>
<a class="sourceLine" id="cb1746-2" data-line-number="2"><span class="st">  </span>my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1746-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Longevity_s =</span> (Longevity <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(Longevity)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(Longevity))</a></code></pre></div>
<p>Because our criterion in a standardized metric, we no longer need our <code>stanvars</code>.</p>
<div class="sourceCode" id="cb1747"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1747-1" data-line-number="1">fit9 &lt;-</a>
<a class="sourceLine" id="cb1747-2" data-line-number="2"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> my_data,</a>
<a class="sourceLine" id="cb1747-3" data-line-number="3">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb1747-4" data-line-number="4">      Longevity_s <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>Virgin1,</a>
<a class="sourceLine" id="cb1747-5" data-line-number="5">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb1747-6" data-line-number="6">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">5</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb1747-7" data-line-number="7">                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb1747-8" data-line-number="8">      <span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb1747-9" data-line-number="9">      <span class="dt">seed =</span> <span class="dv">19</span>)</a></code></pre></div>
<p>Behold our out-of-the-box Bayesian Cohen’s <span class="math inline">\(d\)</span>.</p>
<div class="sourceCode" id="cb1748"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1748-1" data-line-number="1"><span class="co"># no transformation necessary</span></a>
<a class="sourceLine" id="cb1748-2" data-line-number="2"><span class="kw">posterior_samples</span>(fit9) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1748-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb1748-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> b_Virgin1)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1748-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb1748-6" data-line-number="6">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1748-7" data-line-number="7"><span class="st">  </span><span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), </a>
<a class="sourceLine" id="cb1748-8" data-line-number="8">                      <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1748-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> (y_bar_a <span class="op">-</span><span class="st"> </span>y_bar_b) <span class="op">/</span><span class="st"> </span>s_y,</a>
<a class="sourceLine" id="cb1748-10" data-line-number="10">             <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1748-11" data-line-number="11"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1748-12" data-line-number="12"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Cohen&#39;s &quot;</span>, <span class="kw">italic</span>(d), <span class="st">&quot; expressed as a posterior&quot;</span>)))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-105-1.png" /><!-- --></p>
<p>If you work them through, the approaches we took for <code>fit7</code> and <code>fit8</code> can be generalized to models with more than two groups. You just need to be careful how to compute the <span class="math inline">\(s_y\)</span> for each comparison. The same cannot be said for our <code>fit9</code> approach. If you were to, say, fit a model that produced estimates for all five groups, you could not just standardize the data beforehand using the overall standard deviation. If you did, the pooled standard deviation you’d be basing your not-quite-Cohen’s <span class="math inline">\(d\)</span> posteriors on would be pooled across all groups, not just the two groups entailed in a given two-group comparison.</p>
<p>It’s also the case the that standardized mean differences we computed for <code>fit1</code>, above, are not quite Cohen’s <span class="math inline">\(d\)</span> effect sizes in the same way these have been. This is because the hierarchical approach we used partially pooled the estimates for each group toward the grand mean. You might say they were hierarchically-regularized Cohen’s <span class="math inline">\(d\)</span>s. But then again, Cohen’s formula for his <span class="math inline">\(d\)</span> statistic did not account for Bayesian priors, either. So perhaps a purist would deny that any of the standardized mean differences we’ve computed in this chapter were proper Cohen’s <span class="math inline">\(d\)</span> effect sizes. To be on the safe side, tell your readers exactly how you computed your models and what formulas you used to compute your effect sizes.</p>
<div id="populations-and-samples." class="section level3">
<h3><span class="header-section-number">19.6.1</span> Populations and samples.</h3>
<p>You may have noticed that in our equation for <span class="math inline">\(d\)</span>, above, we defined it in terms of sample statistics. Here it is again:</p>
<p><span class="math display">\[d = \frac{\bar y_A - \bar y_B}{s_y}\]</span></p>
<p>Sometimes we speak of the population parameter <span class="math inline">\(\delta\)</span>, which is correspondingly defined as</p>
<p><span class="math display">\[\delta = \frac{\mu_A - \mu_B}{\sigma},\]</span></p>
<p>where <span class="math inline">\(\mu_A\)</span> and <span class="math inline">\(\mu_B\)</span> are the population means for the two groups under consideration and <span class="math inline">\(\sigma\)</span> is the pooled standard deviation in the population. Often times we don’t have access to these values, which is why we run experiments and fit statistical models. But sometimes we do have access to the population parameters. In those cases, we can just plug them into the formula rather than estimate them in our models or with our sample statistics.</p>
<p>Back in section 16.1.2, we saw an example of this with the <code>TwoGroupIQ</code> data. Let’s load them, again.</p>
<div class="sourceCode" id="cb1749"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1749-1" data-line-number="1">my_data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data.R/TwoGroupIQ.csv&quot;</span>)</a>
<a class="sourceLine" id="cb1749-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1749-3" data-line-number="3"><span class="kw">glimpse</span>(my_data)</a></code></pre></div>
<pre><code>## Observations: 120
## Variables: 2
## $ Score &lt;dbl&gt; 102, 107, 92, 101, 110, 68, 119, 106, 99, 103, 90, 93, 79, 89, 137, 119, 126, 110, …
## $ Group &lt;chr&gt; &quot;Smart Drug&quot;, &quot;Smart Drug&quot;, &quot;Smart Drug&quot;, &quot;Smart Drug&quot;, &quot;Smart Drug&quot;, &quot;Smart Drug&quot;,…</code></pre>
<p>The data are IQ scores for participants in two groups. They look like this.</p>
<div class="sourceCode" id="cb1751"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1751-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1751-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Score, Group)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1751-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">95</span>, <span class="fl">.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1751-4" data-line-number="4"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;IQ score&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb1751-5" data-line-number="5"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.5</span>, <span class="fl">2.25</span>))</a></code></pre></div>
<p><img src="19_files/figure-gfm/unnamed-chunk-107-1.png" /><!-- --></p>
<p>If we wanted to compute the point estimate for Cohen’s <span class="math inline">\(d\)</span> by hand, we might extract the necessary sample statistics and go.</p>
<div class="sourceCode" id="cb1752"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1752-1" data-line-number="1"><span class="co"># save the sample means for the groups</span></a>
<a class="sourceLine" id="cb1752-2" data-line-number="2">y_bar_a &lt;-<span class="st"> </span><span class="kw">filter</span>(my_data, Group <span class="op">==</span><span class="st"> &quot;Smart Drug&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(Score)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>()</a>
<a class="sourceLine" id="cb1752-3" data-line-number="3">y_bar_b &lt;-<span class="st"> </span><span class="kw">filter</span>(my_data, Group <span class="op">==</span><span class="st"> &quot;Placebo&quot;</span>)    <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(Score)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>()</a>
<a class="sourceLine" id="cb1752-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1752-5" data-line-number="5"><span class="co"># save the pooled standard deviation in the sample</span></a>
<a class="sourceLine" id="cb1752-6" data-line-number="6">s_y &lt;-<span class="st"> </span><span class="kw">sd</span>(my_data<span class="op">$</span>Score)</a>
<a class="sourceLine" id="cb1752-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1752-8" data-line-number="8"><span class="co"># compute Cohen&#39;s d</span></a>
<a class="sourceLine" id="cb1752-9" data-line-number="9">(y_bar_a <span class="op">-</span><span class="st"> </span>y_bar_b) <span class="op">/</span><span class="st"> </span>s_y</a></code></pre></div>
<pre><code>## [1] 0.3479417</code></pre>
<p>To get full posteriors for <span class="math inline">\(d\)</span>, you might use any of the three methods we practiced with, above. Because we’re only working with sample statistics, these are all only approximations of <span class="math inline">\(\delta\)</span>. The thing about IQ scores is we actually know the population mean and standard deviation for IQ. They are 100 and 15, respectively. We know this because the people who make IQ tests design them that way. Let’s see how well out sample statistics approximate the population parameters.</p>
<div class="sourceCode" id="cb1754"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1754-1" data-line-number="1">my_data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1754-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(Group) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb1754-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(Score),</a>
<a class="sourceLine" id="cb1754-4" data-line-number="4">            <span class="dt">sd =</span> <span class="kw">sd</span>(Score))</a></code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   Group       mean    sd
##   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1 Placebo     100.  17.9
## 2 Smart Drug  108.  25.4</code></pre>
<p>Unsurprisingly, the values for the <code>Smart Drug</code> group are notably different from the population parameters. But notice how close the values from the <code>Placebo</code> group are to the population parameters. If they weren’t, we’d be concerned the <code>Placebo</code> condition was not a valid control. Looks like it was.</p>
<p>However, notice that the mean and standard deviation for the <code>Placebo</code> group aren’t the exact values of 100 and 15 the way they are in the population. If we wanted to compute a standardized mean difference between our <code>Smart Drug</code> group and folks in the population, we could just plug those values directly into our effect size equation. Here’s what that would look like if we plug in the population mean for the control group.</p>
<div class="sourceCode" id="cb1756"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1756-1" data-line-number="1">(y_bar_a <span class="op">-</span><span class="st"> </span><span class="dv">100</span>) <span class="op">/</span><span class="st"> </span>s_y</a></code></pre></div>
<pre><code>## [1] 0.3495057</code></pre>
<p>The result is very close to the one above. But this time our equation for <span class="math inline">\(d\)</span> was</p>
<p><span class="math display">\[d = \frac{\bar y_A - \mu_B}{s_y},\]</span></p>
<p>where we used the population mean <span class="math inline">\(\mu_B\)</span>, but the other two terms were based on values from the sample. As long as you are defining the <code>Placebo</code> control as a stand-in for the population, this is a more precice way to compute <span class="math inline">\(d\)</span>. Going further, we can also replace our <span class="math inline">\(s_y\)</span> with <span class="math inline">\(\sigma\)</span> (i.e., 15).</p>
<div class="sourceCode" id="cb1758"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1758-1" data-line-number="1">(y_bar_a <span class="op">-</span><span class="st"> </span><span class="dv">100</span>) <span class="op">/</span><span class="st"> </span><span class="dv">15</span></a></code></pre></div>
<pre><code>## [1] 0.5227513</code></pre>
<p>Now our estimate is quite different. <em>Why</em>? Recall that sample standard deviations for both groups were larger than 15. That resulted in a <span class="math inline">\(s_y\)</span> value that was larger than 15, which meant we divided the unstandardized difference by a larger denominator. That larger denominator returned a smaller product.</p>
<p>We have more than simple algebra to contend with, though. Replacing <span class="math inline">\(s_y\)</span> with 15 actually changed the meaning of the effect size. We were no longer using a pooled standard deviation. Rather, we were using the unconditional population standard deviation. Again, as long as we’re equating our <code>Placebo</code> group with the population, we might restate that 15 as <span class="math inline">\(\sigma_B\)</span>. Sometimes you might see this expressed as <span class="math inline">\(\sigma_C\)</span>, where <span class="math inline">\(C\)</span> indicates “Control” (i.e., the reference category). That changed our formula to this:</p>
<p><span class="math display">\[d = \frac{\bar y_A - \mu_B}{\sigma_B}\]</span></p>
<p>So yes, that’s right. We don’t have to use pooled standard deviations to compute our standardized mean differences. If we have a good reference category, we could just use the sample estimate or population parameter for that, instead. Confusingly, you might see all these variants referred to as Cohen’s <span class="math inline">\(d\)</span> within the literature. As with all the other decisions you make with experimental design and data analysis, use carefully reasoning to decide on how you’d like to compute your effect sizes, report them transparently to your audience, and prepare yourself for a collegial debate with Reviewer #2.</p>
</div>
</div>
<div id="reference-17" class="section level2 unnumbered">
<h2>Reference</h2>
<p><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Kruschke, J. K. (2015). <em>Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan.</em> Burlington, MA: Academic Press/Elsevier.</a></p>
</div>
<div id="session-info-18" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode" id="cb1760"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1760-1" data-line-number="1"><span class="kw">sessionInfo</span>()</a></code></pre></div>
<pre><code>## R version 3.6.2 (2019-12-12)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_1.1.0 bayesplot_1.7.1 brms_2.11.0     Rcpp_1.0.3      ggridges_0.5.2  forcats_0.4.0  
##  [7] stringr_1.4.0   dplyr_0.8.3     purrr_0.3.3     readr_1.3.1     tidyr_1.0.0     tibble_2.1.3   
## [13] ggplot2_3.2.1   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.4-1          ellipsis_0.3.0            rsconnect_0.8.16         
##   [4] ggstance_0.3.3            markdown_1.1              base64enc_0.1-3          
##   [7] fs_1.3.1                  rstudioapi_0.10           farver_2.0.3             
##  [10] rstan_2.19.2              svUnit_0.7-12             DT_0.11                  
##  [13] fansi_0.4.1               mvtnorm_1.0-12            lubridate_1.7.4          
##  [16] xml2_1.2.2                bridgesampling_0.8-1      knitr_1.26               
##  [19] shinythemes_1.1.2         zeallot_0.1.0             jsonlite_1.6             
##  [22] broom_0.5.3               dbplyr_1.4.2              shiny_1.4.0              
##  [25] compiler_3.6.2            httr_1.4.1                backports_1.1.5          
##  [28] assertthat_0.2.1          Matrix_1.2-18             fastmap_1.0.1            
##  [31] lazyeval_0.2.2            cli_2.0.1                 later_1.0.0              
##  [34] htmltools_0.4.0           prettyunits_1.1.0         tools_3.6.2              
##  [37] igraph_1.2.4.2            coda_0.19-3               gtable_0.3.0             
##  [40] glue_1.3.1                reshape2_1.4.3            cellranger_1.1.0         
##  [43] vctrs_0.2.1               nlme_3.1-142              crosstalk_1.0.0          
##  [46] xfun_0.12                 ps_1.3.0                  rvest_0.3.5              
##  [49] mime_0.8                  miniUI_0.1.1.1            lifecycle_0.1.0          
##  [52] gtools_3.8.1              zoo_1.8-7                 scales_1.1.0             
##  [55] colourpicker_1.0          hms_0.5.3                 promises_1.1.0           
##  [58] Brobdingnag_1.2-6         parallel_3.6.2            inline_0.3.15            
##  [61] shinystan_2.5.0           yaml_2.2.0                gridExtra_2.3            
##  [64] StanHeaders_2.19.0        loo_2.2.0                 stringi_1.4.5            
##  [67] dygraphs_1.1.1.6          pkgbuild_1.0.6            rlang_0.4.2              
##  [70] pkgconfig_2.0.3           matrixStats_0.55.0        HDInterval_0.2.0         
##  [73] evaluate_0.14             lattice_0.20-38           rstantools_2.0.0         
##  [76] htmlwidgets_1.5.1         labeling_0.3              tidyselect_0.2.5         
##  [79] processx_3.4.1            plyr_1.8.5                magrittr_1.5             
##  [82] R6_2.4.1                  generics_0.0.2            DBI_1.1.0                
##  [85] pillar_1.4.3              haven_2.2.0               withr_2.1.2              
##  [88] xts_0.11-2                abind_1.4-5               modelr_0.1.5             
##  [91] crayon_1.3.4              arrayhelpers_1.0-20160527 utf8_1.1.4               
##  [94] rmarkdown_2.0             grid_3.6.2                readxl_1.3.1             
##  [97] callr_3.4.0               threejs_0.3.1             reprex_0.3.0             
## [100] digest_0.6.23             xtable_1.8-4              httpuv_1.5.2             
## [103] stats4_3.6.2              munsell_0.5.0             viridisLite_0.3.0        
## [106] shinyjs_1.1</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="metric-predicted-variable-with-multiple-metric-predictors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="metric-predicted-variable-with-multiple-nominal-predictors.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
