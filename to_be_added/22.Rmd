---
title: "Chapter 22. Nominal Predicted Variable"
author: "A Solomon Kurz"
date: "`r format(Sys.Date())`"
output:
  github_document
---

## 22.1. Softmax regression

 > This chapter considers data structures that have a nominal predicted variable. When the nominal predicted variable has only two possible values, this reduces to the case of the dichotomous predicted variable considered in the previous chapter. In the present chapter, we generalize to cases in which the predicted variable has three or more categorical values. (p. 649)

"The key descriptor of the [models in this chapter is their] inverse-link function, which is the softmax function (which will be defined below). Therefore, [Kruschke] refer[s] to the method as softmax regression instead of multinomial logistic regression" (p. 650)

Say we have a metric predictor $x$ and a multinomial criterion $\lambda$ with $k$ categories. We can express the basic liner model as

$$\lambda_k = \beta_{0, k} + \beta_{1, k} x$$

for which the subscripts $k$ indicate there's a linear model for each of the $k$ categories. We call the possible set of $k$ outcomes $S$. The probability of a given outcome $k$ follows the formula

$$\phi_k = \text{softmax}_S ({\lambda_k}) = \frac{\text{exp}(\lambda_k)}{\sum_{c \in S} \text{exp} (\lambda_c)}$$

"In words, [the equation] says that the probability of outcome $k$ is the exponentiated linear propensity of outcome $k$ relative to the sum of exponentiated linear propensities across all outcomes in the set $S$."


Kruschke saved the data for Figure 22.1 in the `SoftmaxRegData1.csv` and `SoftmaxRegData2.csv` files.

```{r}
library(readr)
library(tidyverse)

d1 <- read_csv("data.R/SoftmaxRegData1.csv")
d2 <- read_csv("data.R/SoftmaxRegData2.csv")

glimpse(d1)
glimpse(d2)
```

Let's bind the two data frames together and plot in bulk.

```{r, fig.width = 5}
bind_rows(d1, d2) %>%
  mutate(data = rep(str_c("d", 1:2), each = n() / 2)) %>% 
  
  ggplot(aes(x = X1, y = X2, label = Y, color = Y)) +
  geom_hline(yintercept = 0, color = "grey85") +
  geom_vline(xintercept = 0, color = "grey85") +
  geom_text(size = 3) +
  scale_color_viridis_c(end = .9) +
  coord_equal() +
  theme(panel.grid = element_blank(),
        legend.position = "none") +
  facet_wrap(~data, ncol = 2)
```

### 22.1.1 Softmax reduces to logistic for two outcomes



### 22.1.2 Independence from irrelevant attributes

## 22.2. Conditional logistic regression

## 22.3. Implementation in JAGS

### 22.3.1 Softmax model

### 22.3.2 Conditional logistic model

### 22.3.3 Results: Interpreting the regression coefficients

#### 22.3.3.1 Softmax model

#### 22.3.3.2 Conditional logistic model

## 22.4. Generalizations and variations of the models

## 22.5. Exercises

## References {-}

Kruschke, J. K. (2015). *Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan.* Burlington, MA: Academic Press/Elsevier.

## Session info {-}

```{r}
sessionInfo()
```

```{r, message = F, echo = F}
# Here we'll remove our objects
rm()

theme_set(theme_grey())
```


